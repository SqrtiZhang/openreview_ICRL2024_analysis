name,key_word,sn,reviews,abstract,detail
Modelling Microbial Communities with Graph Neural Networks,"['graph neural networks', ' microbial communities', ' microbiology', ' genomes']",9504,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 1], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}]",,
TabR: Tabular Deep Learning Meets Nearest Neighbors in 2023,"['tabular', ' tabular data', ' architecture', ' deep learning', ' neural networks']",9502,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [4, 4, 2], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}]",,
Neural Evolutionary Kernel Method: A Knowledge-Based Learning Architechture for Evolutionary PDEs,"['Numerical PDE', ' structure preserving neural network', ' operator learning', ' boundary integral']",9498,"[{'mark': [2, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}]",,
PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs,"['PINN', ' machine learning', ' physics-informed machine learning']",9493,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [4, 4, 4], 'rate': 6, 'confidence': 3}, {'mark': [2, 4, 1], 'rate': 1, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]",,
SaNN: Simple Yet Powerful Simplicial-aware Neural Networks,"['Graph Neural Networks', ' Higher-order Representation Learning', ' Simplicial Complexes', ' Simplicial Neural Networks', ' Weisfeiler-Lehman Isomorphism Test']",9491,"[{'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 2}, {'mark': [4, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search,"['Neural Architecture Search', ' Performance Predictor', ' Graph Neural Network']",9483,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models,['Large Language Models; Prompt Engineering; Boosting Mechanism;'],9482,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}]",,
Farzi Data: Autoregressive Data Distillation,"['Data Distillation', ' Meta Learning', ' Recommender Systems', ' Language Modeling']",9481,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 2}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 4}]",,
BATTLE: Towards Behavior-oriented Adversarial Attacks against Deep Reinforcement Learning,"['deep reinforcement learning', ' preference-based reinforcement learning', ' adversarial reinforcement learning']",9480,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}]",,
Understanding Large Language Models Through the Lens of Dataset Generation,"['Large Language Model', ' dataset generation']",9477,"[{'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}]",,
Temporal Parallelization for GPU Acceleration of Spiking Neural Networks,"['Spiking neural networks', ' High-performance computing', ' GPU acceleration']",9476,"[{'mark': [1, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 5}]",,
FSN: Feature Shift Network for Load-Domain Domain Generalization,"['Fault diagnosis', ' Deep learning', ' CNN', ' Domain Generalization', ' Load-domain Domain Generalization']",9472,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [2, 4, 2], 'rate': 6, 'confidence': 4}]",,
"Ask Again, Then Fail: Large Language Models’ Vacillations in Judgement","['Large Language Models', ' Uncertainty', ' Evaluation', ' In-Context Learning', ' Alignment', ' Multi-round dialogue', ' Robustness']",9468,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}]",,
Do Current Large Language Models Master Adequate Clinical Knowledge?,"['Large Language Model', ' Medical Large Language Model', ' Clinical Knowledge', ' Knowledge Graph']",9466,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 2}]",,
SIMULTANEOUS GENERATION AND IMPROVEMENT: A UNIFIED RL PARADIGM FOR FJSP OPTIMIZATION,"['Reinforcement Learning', ' Flexible Job Shop Schedule Problem', ' FJSP']",9463,"[{'mark': [1, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 4}]",,
Model-Agnostic Shift-Equivariant Downsampling,"['Shift equivariance', ' Shift invariance', ' Downsampling', ' Convolutional neural networks']",9459,"[{'mark': [4, 2, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 4}]",,
Visuo-emotional perception and Human Cognition to engineer content-generation using Generative AI,"['creative content', ' digital creatives', ' attention', ' personalization', ' content optimization', ' content generation', ' generative AI']",9458,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [1, 3, 2], 'rate': 1, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 3}]",,
Amplifying Training Data Exposure through Fine-Tuning with Pseudo-Labeled Memberships,"['large language model', ' training data extraction', ' fine-tuning', ' pseudo-labeling with membership', ' privacy']",9456,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}]",,
"FairPATE: Exposing the Pareto Frontier of Fairness, Privacy, Accuracy, and Coverage","['fairness', ' privacy', ' pate', ' pareto frontier']",9455,"[{'mark': [3, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Real-time computer vision on low-end boards via clustering motion vectors,"['Coreset', ' Motion vectors', ' Segments', ' Robotics', ' Structure from motion', ' non-convex optimization']",9453,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [1, 1, 2], 'rate': 1, 'confidence': 4}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 4}]",,
Beyond Memorization: Violating Privacy via Inference with Large Language Models,"['Privacy', ' Large Language Models']",9451,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 5}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 2}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}]",,
AdaLomo: Low-memory Optimization with Adaptive Learning Rate,"['Memory-efficient', ' Optimization', ' Large language models']",9450,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}]",,
Deep Network Partition Density Exhibits Double Descent,"['Double Descent', ' Partition Density', ' Linear Regions', ' Local Complexity']",9446,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Locality Sensitive Sparse Encoding for Learning World Models Online,"['model-based rl', ' online learning', ' incremental learning', ' catastrophic forgetting']",9441,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}]",,
Towards Relaxing the Unbiasedness Condition of Doubly Robust Estimators for Debiased Recommendation,"['Recommender system', ' Selection bias', ' Doubly robust']",9439,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Instruct2Act: Mapping Multi-modality Instructions to Robotic Arm Actions with Large Language Model,"['large language models', ' robotic manipulation', ' code generation']",9438,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
Beyond Disentanglement: On the Orthogonality of Learned Representations,"['Disentanglement', ' Orthogonality', ' Unsupervised Learning', ' Representation Learning', ' DCI', ' DCI-ES']",9436,"[{'mark': [3, 1, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}]",,
Directional Rank Reduction for Backdoor Defense,"['backdoor defense', ' backdoor attack', ' neuron pruning']",9434,"[{'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
Regulation Games for Trustworthy Machine Learning,"['privacy', ' fairness', ' regulation', ' game']",9431,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}]",,
3D Molecular Pretraining via Localized Geometric Generation,['molecular repsentation; self-supervised learning'],9430,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}]",,
CLIP Exhibits Improved Compositional Generalization Through Representation Disentanglement,"['Compositional generalization', ' Out-of-distribution generalization', ' Vision-language models', ' CLIP', ' Disentangled representations', ' Language supervision', ' data-centric AI']",9428,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Disentanglement Learning via Topology,"['representation learning', ' variational autoencoders', ' disentangled representations', ' topological data analysis']",9426,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}]",,
Object-Centric Noise Filtering in Neural Radiance Fields via Influence Functions and Segmentation,"['NeRF', ' robust learning']",9421,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
Unified Language Model Alignment with Demonstration and Point-wise Human Preference,"['Large Language Model', ' Alignment', ' Point-wise preference']",9420,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 4], 'rate': 6, 'confidence': 3}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 3}]",,
DisFormer: Disentangled Object Representations for Learning Visual Dynamics Via Transformers,"['Unsupervised Visual dynamics prediction', ' object centric representation', ' disentangled representation']",9419,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}]",,
Why are hyperbolic neural networks effective? A study on hierarchical representation capability,"['Hyperbolic space', ' hyperbolic neural networks', ' hierarchical structure']",9418,"[{'mark': [3, 3, 3], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 3}]",,
Large Language Models as superpositions of cultural perspectives,"['Large Language Models', ' context-dependence', ' controllability', ' cultural values', ' personal values', ' personality traits', ' societal considerations', ' Shalom H Schwartz', ' Geert Hofstede', ' Big Five']",9417,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}]",,
InstaTAP: Instance Motion Estimation for Tracking Any Point,"['Video Point Tracking', ' Point Tracking', ' Tracking', ' Spatial-Temporal Vision', ' Segment Anything Model']",9415,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}]",,
An Enhanced Gromov-Wasserstein Barycenter Method for Graph-based Clustering,"['Gromov-Wasserstein Learning', ' Graph-based Clustering', ' Non-convex Optimization']",9414,"[{'mark': [4, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}]",,
Physics-informed neural networks for transformed geometries and manifolds,"['physics-informed', ' neural networks', ' transformation', ' manifold', ' diffeomorphism', ' parametrized', ' geometry', ' reference domain', ' free boundary', ' shape optimization']",9410,"[{'mark': [2, 2, 1], 'rate': 1, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}]",,
Enhancing Neural Subset Selection: Integrating Background Information into Set Representations,"['Neural Set Function', ' Hierarchical Structure', ' Invariance', ' Subset Selection']",9406,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
Causal Impact Index: A Causal Formulation of Citations,"['High-dimensional causal inference', ' text analysis', ' matching', ' citation analysis', ' science of science']",9405,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Node-CwR: Node Classification with Reject Option,"['Node classification', ' graph attention networks', ' reject option', ' label noise', ' label smoothing', ' robust learning']",9404,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Segment Anything Meets Universal Adversarial Perturbation,"['Universal Adversarial Perturbation', ' Adversarial Robustness', ' Segment Anything']",9403,"[{'mark': [2, 2, 2], 'rate': 1, 'confidence': 5}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 4}]",,
Episode Transformer: Model-based Episodic Reinforcement Learning,"['Episodic RL', ' Model-based RL', ' Movement Primitives']",9399,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}]",,
Everyone Deserves A Reward: Learning Customized Human Preferences,"['Human Preference Alignment', ' Large Language Model', ' Data Efficiency']",9397,"[{'mark': [4, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 2}]",,
Bridging Vision and Language Spaces with Assignment Prediction,"['Multimodal learning', ' vision-language tasks', ' frozen LLMs', ' optimal transport', ' assignment prediction']",9396,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 6, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Fair Domain Generalization with Arbitrary Sensitive Attributes,"['domain generalization', ' fairness', ' multiple sensitive attributes']",9395,"[{'mark': [1, 2, 2], 'rate': 1, 'confidence': 5}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Metanetwork: A novel approach to interpreting ANNs,"['AI interpretability', ' Model representation', ' Model capability', ' Autoencoder', ' Meta learning']",9394,"[{'mark': [1, 1, 2], 'rate': 1, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 3}]",,
Generative Judge for Evaluating Alignment,"['Generative', ' Evaluation', ' Alignment']",9392,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 2}]",,
Rethinking and Extending the Probabilistic Inference Capacity of GNNs,"['graph neural networks', ' expressiveness', ' approximate inference']",9389,"[{'mark': [3, 2, 3], 'rate': 8, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]",,
Recurrent Distance-Encoding Neural Networks for Graph Representation Learning,"['Recurrent Neural Networks', ' Graph Neural Networks']",9385,"[{'mark': [4, 3, 4], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Learning model uncertainty as variance-minimizing instance weights,"['loss reweighting', ' epistemic uncertainty', ' bi-level optimization', ' model calibration', ' bayesian neural networks']",9383,"[{'mark': [4, 2, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 3}]",,
TVTSv2: Learning Out-of-the-box Spatiotemporal Visual Representations at Scale,"['Video Representation Learning', ' Out-of-the-box Video Representation', ' Scalable Video Pre-training']",9381,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
Controlled Text Generation via Language Model Arithmetic,"['Controlled text generation', ' LLM', ' Natural Language Processing']",9377,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 4], 'rate': 8, 'confidence': 3}, {'mark': [2, 4, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]",,
Tracking Cognitive Development of Large Language Models,"['Cognitive ability', ' benchmark', ' Large Language Models', "" Piaget's theory of cognitive development""]",9374,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 1, 'confidence': 5}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 5}]",,
Black-box Targeted Adversarial Attack on Segment Anything (SAM),"['Black-box attack', ' adversarial robustness', ' segment anything']",9373,"[{'mark': [2, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 1, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization,"['Forward-only learning', ' Biologically inspired learning', ' Artificial neural networks', ' Analytical characterization']",9371,"[{'mark': [4, 3, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}]",,
Do not Start with Trembling Hands: Improving Multi-agent Reinforcement Learning with Stable Prefix Policy,"['MARL', ' Trembling Hands', ' Exploration', ' Exploration', ' Prefix Policy']",9370,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}]",,
Chain-of-Symbol Prompting for Spatial Relationships in Large Language Models,"['Large Language Models', ' Prompting', ' Spatial Planning', ' Reasoning']",9367,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}]",,
Lightweight Graph Neural Network Search with Graph Sparsification,"['graph neural network', ' neural architecture search', ' graph sparsification']",9366,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}]",,
RLP: A reinforcement learning benchmark for neural algorithmic reasoning,"['reinforcement learning', ' benchmark', ' algorithmic reasoning', ' logic puzzles']",9365,"[{'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
Vision Transformer with Irregular Attention,"['Deep Learning', ' DNN', ' Transformer', ' ViT', ' DeiT', ' Tensor Decomposition', ' Tensor Network', ' BTD', ' BTD-LL1', ' CPD', ' DNN Compression', ' DNN Acceleration']",9363,"[{'mark': [3, 2, 3], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}]",,
Towards Cross Domain Generalization of Hamiltonian Representation via Meta Learning,"['hamiltonian dynamics', ' cross domain generalization', ' learning physics', ' meta learning']",9361,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
UBERT: Unsupervised adaptive early exits in BERT,"['Early exits', ' Deep Neural Networks', ' BERT']",9356,"[{'mark': [2, 2, 3], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 1}, {'mark': [1, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
PEACH: Pretrained-embedding Explanation Across Contextual and Hierarchical Structure,"['Interpretability', ' Text classification', ' Global interpretation', ' Local interpretation']",9354,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]",,
"ReLiK: Retrieve, Read and LinK: Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget","['Information Extraction', ' Entity Linking', ' Relation Extraction', ' Natural Language Processing', ' NLP']",9353,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}]",,
What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning,"['data selection', ' instruction tuning', ' large language models']",9349,"[{'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}]",,
Causality-Inspired Spatial-Temporal Explanations for Dynamic Graph Neural Networks,"['Dynamic Graph', ' Graph Explanation', ' Graph Neural Network', ' Causal Inference']",9348,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 2}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Dissecting learning and forgetting in language model finetuning,"['language models', ' domain adaptation', ' catastrophic forgetting']",9346,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
MetaFormer with Holistic Attention Modelling Improves Few-Shot Classification,"['Meta-Learning', ' Vision Transformers']",9345,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
TinyTrain: Deep Neural Network Training at the Extreme Edge,"['Tiny Machine Learning', ' On-device Training', ' Personalisation', ' Edge Computing', ' Microcontrollers']",9344,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 2, 3], 'rate': 8, 'confidence': 4}]",,
Test-time Adaption against Multi-modal Reliability Bias,"['Test-time adaption', ' Imbalanced multi-modal learning']",9339,"[{'mark': [4, 4, 4], 'rate': 8, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [4, 3, 4], 'rate': 6, 'confidence': 5}, {'mark': [3, 4, 4], 'rate': 8, 'confidence': 5}]",,
Fully Identical Initialization,"['Initialization', ' Idetity Matrix', ' Dynamic Isometry']",9336,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 4], 'rate': 6, 'confidence': 4}]",,
LatentCBF: A Control Barrier Function in Latent Space for Safe Control,"['Representation Learning', ' Reinforcement Learning', ' Optimal Control', ' End-to-End Learning', ' Convex Optimization', ' Control Barrier Function', ' Autonomous Driving', ' CARLA', ' Robotics']",9335,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Mirage: Model-agnostic Graph Distillation for Graph Classification,"['graph distillation', ' graph classification', ' frequent pattern mining']",9334,"[{'mark': [2, 3, 1], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 4], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]",,
Stealing the Invisible: Unveiling Pre-Trained CNN Models through Adversarial Examples and Timing Side-Channels,"['Model stealing', ' Adversarial images', ' Timing side-channel', ' Transfer Learning']",9333,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 1, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}]",,
A Weakly Supervised and Globally Explainable Learning Framework for Brain Tumor Segmentation,"['brain tumor segmentation', ' weakly supervised learning', ' explainable learning', ' counterfactual generation', ' class association embedding', ' topological data analysis']",9332,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Exploring mechanisms of Neural Robustness: probing the bridge between geometry and spectrum,"['Latent Geometry', ' Latent Spectrum', ' Adversarial Robustness', ' Mechanistic Model', ' Unsupervised Learning', ' Local Learning', ' Jacobian Regularization', ' Spectral Regularization']",9331,"[{'mark': [3, 1, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}]",,
Two-shot learning of continuous interpolation using a conceptor-aided recurrent autoencoder,"['Conceptors', ' Few Shot Learning', ' Recurrent Neural Networks', ' BPTT', ' Motion Modelling', ' Low Dimensional Dynamics']",9329,"[{'mark': [2, 3, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 2}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 1}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
On the Learnability of Watermarks for Language Models,"['watermarking', ' large language models', ' distillation']",9328,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [4, 4, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}]",,
Personalized Language Generation via Bayesian Metric Augmented Retrieval,"['Retrieval Augmented Generation', ' Bayesian Metric Learning']",9327,"[{'mark': [3, 4, 3], 'rate': 8, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}]",,
Prompt Sketching for Large Language Models,"['large language models', ' prompting', ' decoding']",9320,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision,"['Graph anomaly detection', ' consistency training', ' learnable data augmentation']",9315,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
AN ENTROPY PERSPECTIVE IN KNOWLEDGE DISTILLATION,['Knowledge Distillation'],9314,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
OPTIMIZING STABILIZATION IN SINGULARLY PER- TURBED PROBLEMS WITH SUPG SCHEME,"['Convolutional Neural Network', ' Singularly Perturbed PDEs', ' Stabilization Scheme']",9313,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [1, 3, 1], 'rate': 3, 'confidence': 5}]",,
Bellman Optimal Step-size Straightening of Flow-Matching Models,"['flow matching', ' generative model', ' efficient sampling', ' distillation', ' responsible ML']",9312,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}]",,
Distributional Structured Pruning by Lower bounding the Total Variation Distance using Witness functions,"['Pruning', ' Structured Pruning', ' Total Variation Distance']",9311,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]",,
ZGS-Based Event-Driven Algorithms for Bayesian Optimization in Fully Distributed Multi-Agent Systems,"['distributed machine learning', ' Bayesian optimization', ' multi-agent systems', ' zero-gradient-sum optimization', ' event-driven mechanism']",9310,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 2}, {'mark': [1, 1, 2], 'rate': 1, 'confidence': 3}]",,
Boosted Long Short-Term Memory with Additional Inner Layers,"['Recurrent Neural Networks', ' Long Short-Term Memory', ' Sequence classification', ' Boosted architectures']",9308,"[{'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 2}, {'mark': [1, 2, 1], 'rate': 1, 'confidence': 5}]",,
An Optimization-Based Framework for Adversarial Defence of Graph Neural Networks Via Adaptive Lipschitz Regularization,"['Graph Neural Networks', ' Robustness', ' Lipschitz Regularization']",9303,"[{'mark': [1, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}]",,
Teaching LLMs to Teach Themselves Better Instructions via Reinforcement Learning,"['Large Language Models', ' Complex Instructions', ' Reinforcement Learning']",9302,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 6, 'confidence': 3}]",,
Diffusion with Synthetic Features: Feature Imputation for Graphs with Partially Observed Features,"['Graph neural networks', ' Missing features']",9301,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [1, 2, 1], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}]",,
LST-Bench:A Benchmark for long sequence time-series forecasting Task,"['Time Series', ' Deep Learning', ' Neural Networks', ' Data Mining']",9299,"[{'mark': [1, 2, 1], 'rate': 1, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}]",,
Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction,"['Extreme Classification', ' Extreme Multi-Label Learning']",9297,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [3, 1, 2], 'rate': 5, 'confidence': 2}]",,
Time2Image: A Unified Image Representation Framework for Time Series Classification,['Time series classification; Time series image representation; Adaptive time series gaussian mapping; Vision Transformer'],9293,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 5, 'confidence': 4}]",,
FruitBin: A tunable large-scale dataset for advancing 6D Pose estimation in fruit bin picking automation,"['Datasets and Benchmarks', ' 6D Pose estimation', ' Robotic', ' Bin Picking', ' Occlusion']",9289,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}]",,
Uncovering the Spectrum of Graph Generative Models: From One-Shot to Sequential,"['Graph generation', ' One-shot generation', ' Autoregressive generation', ' Unified framework', ' Diffusion Model', ' Molecule generation']",9287,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
Universal Algorithm for Extreme Bandits with the Minimal Complexities,"['extreme bandits', ' online optimization', ' heavy-tails', ' non-iid data', ' non-parametric']",9286,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 1, 'confidence': 3}, {'mark': [3, 1, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Summing Up the Facts: Additive Mechanisms behind Factual Recall in LLMs,"['Mechanistic Interpretability', ' Interpretability', ' Fact', ' Factual Recall', ' LLM', ' Explainability', ' Transparency']",9284,"[{'mark': [2, 3, 2], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
Task-Oriented Multi-View Representation Learning,['Multi-view learning; Meta learning; Feature modulation; Task adaptation'],9283,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
Understanding the Mechanics and Dynamics of Memorisation in Large Language Models: A Case Study with Random Strings,"['language models', ' memorization']",9281,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}]",,
NeFL: Nested Federated Learning for Heterogeneous Clients,"['federated learning', ' system heterogeneity']",9278,"[{'mark': [4, 3, 4], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching,"['Mechanistic Interpretability', ' Natural Language Processing', ' Large Language Models']",9274,"[{'mark': [4, 4, 4], 'rate': 8, 'confidence': 3}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 4, 4], 'rate': 8, 'confidence': 2}]",,
Fixed-Budget Best Arm Identification with Variance-Dependent Regret Bounds,['Best arm identification'],9273,"[{'mark': [3, 1, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems,"['mean-field Langevin dynamics', ' minimax optimization', ' zero-sum games', ' Markov games']",9271,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 4], 'rate': 8, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 4}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 2}]",,
Causal Inference Using LLM-Guided Discovery,"['Causal Inference', ' Large Language Models', ' Causal Discovery', ' Causal Order']",9268,"[{'mark': [1, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [4, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Learning Predictive Checklists with Probabilistic Logic Programming,"['Predictive Checklists', ' Interpretability', ' Fairness', ' Probabilistic Logic Programming']",9267,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}]",,
Parrot: Enhancing Multi-Turn Chat Models by Learning to Ask Questions,"['large language model', ' instruction tuning', ' multi-turn conversation']",9266,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}]",,
Knowledge Graph Completion by Intermediate Variables Regularization,"['Knowledge Graph Completion', ' Tensor Decomposition', ' Regularization']",9265,"[{'mark': [3, 4, 1], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 2, 3], 'rate': 8, 'confidence': 4}]",,
Attributed Graph Clustering via Coarsening with Modularity,"['Graph Clustering', ' Graph Neural Networks', ' Convex Optimization', ' Non-Convex Optimization', ' Graph Coarsening']",9264,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [1, 3, 1], 'rate': 3, 'confidence': 5}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}]",,
MAGDiff: Covariate Data Set Shift Detection via Activation Graphs of Deep Neural Networks,"['shift detection', ' dimensionality reduction', ' neural networks', ' activation graphs']",9263,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
Prototypes-Injected Prompt for Federated Class Incremental Learning,"['federated class incremental learning', ' federated learning', ' class incremental learning', ' continual learning', ' prompt', ' prototype']",9261,"[{'mark': [3, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 1}]",,
Demonstration-Regularized RL,"['reinforcement learning', ' regularization in reinforcement leaning', ' learning with demonstrations', ' reinforcemenet learning with human feedback']",9260,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 2}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 2}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}]",,
Explorative Latent Self-Supervised Active Search Algorithm (ELSA),"['Computer Vision', ' Active Learning', ' Interactive Labeling', ' Self-Supervised Learning']",9259,"[{'mark': [2, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 1, 2], 'rate': 5, 'confidence': 2}, {'mark': [2, 1, 1], 'rate': 1, 'confidence': 4}]",,
Negative-prompt Inversion: Fast Image Inversion for Editing with Text-guided Diffusion Models,"['generative models', ' diffusion models', ' score-based models', ' image generation', ' image editing']",9257,"[{'mark': [3, 4, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 6, 'confidence': 4}]",,
"GatedMTL: Learning to Share, Specialize, and Prune Representations for Multi-task Learning","['Multi-task learning', ' Gated networks', ' Sharing', ' Pruning', ' Sparsity', ' MTL']",9256,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
PDE-Diffusion: Physic guided diffusion model for solving partial derivative equations,"['AI for science', ' PDE', ' diffusion model', ' generative model']",9255,"[{'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}, {'mark': [1, 2, 2], 'rate': 1, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}]",,
BEV-CLIP: Multi-modal BEV Retrieval Methodology for Complex Scene in Autonomous Driving,"['Autonomous Driving', ' BEV', ' Retrieval', ' Multi-modal', ' LLM', ' prompt learning']",9254,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Differentiable Optimization in Plane-Wave Density Functional Theory for Solid States,"['AI for Science', ' Quantum Chemisty', ' Density Functional Theory', ' Deep Learning', ' Kohn-Sham Equation', ' Solid-State Physics']",9253,"[{'mark': [3, 3, 3], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [4, 4, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Multilingual Jailbreak Challenges in Large Language Models,"['multilingual', ' safety', ' large language models']",9250,"[{'mark': [2, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}]",,
Instruction-tuned LLMs with World Knowledge are More Aligned to the Human Brain,"['large language models', ' instruction-tuning', ' world knowledge', ' neuroscience', ' neuroAI']",9249,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Brain-inspired Geometry Constrain on Represention for Compositional Generalization,"['Represention Learning', ' Compositional Generalization.']",9248,"[{'mark': [3, 1, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 1, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 1], 'rate': 1, 'confidence': 3}]",,
Categorical Features of entities in Recommendation Systems Using Graph Neural Networks,"['Graph Neural Networks', ' Representation learning', ' recommender engines', ' Hyper edges']",9246,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}]",,
Generalized Policy Iteration using Tensor Approximation for Hybrid Control,"['Optimal Control', ' Hybrid Actions', ' Robotics', ' Approximate Dynamic Programming', ' Tensor Approximation']",9245,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}]",,
t3-Variational Autoencoder: Learning Heavy-tailed Data with Student's t and Power Divergence,"['Variational autoencoder', ' Information geometry', ' Heavy-tail learning', ' Generative model']",9244,"[{'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
Neuron to Graph: Interpreting Language Model Neurons at Scale,"['Mechanistic Interpretability', ' Visualisation']",9243,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 1, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}]",,
Residual Factorized Fourier Neural Operator for simulation of three-dimensional turbulence,"['factorized fourier neural operator', ' fourier neural operator', ' navier stokes', ' three-dimensional turbulence prediction']",9242,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Adjustable Quantile-Guided Diffusion Policy for Diverse Behavior Generation in Offline RL,"['offline reinforcement learning', ' diffusion']",9241,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 5, 'confidence': 4}]",,
Cooperative Hardware-Prompt Learning for Snapshot Compressive Imaging,"['snapshot compressive imaging', ' hyperpectral imaging', ' prompt learning', ' federated learning']",9239,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 5}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}]",,
Prompt Optimization via Adversarial In-Context Learning,"['Prompt Optimization', ' Adversarial Learning', ' In-Context Learning', ' Large Language Model']",9238,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
FEATHER: Lifelong Test-Time Adaptation with Lightweight Adapters,"['test-time adaptation', ' source free test-time domain adaptation', ' parameter efficient test-time adaptation']",9237,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 1], 'rate': 3, 'confidence': 4}]",,
FLAT-Chat: A Word Recovery Attack on Federated Language Model Training,"['Label inference attack', ' Large-scale language model', ' Matrix flattening']",9236,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 5}]",,
Chain-of-Thought Predictive Control,"['Hierarchical Imitation Learning', ' Robotic Manipulation']",9232,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
Adapting ConvNets for New Cameras without Retraining,"['Convolutional Networks', ' Pretrained', ' Wide FOV', ' Fisheye', ' Segmentation', ' Rectification']",9231,"[{'mark': [2, 2, 2], 'rate': 1, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}]",,
Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability,"['Graph neural networks', ' Graph canonization', ' Stability']",9229,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]",,
Relating Implicit Bias and Adversarial Attacks through Intrinsic Dimension,"['Implicit Bias', ' Adversarial Attacks', ' Intrinsic Dimension', ' Neural Networks', ' Fourier Transform']",9228,"[{'mark': [2, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}]",,
Rethinking Actor-Critic: Successive Actors for Critic Maximization,"['Off-policy reinforcement learning', ' actor-critic methods', ' TD3', ' discrete action spaces', ' continuous action spaces']",9227,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
Gradual Optimization Learning for Conformational Energy Minimization,"['energy minimization', ' conformational optimization']",9224,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 4, 3], 'rate': 6, 'confidence': 4}]",,
AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection,"['Anomaly detection', ' Zero-shot anomaly detection', ' CLIP', ' Industrial defect inspection']",9222,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [3, 4, 4], 'rate': 8, 'confidence': 3}]",,
Chat Vector: A Simple Approach to Equip LLMs With New Language Chat Capabilities,"['RLHF', ' LLM']",9220,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Generative Models are Self-Watermarked: Intellectual Property Declaration through Re-Generation,"['Watermark', ' Generative Model', ' Re-generation', ' Fixed-point Theory']",9219,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Nonlinear Inference Learning for Differentially Private Massive Data,"['Differential privacy', ' Nonlinear Inference', ' Massive Data', ' Bag of Little Bootstraps']",9218,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 3, 'confidence': 5}, {'mark': [2, 1, 1], 'rate': 1, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}]",,
Boosting Selective Rationalization with Shortcuts Discovery,"['Selective Rationalization', ' Shortcut']",9216,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 4}]",,
RL4CO: a Unified Reinforcement Learning for Combinatorial Optimization Library,"['Reinforcement Learning', ' Neural Combinatorial Optimization', ' Combinatorial Optimization', ' Library', ' Benchmark']",9212,"[{'mark': [3, 3, 3], 'rate': 3, 'confidence': 3}, {'mark': [3, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
IKL: Boosting Long-Tail Recognition with Implicit Knowledge Learning,['Long-tail Recognition'],9210,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}]",,
GPT Can Solve Mathematical Problems Without a Calculator,['Large Language Model; Mathematical Reasoning; Arithmetic Tasks; Math Word Problem'],9208,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [1, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
S4G: Breaking the Bottleneck on Graphs with Structured State Spaces,"['GNN', ' over-squashing', ' state-space models']",9207,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}]",,
CORN: Contact-based Object Representation for Nonprehensile Manipulation of General Unseen Objects,"['pretraining', ' robotics', ' manipulation', ' object representation', ' representation learning']",9206,"[{'mark': [4, 4, 4], 'rate': 1, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 4}]",,
An Intuitive Multi-Frequency Feature Representation for SO(3)-Equivariant Networks,"['Equivariant networks', ' SO(3) Equivariance', ' Fourier features']",9205,"[{'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}]",,
CodeComplex: A Time-complexity Dataset for Multi-language Source Codes,"['Code complexity', ' Dataset', ' Neural network']",9201,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Implicit Regularisation in Overparametrized Networks: A Multiscale Analysis of the Fokker-Planck equation,"['overparametrized networks', ' optimisation', ' implicit regularization', ' multiscale', ' fokker-planck equation']",9200,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 3], 'rate': 3, 'confidence': 3}]",,
KoLA: Carefully Benchmarking World Knowledge of Large Language Models,"['Large Language Model', ' World Knowledge', ' Evolving Benchmark']",9199,"[{'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 2}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 2}]",,
Screening Unlearnable Examples via Iterative Self Regression,"['data poisoning attack', ' iterative self regression', ' availability attacks detection', ' unlearnable examples']",9197,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 1], 'rate': 1, 'confidence': 5}]",,
Graph Parsing Networks,"['GNN', ' graph pooling', ' parsing']",9196,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 3}]",,
Retrieving Texts by Abstract Descriptions,"['similarity', ' descriptions', ' LMs', ' retrieval']",9195,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}]",,
TESTAM: A Time-Enhanced Spatio-Temporal Attention Model with Mixture of Experts,"['Traffic Predictoin', ' Deep Learning', ' Spatio-Temporal data modeling']",9189,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}]",,
Improving SAM Requires Rethinking its Optimization Formulation,"['Sharpness aware minimization', ' generalization', ' supervised learning', ' optimization', ' bilevel optimization']",9188,"[{'mark': [4, 4, 4], 'rate': 1, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
RedMotion: Motion Prediction via Redundancy Reduction,"['Motion prediction', ' self-supervised learning', ' trajectory forecasting', ' self-driving']",9187,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 5}]",,
TILDE-Q: A Transformation Invariant Loss Function for Time-Series Forecasting,"['Time-Series Forecasting', ' Deep Learning', ' Loss functions', ' Time-series Similarity']",9186,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
Learning From Simplicial Data Based on Random Walks and 1D Convolutions,"['simplicial complex', ' simplicial neural network', ' random walks']",9185,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 5}]",,
Adaptive Environmental Modeling for Task-Oriented Language Agents,"['Large Language Model', ' Environmental Adaptation', ' Agents', ' Interactive Decision Making']",9182,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
LUM-ViT: Learnable Under-sampling Mask Vision Transformer for Bandwidth Limited Optical Signal Acquisition,"['hyperspectral imaging', ' optical modulation', ' real-time detection', ' vision transformer', ' pre-acquisition modulation', ' learnable mask', ' weight binarization']",9181,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}]",,
Sensitivity-Aware Differentially Private Decentralized Learning with Adaptive Noise,"['decentralized learning', ' differential privacy', ' adaptive noise', ' time-varying topology']",9180,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 3, 1], 'rate': 3, 'confidence': 4}]",,
EvIL: Evolution Strategies for Generalisable Imitation Learning,"['Reinforcement Learning', ' Inverse Reinforcement Learning', ' Imitation Learning', ' Evolutionary Strategies']",9179,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 5}]",,
RILe: Reinforced Imitation Learning,"['Reinforcement Learning', ' Imitation Learning', ' Deep Reinforcement Learning']",9178,"[{'mark': [1, 1, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}]",,
Few Heads are Enough,"['transformers', ' attention', ' moe', ' mixture of experts', ' efficient transformers', ' language modelling']",9177,"[{'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 3}]",,
LMExplainer: A Knowledge-Enhanced Explainer for Language Models,"['Explainability', ' XAI', ' Language Model']",9174,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Optimal spherical codes for locality-sensitive hashing,"['Optimal spherical codes', ' locality sensitive hashing', ' similarity search', ' sparse coding']",9173,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 1, 'confidence': 5}, {'mark': [2, 1, 3], 'rate': 3, 'confidence': 4}]",,
ProtChatGPT: Towards Understanding Proteins with Large Language Models,"['Large Language Models', ' ChatGPT-like system', ' Protein Understanding']",9172,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
Bayesian Vector Optimization with Gaussian Processes,"['Vector Optimization', ' Bayesian Optimization', ' Gaussian Processes', ' Ordering Cones']",9167,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}]",,
Meta- (out-of-context) learning in neural networks,"['LLMs', ' large language models', ' in-context learning', ' meta-learning', ' world models', ' internalization', ' consistency', ' learning factual associations']",9166,"[{'mark': [2, 2, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 5, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
On the Long Range Abilities of Transformers,"['Transformers', ' Long Range', ' LRA Benchmark']",9164,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}]",,
Social-Transmotion: Promptable Human Trajectory Prediction,"['human trajectory prediction', ' robot navigation', ' autonomous driving', ' attention mechanism']",9161,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
Efficient architectural aspects for text-to-video generation pipeline,"['text-to-video', ' video generation', ' temporal consistency', ' frames interpolation', ' Inception Score', ' CLIPSIM', ' MoVQ video decoder']",9160,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}]",,
Gandalf: Learning label correlations in Extreme Multi-label Classification via Label Features,"['Extreme Multilabel Classification', ' Key-phrase ads matching', ' short-text classification']",9159,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 5}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}]",,
Robust Classification via Regression-Based Loss Reweighting and Label Correction,"['label noise', ' noisy labels', ' robustness', ' Gaussian noise', ' classification']",9158,"[{'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Subject-specific Deep Neural Networks for Count Data with High-cardinality Categorical Features,"['subject-specific prediction', ' random effect', ' high-cardinality categorical feature', ' count data', ' clustered data', ' hierarchical likelihood', ' deep learning']",9157,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
ProteinAdapter: Adapting Pre-trained Large Protein Models for Efficient Protein Representation Learning,"['Pretrained Large Models', ' Parameter-Efficient Fine-tuning', ' Protein Representation Learning']",9155,"[{'mark': [2, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 3}]",,
Let's reward step by step: Step-Level reward model as the Navigators for  Reasoning,"['Large Launage model', ' Process-Supervised Reward Model', ' Multi-step Reasoning']",9154,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 1, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}]",,
Generalization error of spectral algorithms,"['gradient descent', ' kernel ridge regression', ' optimal algorithm', ' generalization', ' asymptotic error rates', ' power-laws']",9152,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 2}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}]",,
Slot Structured World Models,"['world models', ' model-based reinforcement learning', ' object-centric representation learning']",9151,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}]",,
Observer Uncertainty of Learning in Games from a Covariance Perspective,"['covariance', ' symplectic Euler method', ' follow-the-regularized-leader (FTRL) algorithm', ' uncertainty', ' zero-sum games']",9150,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]",,
Contrastive Implicit Representation Learning,"['Implicit neural representations', ' self-supervised-learning', ' contrastive learning', ' neural fields', ' multiplicative filter networks', ' SimCLR']",9148,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 1, 'confidence': 3}]",,
LLM+A: Grounding Large Language Models in Physical World with Affordance Prompting,"['Large Language Model', ' Robotic Control', ' Affordance Prompting']",9146,"[{'mark': [2, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
DAS2C: A Distributed Adaptive Minimax Method with Near-Optimal Convergence,"['Minimax Optimization', ' Distributed Learning', ' Nonconvex Optimization', ' Convergence Analysis', ' Stepsize Inconsistency']",9142,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 1, 3], 'rate': 6, 'confidence': 3}]",,
Learning to Reject with a Fixed Predictor: Application to Decontextualization,"['Rejection', ' abstention', ' loss function', ' consistency', ' learning theory', ' decontextualization', ' natural language processing']",9141,"[{'mark': [3, 3, 3], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}]",,
Disentangling Covariates to Predict Counterfactuals for single-cell data,"['single-cell', ' computational biology', ' causal inference', ' generative model', ' variational inference', ' variational autoencoder', ' fairness', ' representation disentanglement']",9140,"[{'mark': [1, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 4}]",,
All Languages Matter: On the Multilingual Safety of Large Language Models,"['LLMs', ' Safety', ' Multilingual']",9139,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 3], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 4], 'rate': 5, 'confidence': 4}]",,
Deep Anti-Regularized Ensembles,"['Deep Ensemble', ' Uncertainty', ' Out-of-distribution', ' Anti-regularization']",9138,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}]",,
CLASS-INCREMENTAL LEARNING USING GENERATIVE EXPERIENCE REPLAY BASED ON TIME-AWARE REGULARIZATION,"['lifelong learning', ' continual learning', ' class-incremental learning', ' regularization']",9137,"[{'mark': [3, 3, 1], 'rate': 3, 'confidence': 3}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}]",,
Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging,"['Cross-Lingual Transfer', ' Model Merging', ' Large Language Models']",9136,"[{'mark': [4, 4, 3], 'rate': 8, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 4}]",,
Thin-Thick Adapter: Segmenting Thin Scans Using Thick Annotations,"['Semantic Segmentation', ' Computed Tomography', ' Domain Adaptation']",9133,"[{'mark': [3, 4, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}]",,
γ-Orthogonalized Tensor Deflation: Towards Robust \& Interpretable Tensor Decomposition in the Presence of Correlated Components,"['Low-rank signal reconstruction', ' tensor decomposition', ' random matrix theory', ' optimization.']",9131,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 5}, {'mark': [3, 1, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}]",,
Dynamics-Informed Protein Design with Structure Conditioning,"['Diffusion Models', ' Generative Modeling', ' Protein Design', ' Normal Mode Analysis']",9128,"[{'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
DfPO: Degeneration-free Policy Optimization via Action Masking in Natural Language Action Spaces,"['Reinforcement learning', ' Natural language processing']",9127,"[{'mark': [1, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}]",,
SR-OOD: Out-of-Distribution Detection via Sample Repairing,"['OOD Detection', ' Generative Model']",9125,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}]",,
Syntactic Representations Enable Interpretable Hierarchical Word Vectors,"['Syntactic Representations', ' Interpretable Vectors', ' Hierarchical Vectors']",9124,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}]",,
On Synthetic Data and Iterative Magnitude Pruning: a Linear Mode Connectivity Study,"['Neural Network Pruning', ' Linear Mode Connectivity', ' Dataset Distillation', ' Sparse Neural Networks']",9121,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 4}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 1, 2], 'rate': 5, 'confidence': 3}]",,
Can General-Purpose Language Models Emulate a General-Purpose Computer In-Context?,"['large language models', ' general-purpose computing', ' AI alignment']",9120,"[{'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 5}, {'mark': [4, 4, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}]",,
VRAda: A Variance Reduced Adaptive Algorithm for Stochastic Parameter-Agnostic Minimax Optimizations,"['Stochastic minimax optimization', ' Parameter-agnostic', ' Variance-reduction']",9118,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}]",,
Unlocking Anticipatory Text Generation: A Constrained Approach for Faithful Decoding with Large Language Models,"['LLM decoding', ' keyword-constrained generation', ' toxicity reduction', ' factual correctness']",9116,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 1, 4], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
Partitioning Message Passing for Graph Fraud Detection,"['Graph Neural Networks', ' Fraud Detection']",9114,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
"Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation","['language model', ' hallucination', ' trustworthy artificial intelligence', ' reasoning']",9113,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}]",,
Non-backtracking Graph Neural Networks,"['non-backtracking', ' redundancy', ' graph neural network', ' over-squashing']",9111,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}]",,
FHA-Kitchens: A Novel Dataset for Fine-Grained Hand Action Recognition in Kitchen Scenes,"['hand action recognition', ' fine-grained', ' dataset', ' benchmark']",9109,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
Towards Analyzing Self-attention via Linear Neural Network,"['transformers', ' linear neural networks', ' gradient flow analysis']",9108,"[{'mark': [2, 2, 1], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Efficient Denoising Diffusion via Probabilistic Masking,"['Diffusion Model', ' Sparse Training', ' Model Compression']",9106,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}]",,
Phase Transitions in Contrastive Learning,"['representation learning', ' training dynamics', ' contrastive learning']",9102,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}]",,
There is More to Graphs than Meets the Eye: Learning Universal Features with Self-supervision,"['Representation learning', ' Self supervised learning', ' Foundation models', ' Generalisability', ' Graph transformer']",9097,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Latent Lie Group Representations,"['deep learning', ' symmetry', ' lie groups']",9095,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 1, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 5, 'confidence': 4}]",,
CORE: Common Random Reconstruction for Distributed Optimization with Provable Low Communication Complexity,"['Distributed Optimization', ' Effective Dimension', ' Gradient Compression', ' Learning Theory']",9094,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}]",,
The KNN Score for Evaluating Probabilistic Multivariate Time Series Forecasting,"['time series', ' forecasting', ' metric', ' evaluation', ' probabilistic', ' multivariate', ' knn', ' density estimation', ' scoring rule']",9092,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}]",,
ProFeAT: Projected Feature Adversarial Training for Self-Supervised Learning of Robust Representations,"['Self-supervised Adversarial Training', ' Adversarial Training', ' Adversarial Robustness', ' Contrastive Learning']",9090,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 5}]",,
Semi-Anchored Gradient Methods for Nonconvex-Nonconcave Minimax Problems,"['Optimization', ' Minimax', ' PDHG', ' nonconvex-nonconcave', ' Weak-MVI']",9088,"[{'mark': [3, 2, 1], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}]",,
Tensor-Train Point Cloud Compression and Efficient Approximate Nearest Neighbor Search,"['Nearest neighbor search', ' Approximate Search', ' Information Storage and Retrieval']",9087,"[{'mark': [3, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 4}]",,
Automating Continual Learning,"['continual learning', ' in-context learning', ' meta-learning', ' self-referential learning', ' linear Transformers']",9084,"[{'mark': [2, 4, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}]",,
When does In-context Learning Fall Short and Why? A Study on Specification-Heavy Tasks,"['In-context learning', ' large language models', ' instruction tuning']",9082,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 4, 2], 'rate': 3, 'confidence': 4}]",,
Mitigating backdoor attacks with generative modelling and dataset relabelling,"['backdoor defense', ' backdoor learning', ' trusthworty AI', ' AI security']",9081,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}]",,
Layer-wise Pre-weight Decay,"['deep learning', ' regularization', ' generalization', ' weight decay']",9078,"[{'mark': [1, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Efficient Unsupervised Knowledge Distillation with Space Similarity,['unsupervised knowledge distillation'],9077,"[{'mark': [2, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
A Convergent Federated Clustering  Algorithm without Initial Condition,"['Federated Learning', ' Heterogeneity', ' Clustering']",9076,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Antibody DomainBed: Out-of-Distribution Generalization in Therapeutic Protein Design,"['domain generalization', ' invariance', ' benchmarks', ' drug discovery']",9074,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 3}]",,
Adaptive Causal Balancing for Collaborative Filtering,"['Recommender System', ' Causal Inference', ' Bias', ' Debias', ' Balancing']",9073,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}]",,
Integrated Model Explanations by Independent and Collaborative Feature Influence via Linear-Nonlinear Perspectives.,"['Explanation method', ' Linear simplification', ' Feature interactions', ' Independent influence', ' Collaborative influence', ' Linear-Nonlinear Explanation']",9072,"[{'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
Where is the Invisible: Spatial-Temporal Reasoning with Object Permanence,"['Object Permanence', ' Visual Relational Reasoning', ' Trajectory Prediction']",9071,"[{'mark': [2, 1, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 5}]",,
Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems,"['large language models', ' prompting', ' mathematical reasoning', ' natural language processing']",9070,"[{'mark': [2, 2, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}]",,
Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching,"['Supervised contrastive learning', ' neural collapse', ' implicit bias', ' class imbalance']",9066,"[{'mark': [4, 4, 2], 'rate': 6, 'confidence': 4}, {'mark': [4, 4, 2], 'rate': 5, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}]",,
Manipulating dropout reveals an optimal balance of efficiency and robustness in biological and machine visual systems,"['Efficient coding', ' object representation', ' dropout', ' robustness', ' human fMRI', ' occipitotemporal cortex', ' cognitive neuroscience', ' distributed coding']",9065,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}]",,
Controllable Text-to-Image Generation with Automatic Sketches,"['text to image generation', ' controllable generation', ' large language models']",9064,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 5, 'confidence': 5}]",,
Knowledge Distillation with Perturbed Loss: From a Vanilla Teacher to a Proxy Teacher,"['knowledge distillation', ' language model', ' NLP']",9063,"[{'mark': [3, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}]",,
Estimation error of gradient descent in deep regressions,"['deep regression', ' gradient descent', ' estimation error', ' approximation', ' generalization', ' optimization']",9062,"[{'mark': [3, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}]",,
Fast Conditional Intervention in Algorithmic Recourse with Reinforcement Learning,"['Algorithmic recource', ' Causality', ' Reinforcement Learning', ' Explainable machine learning']",9061,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}]",,
Domain-agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations,"['Implicit neural representation', ' generative model', ' domain agnostic']",9058,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 3}]",,
DreamFuser: Value-guided Diffusion Policy for Offline Reinforcement Learning,['Trajectory-based Reinforcement Learning; Diffusion Model; Offline Reinforcement Learning;'],9052,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]",,
2D-Supervised Monocular 3D Object Detection by Global-to-Local Reconstruction,['monocular 3D object detection'],9051,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}]",,
TANGO: Time-Reversal Latent GraphODE for Multi-Agent Dynamical Systems,"['NeuralODE', ' Graph Neural Networks', ' Dynamical Systems', ' Physical Simulations', ' Physics-informed Neural Networks']",9050,"[{'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 4}]",,
Post-Training Recovery from Injected Bias with Self-Influence,"['Deep learning', ' dataset bias', ' debiasing']",9048,"[{'mark': [1, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}]",,
Feature Selection in the Presence of Monotone Batch Effects,"['Batch Effect', ' Distribution Shift']",9047,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}]",,
Misusing Tools in Large Language Models With Visual Adversarial Examples,"['LLM', ' Advesarial examples', ' Prompt Injection', ' Security']",9046,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 6, 'confidence': 5}]",,
FedLoRA: When Personalized Federated Learning Meets Low-Rank Adaptation,"['Personalized Federated Learning', ' non-IID', ' Low-Rank Adaptation']",9045,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [3, 4, 4], 'rate': 8, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Exploring Active Learning in Meta-Learning: Enhancing Context Set Labeling,"['Active Learning', ' Meta Learning']",9044,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
A Neural Sandbox Framework for Discovering Spurious Concpets in LLM Decisions,"['Large Language Model', ' Spurious Corelation', ' NLP', ' AI Alignment']",9041,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 3, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 1, 'confidence': 4}]",,
From Random to Relevant: Harnessing Salient Masks in Non-IID Federated Learning,"['Sparsity', ' Pruning', ' Federated Learning', ' Sparse Federated Learning', ' Communication efficiency', ' Efficient FL', ' Pruning at Initialization']",9040,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 2}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}]",,
MedJourney: Counterfactual Medical Image Generation by Instruction-Learning from Multimodal Patient Journeys,"['instruction image editing', ' instruction-learning', ' image generation', ' diffusion', ' natural-language instruction', ' biomedicine', ' counterfactual generation', ' disease progression modeling', ' GPT-4', ' imaging reports', ' latent diffusion model', ' curriculum learning', ' MIMIC-CXR']",9035,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Bayesian Coreset Optimization for Personalized Federated Learning,"['federated learning', ' personalized federated learning', ' bayesian coreset', ' submodularity', ' variational inference', ' coresets', ' optimization']",9034,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}]",,
Fooling the Textual Fooler via Randomizing Latent Representations,"['NLP', ' Adversarial Defense', ' Robustbess']",9033,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 4, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 4], 'rate': 5, 'confidence': 5}]",,
In-context Autoencoder for Context Compression in a Large Language Model,"['large language model', ' context compression', ' in-context autoencoder', ' pretraining', ' fine-tuning', ' Llama', ' GPT', ' memorization']",9031,"[{'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning,"['instruction tuning', ' multimodal large language model', ' hallucination', ' datasets']",9027,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}]",,
Implicit Neural Representation Image Codec with Mixed Context for Fast Decoding,"['Image Compression', ' Implicit Neural Representation', ' Adaptive Entropy Modeling']",9026,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
DECOUPLING REASONING FROM OBSERVATIONS FOR EFFICIENT AUGMENTED LANGUAGE MODELS,"['Tool augmented language model', ' Efficiency', ' Prompt redundancy', ' Instruction fine-tuning']",9024,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Multimarginal Generative Modeling with Stochastic Interpolants,"['multi-marginal', ' unsupervised learning', ' generative modeling', ' measure transport', ' optimal transport']",9021,"[{'mark': [4, 3, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
Neural Bounds on Bayes Error: Advancing Classification and Generative Models,"['f-Divergence', ' Bayes Error', ' Generative Adversarial Networks (GANs)', ' Representation Learning Neural Networks', ' Multiclass Classification']",9020,"[{'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 2}]",,
Proving Test Set Contamination for Black-Box Language Models,"['language modeling', ' memorization', ' dataset contamination']",9019,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 4, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
Leveraging Cross-Modal Neighbor Representation for Improved CLIP Classification,"['Vision-Language Models', ' Large Language Model', ' Zero-Shot Learning', ' Few-Shot Learning']",9018,"[{'mark': [2, 3, 1], 'rate': 5, 'confidence': 2}, {'mark': [3, 3, 1], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 5}]",,
Stochastic interpolants with data-dependent couplings,"['flows', ' diffusions', ' stochastic interpolants', ' generative models', ' sde', ' ode', ' image generation']",9016,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
FILI: Syntax Repair By Learning From Own Mistakes,"['Automatic Program Repair', ' Software Engineering', ' Neural Syntax Fix']",9014,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 2], 'rate': 6, 'confidence': 4}]",,
GrowLength: Accelerating LLMs Pretraining by Progressively Growing Training Length,"['Large Language Model', ' Pretraining']",9012,"[{'mark': [4, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [1, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Meta Compression: Learning to compress Deep Neural Networks,"['Model compression', ' meta learning', ' efficient inference', ' deep learning']",9011,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 5}]",,
Non-Autoregressive Machine Translation as Constrained HMM,['text generation; label bias'],9009,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling,"['Prompting', ' In-Context Learning', ' Few-Shot Learning', ' GPT', ' Large Language Models', ' Multi-Step Reasoning', ' Natural Language Processing']",9008,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}]",,
Efficiently Measuring the Cognitive Ability of LLMs: An Adaptive Testing Perspective,"['large language model', ' adaptive testing', ' model evaluation']",9005,"[{'mark': [1, 1, 1], 'rate': 3, 'confidence': 2}, {'mark': [2, 3, 3], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 5, 'confidence': 4}]",,
Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators,"['Multivariate time series forecasting', ' channel dependence', ' lead-lag relationships']",9003,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 4, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Structured Graph Reduction for Efficient GNN,"['structured graph coarsening', ' graph neural network', ' node classification', ' convex optimization']",9000,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}]",,
RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval,"['Retrieval Augmented Language Models', ' Information Retrieval', ' summarization', ' QA']",8997,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}]",,
Fair and Efficient Contribution Valuation for Vertical Federated Learning,"['Vertical federated learning', ' Contribution valuation', ' Fairness']",8996,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Principal Component Analysis for Cross-Sectionally Correlated Pricing Errors,"['Unsupervised Learning', ' Optimization', ' Principal Component Analysis', ' Asset Pricing', ' Factor Pricing Model']",8992,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 5}]",,
Self Guided Exploration for Automatic and Diverse AI Supervision,"['Language models', ' Reinforcement Learning', ' Unsupervised Reinforcement Learning']",8990,"[{'mark': [4, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 3, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Interpretable and Convergent Graph Neural Network Layers at Scale,"['Graph Neural Networks', ' Energy-based Models', ' Scalable Training', ' Bi-level Optimization', ' Interpretability']",8988,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 4, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}]",,
Learning Invariances via Neural Network Pruning,"['Invariance Learning', ' Neural Network Pruning', ' Auto ML', ' Contrastive Learning', ' Lazy Training', ' Representation Learning', ' Self-Supervised Learning', ' Computer Vision', ' Tabular Learning']",8987,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 5}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 3}]",,
In-Context Learning through the Bayesian Prism,"['In-context Learning', ' Transformers', ' Inductive Biases', ' Meta Learning', ' Language Modelling', ' Bayesian Inference']",8985,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 2}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}]",,
Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning,"['Trojan attacks', ' Parameter-efficient fine-tuning', ' Pre-trained language models']",8984,"[{'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
Harnessing Overlap in Blockwise Transformers for Near-Infinite Context,"['Language Model', ' Long Context Modeling', ' Reinforcement Learning', ' Unsupervised Reinforcement Learning']",8983,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}]",,
L-MBOP-E: Latent-Model Based Offline Planning with Extrinsic Policy Guided Exploration,"['reinforcement learning', ' offline planning', ' offline reinforcement learning', ' model-based reinforcement learning']",8979,"[{'mark': [1, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}]",,
Chain of Hindsight aligns Language Models with Feedback,"['Reinforcement Learning', ' Reinforcement Learning from Human Feedback', ' RLHF']",8976,"[{'mark': [3, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 4], 'rate': 6, 'confidence': 3}, {'mark': [4, 4, 3], 'rate': 6, 'confidence': 4}]",,
Bounding the Robustness and Generalization for Individual Treatment Effect,"['Individual Treatment Effect', ' Causal inference']",8972,"[{'mark': [2, 2, 1], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
GraphChef: Decision-Tree Recipes to Explain Graph Neural Networks,"['Graph Neural Networks', ' GNN', ' Explainability', ' Decision Trees']",8971,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
Safe Collaborative Filtering,"['recommender systems', ' collaborative filtering', ' scalability']",8970,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 2}]",,
MAP's not dead yet: Uncovering true language model modes by conditioning away degeneracy,"['language modeling', ' natural language generation', ' decoding algorithms']",8969,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}]",,
On Representation Complexity of Model-based and Model-free Reinforcement Learning,"['model-based and model-free RL', ' representation complexity', ' circuit complexity', ' approximation error']",8968,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 2}]",,
TPA-Gen: A Multi-modal Data Generative Method for Text and Physics-based Animation,"['Text to Physics-based Animation', ' Multimodal Generation']",8967,"[{'mark': [1, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 1, 'confidence': 3}]",,
Addressing Catastrophic Forgetting and Loss of Plasticity in Neural Networks,"['catastrophic forgetting', ' loss of plasticity', ' continual learning', ' streaming learning', ' online learning']",8965,"[{'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
Understanding Multimodal Instruction Format for In-context Learning,"['Visual instruction tuning', ' in-context learning', ' instruction format']",8964,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}]",,
Creative Robot Tool Use with Large Language Models,"['Large Language Model', ' Robot Learning', ' Tool Use']",8963,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 4, 2], 'rate': 5, 'confidence': 4}]",,
DFITE: Estimation of Individual Treatment Effect Using Diffusion Model,"['Individual Treatment Effect', ' Causal inference', ' diffusion model']",8962,"[{'mark': [1, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Hessian-Aware Bayesian Optimization for Decision Making Systems,"['Bayesian Optimization', ' Active Learning', ' Gaussian Process', ' Graphical Models', ' Bayesian', ' Probabilistic Methods', ' Hessian', ' High-dimensional optimization', ' Global optimization', ' Uncertainty', ' Optimization under Uncertainty']",8961,"[{'mark': [2, 1, 2], 'rate': 1, 'confidence': 4}, {'mark': [2, 1, 3], 'rate': 3, 'confidence': 3}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 1, 3], 'rate': 5, 'confidence': 2}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 2}]",,
A Good Learner can Teach Better: Teacher-Student Collaborative Knowledge Distillation,"['Knowledge Distillation', ' Meta-Knowledge Distillation', ' Policy-driven Knowledge Distillation', ' Large Language Models']",8958,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 1}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 6, 'confidence': 3}]",,
Unsupervised Representation Learning of Brain Activity via Bridging Voxel Activity and Functional Connectivity,"['Functional Connectivity', ' Graph Representation Learning', ' Anomaly Detection', ' Brain Representation Learning']",8957,"[{'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 3}]",,
Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making,"['fine-tuning', ' transformer-based language models', ' feature analysis', ' interpretation', ' clinical classification']",8956,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
What happens when you fine-tuning your model? Mechanistic analysis of procedurally generated tasks.,"['Fine-Tuning', ' Interpretability', ' Mechanisms']",8951,"[{'mark': [4, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 1, 3], 'rate': 3, 'confidence': 4}]",,
LLMatic: Neural Architecture Search via Large Language Models and Quality Diversity Optimization,"['Neural Architecture Search', ' Large Language Models', ' Quality Diversity Optimization']",8949,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 2, 3], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 1, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 3], 'rate': 3, 'confidence': 4}]",,
Combine and Compare: Graph Rationale Learning with Conditional Non-Rationale Sampling,"['Non-Rationale Sampling', ' Rationale representation learning', ' Graph Generalization']",8946,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Harnessing Discrete Representations for Continual Reinforcement Learning,"['reinforcement learning', ' continual reinforcement learning', ' discrete representations', ' representation learning']",8945,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Learning Dynamical Systems with Helmholtz-Hodge Decomposition and Gaussian Processes,"['Gaussian process', ' dynamical system', ' Helmholtz-Hodge decomposition']",8944,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 3}]",,
"MiniFold: Simple, Fast and Accurate Protein Structure Prediction","['protein', ' structure prediction', ' efficiency', ' hardware-optimization']",8942,"[{'mark': [3, 3, 3], 'rate': 3, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [1, 3, 2], 'rate': 3, 'confidence': 5}]",,
RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems,"['large language model', ' code completion', ' benchmark']",8936,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}]",,
Outliers Memorized Last: Trends in Memorization of Diffusion Models Based on Training Distribution and Epoch,"['Diffusion Models', ' Generative AI', ' Memorization']",8934,"[{'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}, {'mark': [2, 1, 2], 'rate': 1, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 4}]",,
Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective,"['Parametric Knowledge Transfer', ' Large Language Model']",8932,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 1}]",,
Generalization Error Analysis of Deep Physical Models With Latent Variables Trained on Trajectory Data,"['Hamiltonian Neural Networks', ' Generalization Error', ' AI for Science']",8931,"[{'mark': [4, 3, 4], 'rate': 8, 'confidence': 1}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 1}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}]",,
Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning,"['large language models (LLM)', ' feature learning', ' text attributed graphs (TAG)', ' graph neural networks (GNN)']",8930,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
GNN-based Probabilistic Supply and Inventory Predictions in Supply Chain Networks,"['Graph Neural Network', ' Supply Chain Network', ' Shipment Prediction', ' Inventory Prediction', ' Event Prediction']",8927,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 1, 'confidence': 4}]",,
Multi-Scale Generative Modeling in Wavelet Domain,['wavelet transform; score-based generative model; diffusion model; wavelet decomposition'],8926,"[{'mark': [1, 1, 1], 'rate': 1, 'confidence': 3}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
A Theoretical Explanation of Deep RL Performance in Stochastic Environments,"['reinforcement learning', ' effective horizon', ' RL theory', ' theory of reinforcement learning', ' instance-dependent bounds', ' empirical validation of theory']",8925,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}]",,
SMILE: Audio-Visual Speech Recognition with Siamese Masked Interaction Learning,"['Audio-Visual Speech Recognition', ' Siamese Masked Interaction Learning']",8924,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Investigating the Fairness of Large Language Models for Predictions on Tabular Data,"['Fairness', ' Social Biases', ' Large Language Models', ' In-Context Learning', ' Tabular Data', ' Trustworthy ML']",8922,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 3], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
SuRe: Improving Open-domain Question Answering of LLMs via Summarized Retrieval,"['question answering', ' large language model', ' retrieval']",8921,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Reinforced UI Instruction Grounding: Towards a Generic UI Task Automation API,['UI task automation; Instruction grounding; RL for computer vision'],8920,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
An Explainable AI-based Complementary Attention Mechanism for Detecting Identity Swaps,"['deep learning', ' fake content', ' fake faces', ' identity swap', ' scaled spatial attention', ' layer-integrated channel attention', ' LIME', ' deepfake', ' faceswap']",8919,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}]",,
Retrieval meets Long Context Large Language Models,"['Large Language Models', ' Long Context Window', ' Retrieval']",8917,"[{'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}]",,
From Child's Play to AI: Insights into Automated Causal Curriculum Learning,"['reinforcement learning', ' curriculum learning', ' cognitive science', ' cognitive development']",8916,"[{'mark': [3, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [2, 4, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}]",,
Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning,"['Diffusion Models', ' Large Language Models', ' Instruction-Finetuning', ' Reasoning']",8915,"[{'mark': [4, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [4, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Certified Robustness on Visual Graph Matching via Searching Optimal Smoothing Range,"['Visual graph matching (GM)', ' certified robustness', ' randomized smoothing', ' joint smoothing distribution']",8914,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
DAME: A Distillation Based Approach For Model-agnostic Local Explainability,"['Post-hoc Explainability', ' Interpretability', ' Saliency']",8912,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [4, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Neural Spectral Methods,"['Machine learning for PDE', ' spectral methods', ' neural network differentiation', ' spectral loss']",8910,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}]",,
Heterogeneous Decision Making towards Mixed Autonomy: When Uncertainty-aware Planning Meets Bounded Rationality,"['Mixed Autonomy', ' Reinforcement Learning', ' Bounded Rationality', ' Regret Analysis']",8909,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 2}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 4, 2], 'rate': 6, 'confidence': 2}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 2}]",,
Plasticity-Driven Sparsity Training for Deep Reinforcement Learning,"['Reinforcement Learning', ' Sparse Training', ' Network Plasticity']",8907,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [1, 3, 1], 'rate': 3, 'confidence': 5}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
ScoreFlow: Bridging Score and Neural ODE for Reversible Generative Modeling,"['Reversible generative modeling', ' Neural ODEs', ' Diffusion models', ' Image translation', ' Deep learning']",8904,"[{'mark': [2, 2, 1], 'rate': 1, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 1, 1], 'rate': 3, 'confidence': 4}]",,
Moral High Ground: A text-based games benchmark for moral evaluation,"['Text-based Games', ' LLM Evaluation', ' LLM Tuning']",8903,"[{'mark': [1, 1, 1], 'rate': 1, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 1, 'confidence': 4}]",,
Achieving Certified Robustness and Maintaining Clean Accuracy via Vanilla Model Guide,"['Adversarial examples', ' Certified Robustness']",8901,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 3], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}]",,
Generating Images in Context with Multimodal Large Language Models,"['Diffusion Models', ' Vision-Language', ' Image Generation']",8897,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}]",,
Learning to Explore for Stochastic Gradient MCMC,"['Bayesian Neural Networks', ' Meta-Learning', ' MCMC']",8896,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Selective Visual Representations Improve Convergence and Generalization for Embodied AI,"['Embodied-AI', ' Task-conditioned Representations', ' Visual Navigation', ' Reinforcement Learning']",8895,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
Fairness-Aware Attention for Contrastive Learning,"['Fairness', ' Contrastive Learning', ' Attention']",8894,"[{'mark': [3, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 2}]",,
High variance score function estimates help diffusion models generalize,"['generative modeling', ' score-based modeling', ' score matching', ' generalization', ' diffusion', ' theory']",8893,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
STARLING: Self-supervised Training of Text-based Reinforcement Learning Agent with Large Language Models,"['Interactive Fiction', ' Text-based Reinforcement Learning', ' Self-supervision']",8892,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Assessing Uncertainty in Similarity Scoring: Performance & Fairness in Face Recognition,"['Uncertainty', ' Face', ' Recognition', ' Performance', ' ROC', ' Fairness', ' Bootstrap']",8889,"[{'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Lightweight Language Model Calibration for Open-ended Question Answering with Varied Answer Lengths,"['calibration', ' hallucination', ' large language model']",8885,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}]",,
Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models,"['large language model', ' clinical nlp', ' synthetic data generation']",8883,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 5}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 4}]",,
FusionViT: Hierarchical 3D Object Detection via Lidar-Camera Vision Transformer Fusion,"['3D object detection', ' Camera-Lidar Fusion', ' Vision Transformer']",8882,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}]",,
Improving Generalization of Alignment with Human Preferences through Group Invariant Learning,"['alignment', ' language model', ' invariant learning']",8880,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 4, 4], 'rate': 1, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Learning and Forgetting Unsafe Examples in Large Language Models,['Large language models; Safety alignment; Neural networks forgetting'],8876,"[{'mark': [1, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 3}]",,
Deep-Learning Approaches for Optimized Web Accessibility: Correcting Violations and Enhancing User Experience,"['web accessibility', ' artificial intelligence', ' large language models', ' benchmark', ' GPT']",8875,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources,"['large language model', ' knowledge grounding']",8874,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Disentangled Heterogeneous Collaborative Filtering,"['Collaborative Filtering', ' Recommender System', ' Contrastive Learning']",8872,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 2}]",,
Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning,"['Reinforcement Learning', ' Model-based Reinforcement Learning', ' Offline Reinforcement Learning']",8871,"[{'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 2, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}]",,
Energy-based Automated Model Evaluation,"['Automated Model Evalutaion', ' Energy', ' Meta-distribution', ' Distribution shift']",8869,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}]",,
Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning,"['Large Language Models', ' In-context Learning', ' Natural Language Explanations']",8868,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 4], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Deceptive Fairness Attacks on Graphs via Meta Learning,"['graph learning', ' fairness', ' adversarial attacks']",8867,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 4], 'rate': 8, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [4, 2, 3], 'rate': 8, 'confidence': 3}]",,
What Matters to You? Towards Visual Representation Alignment for Robot Learning,"['Robot learning', ' Preference learning', ' Visual reward learning', ' Representation alignment']",8866,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}]",,
Village-Net clustering: A novel unsupervised manifold clustering method,"['Unsupervised clustering', ' Machine Learning', ' Random-Walks', ' Community detection']",8865,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}]",,
Zero-shot Clustering of Embeddings with Pretrained and Self-Supervised Learning Encoders,"['ssl', ' clustering']",8864,"[{'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [4, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 1, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
Genetic Algorithm for Curriculum Generation in Multi-Agent Reinforcement Learning,"['Reinforcement Learning', ' Curriculum Learning', ' Genetic Algorithm', ' Multiagent Reinforcement Learning']",8862,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}]",,
Correct and speak: accent reduction with minimum supervision,"['Voice Conversion', ' Spoken Language Models', ' speech tokenizer', ' In-context Learning']",8861,"[{'mark': [3, 2, 2], 'rate': 1, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
PINNACLE: PINN Adaptive ColLocation and Experimental points selection,"['Physics-informed Neural Networks', ' PINNs', ' adaptive training points selection']",8858,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
FedDA: Faster Adaptive Gradient Methods for Federated Constrained Optimization,"['Federated Learning', ' Adaptive Gradient Methods']",8857,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 1, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
A Differentiable Physical Simulation Framework for Soft Robots on Multiple-Task Learning,"['Differentiable Physics', ' Multiple-task Learning', ' Soft Robot Learning']",8856,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers,"['instruction optimization', ' prompt optimization', ' large language models']",8855,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Instructing Large Language Models to Identify and Ignore Irrelevant Conditions,"['Math Word Problem Solving', ' Multi-step Reasoning', ' Prompting', ' Chain-of-Thought', ' Large Language Models']",8853,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}]",,
Adaptive Expansion for Hypergraph Learning,"['Hypergraph', ' Hypergraph Expansion.']",8851,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
G2PTL: A Pre-trained Model for Delivery Address and its Applications in Logistics System,"['logistics', ' delivery address', ' pre-training', ' graph']",8849,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 5}]",,
BooookScore: A systematic exploration of book-length summarization in the era of LLMs,"['summarization', ' evaluation', ' long context', ' prompting', ' LLM']",8848,"[{'mark': [4, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [4, 4, 4], 'rate': 1, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
NP-GL: Extending Power of Nature from Binary Problems to Real-World Graph Learning,"['graph learning', ' nature-powered computing', ' dynamic physical system']",8845,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
Transformer-Based Large Language Models Are Not General Learners: A Universal Circuit Perspective,"['Large Language Model', ' Transformer', ' Universal Circuit']",8842,"[{'mark': [4, 2, 1], 'rate': 1, 'confidence': 5}, {'mark': [2, 1, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Posterior Sampling via Langevin Monte Carlo for Offline Reinforcement Learning,"['reinforcement learning', ' offline RL', ' posterior sampling']",8841,"[{'mark': [3, 2, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 6, 'confidence': 4}]",,
Efficient Point Cloud Matching for 3D Geometric Shape Assembly,"['Geometric shape assembly', ' High-dimensional feature transform', ' Correlation aggregation', ' Proxy Match Transform']",8840,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 2}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 2}, {'mark': [3, 1, 2], 'rate': 5, 'confidence': 4}]",,
From Deterministic to Probabilistic World: Balancing Enhanced Doubly Robust Learning for Debiased Recommendation,"['Recommender system', ' Selection bias', ' Doubly robust', ' Probabilistic model']",8839,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
FLOOD SIMULATION WITH PHYSICS-INFORMED MESSAGE PASSING,"['Physics-informed GNN', ' flood simulation', ' PDEs']",8838,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}]",,
PACIA: Parameter-Efficient Adapter for Few-Shot Molecular Property Prediction,"['molecular property prediction', ' few-shot learning', ' hypernetwork']",8837,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 2}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}]",,
Provable Repair of Vision Transformers: Last Layer is All You Need,"['neural network repair', ' vision transformers', ' formal guarantees']",8836,"[{'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}]",,
LLMZip: Lossless Text Compression using Large Language Models,"['Large Language Models', ' Transformers', ' Compression', ' Arithmetic Coding', ' Zip', ' Lossless Text Compression']",8834,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}]",,
VMFTransformer: An Angle-Preserving and Auto-Scaling Machine for Multi-horizon Probabilistic Forecasting,"['time series forecasting', ' probabilistic forecasting']",8832,"[{'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}]",,
AdaO2B: Adaptive Online to Batch Conversion for Out-of-Distribution Generalization,"['online to batch conversion', ' out-of-distribution (OOD) generalization', ' streaming applications', ' bandit']",8830,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}]",,
Leveraging Previous Tasks in Optimizing Risk Measures with Gaussian Processes,"['risk measure', ' value-at-risk', ' conditional value-at-risk']",8829,"[{'mark': [2, 1, 2], 'rate': 5, 'confidence': 3}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}]",,
Canonpipe: Data Debugging with Shapley Importance over Machine Learning Pipelines,"['data debugging', ' data valuation', ' shapley value', ' machine learning pipelines']",8826,"[{'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
MoAT: Multi-Modal Augmented Time Series Forecasting,"['time series', ' multi-modal', ' augmentation', ' forecasting']",8825,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}]",,
Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances,"['scientific computing', ' data-driven algorithm design', ' online learning', ' multi-armed bandits', ' contextual bandits', ' numerical analysis', ' learning-augmented algorithms', ' algorithms with predictions']",8824,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 2}]",,
Group Robustness via Adaptive Class-Specific Scaling,"['group robustness', ' debiasing']",8822,"[{'mark': [1, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
CT++: Complementary Co-Training for Semi-Supervised Semantic Segmentation,"['semi-supervised learning', ' semantic segmentation']",8819,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 5}]",,
Towards Better Evaluation of GNN Expressiveness with BREC Dataset,"['GNN', ' Expressiveness', ' Datasets']",8818,"[{'mark': [3, 2, 2], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}]",,
Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning,"['Offline reinforcement learning', ' instance-dependent', ' least-squares value iteration']",8813,"[{'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
EMP-SSL: Towards Self-Supervised Learning in One Training Epoch,"['Self-supervised Learning', ' Online Learning']",8812,"[{'mark': [2, 2, 3], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}]",,
Nuisance-Robust Weighting Network for End-to-End Causal Effect Estimation,"['causal inference', ' pessimism', ' adversarial training']",8811,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 2}]",,
Skill-Mix: a Flexible and Expandable Family of Evaluations for AI Models,"['Large language model', ' skill evaluation', ' LLM benchmark', ' emergence']",8809,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}]",,
OrthCaps: An Orthogonal CapsNet with Sparse Attention Routing and Pruning,"['Deep Learing', ' Capsule Network', ' Orthogonality', ' Pruning']",8808,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 1, 2], 'rate': 1, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 6, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}]",,
A Quadratic Synchronization Rule for Distributed Deep Learning,"['distributed training', ' Local SGD', ' local gradient methods', ' generalization', ' implicit bias', ' sharpness']",8805,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 2}]",,
ArchLock: Locking DNN Transferability at the Architecture Level with a Zero-Cost Binary Predictor,['Defense; DNN Transferability; Neural Architecture Search'],8804,"[{'mark': [4, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}]",,
Referring Expression Matters: Multi-referring Feature Aggregation for Referring Video Object Segmentation,"['Referring Video Object Segmentation', ' Referring expression segmentation', ' Multimodal representation earning']",8803,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Local-Forward: Towards Biological Plausibility in Deep Reinforcement Learning,"['biological plausibility', ' deep Q-learning', ' TD learning']",8802,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 3, 1], 'rate': 1, 'confidence': 4}, {'mark': [1, 3, 2], 'rate': 3, 'confidence': 4}]",,
Exploiting Code Symmetries for Learning Program Semantics,"['Code Symmetry', ' Program Representation', ' Code Modeling', ' Group-Equivariance', ' Robustness']",8801,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 3], 'rate': 3, 'confidence': 5}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}]",,
Weight Uncertainty in Individual Treatment Effect,"['Individual Treatment Effect', ' Causal inference', ' Bayesian inference']",8800,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 1], 'rate': 1, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}]",,
Latent Shattering: Turning Unconditional Pretrained Generators Into Conditional Models By Imposing Latent Structure,"['generative models', ' generative modeling', ' GANs', ' VAEs']",8799,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 4, 3], 'rate': 5, 'confidence': 3}]",,
Efficient Large Language Models Fine-Tuning on Graphs,"['Graph Neural Networks', ' Large Language Models', ' Scalability', ' Label Efficiency']",8798,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
On information dropping and oversmoothing in graph neural networks,['Oversmoothing'],8797,"[{'mark': [3, 2, 3], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
HuRef: HUman-REadable Fingerprint  for Large Language Models,"['Large Language Models (LLMs)', ' Model Identification', ' Fingerprinting']",8795,"[{'mark': [4, 4, 4], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Adaptive Memory Module for Sequential Planning and Reasoning,"['Adaptive computation', ' Memory', ' Planning', ' Reasoning', ' Offline RL']",8794,"[{'mark': [1, 1, 1], 'rate': 1, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 3}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 4}]",,
Projected Subnetworks Scale Adaptation,"['adaptation', ' subnetworks']",8793,"[{'mark': [1, 2, 2], 'rate': 1, 'confidence': 4}, {'mark': [1, 1, 2], 'rate': 1, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}]",,
Multiple Modes for Continual Learning,['continual learning'],8792,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Robust Graph Neural Networks via Unbiased Aggregation,"['Graph Neural Networks', ' Adversarial Attack', ' Unbiased Graph Estimator']",8788,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 4], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 2, 2], 'rate': 3, 'confidence': 4}]",,
Flashback: Understanding and Mitigating Forgetting in Federated Learning,"['Federated Learning', ' Forgetting', ' Knowledge Distillation', ' Deep Learning', ' Continual Learning']",8786,"[{'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
Efficient Backdoor Mitigation in Federated Learning with Contrastive Loss,['Backdoor Defense; Federated Learning; Contrastive Loss'],8785,"[{'mark': [3, 1, 1], 'rate': 1, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Turing Complete Transformers: Two Transformers Are More Powerful Than One,"['transformers', ' computational complexity', ' computation', ' generalization', ' agents', ' multi-model']",8781,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 3}]",,
PolyFormer: Scalable Graph Transformer via Polynomial Attention,"['Graph Transformer', ' Graph Filter', ' Graph Neural Network']",8779,"[{'mark': [2, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
A Data-Centric Approach for Financial Large Language Models with Abductive Augmentation Reasoning,"['Data centic', ' LLM', ' Finance']",8778,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Cost Adaptive Recourse Recommendation by Adaptive Preference Elicitation,"['Algorithmic Recourse', ' Preference Elicitation']",8776,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [4, 4, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}]",,
"Multi-Method Self-Training: Improving Code Generation With Text, And Vice Versa","['self-training', ' large langauge models', ' finetuning', ' bootstrapping', ' multi-modal']",8775,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 1, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}]",,
Improving Language Models with Advantage-based Offline Policy Gradients,"['Reinforcement Learning', ' Natural Language Generation', ' Offline Policy Gradients']",8769,"[{'mark': [2, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
RECOMP: Improving Retrieval-Augmented LMs with Context Compression and Selective Augmentation,"['retrieval augmented language model', ' language modeling', ' question answering', ' summarization', ' distillation']",8767,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 8, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 4, 3], 'rate': 6, 'confidence': 4}]",,
Federated Generalization via Information-Theoretic Distribution Diversification,"['Federated learning', ' Information theory', ' Generalization theory', ' Learning theory']",8766,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 3}]",,
Defender of privacy and fairness: tiny but reversible generative model via mutually collaborative knowledge distillation,"['Privacy protection', ' and knowledge distillation.']",8765,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}]",,
Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions,"['zero-shot classification', ' prompting', ' generative classification', ' label descriptions']",8763,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
A graph transformer for symbolic regression,"['attention mechanism', ' graph transformer', ' symbolic regression']",8761,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 4}]",,
Learning Latent Structural Causal Models,"['Bayesian Causal Discovery', ' Latent variable models']",8760,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 3, 2], 'rate': 5, 'confidence': 3}]",,
Flexible Diffusion for Graph Neural Networks,['Graph Neural Network; Diffusion; Smoothing Label'],8759,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}]",,
In-Context Learning Dynamics with Random Binary Sequences,"['In-Context Learning', ' Large Language Models', ' Interpretability', ' Computational Cognitive Science']",8758,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 1, 3], 'rate': 3, 'confidence': 4}]",,
Dynamic Representation of Optimal Transport via Ensemble Systems,['Optimal transport; ensemble systems; moment kernel representation'],8757,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 3, 1], 'rate': 3, 'confidence': 4}]",,
Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking,"['grokking', ' implicit bias', ' margin', ' kernel', ' training dynamics', ' generalization']",8756,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [1, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation,"['Recommender system', ' Selection Bias', ' Neighborhood effect']",8755,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
GraphECL: Towards Efficient Contrastive Learning for Graphs,['Graph Neural Networks'],8753,"[{'mark': [2, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}]",,
An Implicit Watermark Framework for Adversary Identification,"['Adversarial attack', ' Forensic investigation']",8752,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 3}]",,
PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization,"['Large Language Models', ' Expert-level Prompt Optimization', ' Strategic Planning']",8751,"[{'mark': [2, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}]",,
Understanding Retrieval Augmentation for Long-Form Question Answering,"['Question Answering', ' Retrieval', ' Retrieval Augmented Generation', ' Long-Form Question Answering', ' Attribution', ' NLP', ' QA']",8750,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning,"['data pruning', ' dataset distillation', ' random sampling', ' corset selection', ' data-efficient learning']",8746,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 5}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs,"['Bias', ' Fairness', ' LLM', ' Reasoning', ' Persona']",8745,"[{'mark': [3, 4, 3], 'rate': 8, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Enhancing Instance-Level Image Classification with Set-Level Labels,"['set-level labels', ' fast excess risk rate', ' representation learning', ' few-shot learning']",8741,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}]",,
Rotation has two sides: Evaluating Data Augmentation for Deep One-class Classification,"['self-supervised learning', ' deep one-class cilassification']",8740,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}]",,
QuantEase: Optimization-based Quantization for Large Language Models,"['Post-training Quantization', ' Quantization', ' Large Language Models']",8739,"[{'mark': [4, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 4], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
On the Power of Multitask Representation Learning with Gradient Descent,"['representation learning', ' multi-task learning', ' gradient descent', ' generalization']",8738,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Pushing Boundaries: Mixup's Influence on Neural Collapse,"['mixup', ' neural collapse', ' unconstrained features model']",8736,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 1, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
sRGB Real Noise Modeling via Noise-Aware Sampling with Normalizing Flows,"['sRGB real noise modeling', ' Normalizing flow', ' Low-level vision']",8735,"[{'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}]",,
Open-Ended Learning in General-Sum Games: The Role of Diversity in Correlated Equilibrium,"['Correlated Equilibrium', ' Policy Diversity', ' PSRO']",8733,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}]",,
On Local Equilibrium in Non-Concave Games,"['non-concave games', ' learning in games', ' no-regret algorithms', ' local equilibrium']",8732,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [4, 3, 4], 'rate': 1, 'confidence': 4}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 2, 1], 'rate': 3, 'confidence': 3}]",,
A Benchmark on Robust Semi-Supervised Learning in Open Environments,['Semi-Supervised Learning; Robustness; Open Environments'],8731,"[{'mark': [3, 3, 4], 'rate': 8, 'confidence': 5}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 5}, {'mark': [3, 4, 4], 'rate': 8, 'confidence': 5}]",,
Uncertainty-aware Graph-based Hyperspectral Image Classification,"['Uncertainty Quantification', ' Graph', ' Hyperspectral Image Classification']",8730,"[{'mark': [4, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 2}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
Zero-shot Human-Object Interaction Detection via Conditional Multi-Modal Prompts,"['Human Object Interaction Detection', ' Zero-shot']",8729,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}]",,
Pick and Adapt: An Iterative Approach for Source-Free Domain Adaptation,"['representation learning', ' domain adaptation']",8728,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
XplainLLM: A QA Explanation Dataset for Understanding LLM Decision-Making,"['Dataset', ' Explanation', ' XAI', ' Language Model']",8727,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Generative Adversarial Equilibrium Solvers,"['Game Theory', ' Amortized Optimization', ' Generalized Nash equilibrium', ' Economics']",8725,"[{'mark': [4, 4, 4], 'rate': 1, 'confidence': 5}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [4, 2, 3], 'rate': 6, 'confidence': 4}]",,
"Rethinking Counterfactual Fairness: On Which Individuals to Enforce, and How?","['counterfactual fairness', ' fairness', ' causal effect', ' principal stratification']",8724,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}]",,
Learning Boolean functions with neural networks,"['Deep Learning Theory', ' Learning Theory', ' Gradient Descent', ' Analysis of Boolean functions']",8722,"[{'mark': [2, 1, 3], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}]",,
Emergent Corpus Pretraining Benefits Vision Language Modeling,"['emergent communication', ' vision language pretraining', ' corpus transfer']",8721,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}]",,
Rethinking Test-time Likelihood: The Likelihood Path Principle and Its Application to OOD Detection,"['outlier detection', ' ood', ' out-of-distribution', ' anomaly detection', ' variational autoencoder', ' VAE']",8717,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 2}, {'mark': [2, 1, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 6, 'confidence': 2}]",,
Generative Adversarial Inverse Multiagent Learning,"['Inverse Game Theory', ' Inverse Multiagent Reinforcement Learning']",8714,"[{'mark': [2, 2, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 2}, {'mark': [4, 3, 4], 'rate': 1, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}]",,
Learning to Play Atari in a World of Tokens,"['model-based reinforcement learning', ' transformer', ' vector quantised-variational autoencoder']",8712,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}]",,
Do Pre-trained Transformers Really Learn In-context by Gradient Descent?,"['In-context learning', ' gradient descent', ' large language models']",8711,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Fairness-enhancing mixed effects deep learning improves fairness on in- and out-of-distribution clustered (non-iid) data,"['Fairness-enhancing models', ' adversarial debiasing', ' mixed effects deep learning', ' out of distribution generalization']",8710,"[{'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
FedOD: Federated Outlier Detection via Neural Approximation,"['outlier detection', ' federated learning']",8709,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 4}]",,
Robustness Evaluation of Proxy Models against Adversarial Optimization,"['proxy gaming', ' reward hacking', ' specification gaming', ' misspecification', ' robustness', ' adversarial robustness', ' adversarial attacks', ' alignment', ' ai safety']",8708,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 4], 'rate': 6, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 3}]",,
Multi-Objective Multi-Solution Transport,['Multi-Objective Optimization'],8707,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 1, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 3, 3], 'rate': 1, 'confidence': 5}]",,
FORKS: Fast Second-Order Online Kernel Learning using Incremental Sketching,"['Online Kernel Learning', ' Second-Order Method', ' Randomized Sketch']",8706,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 1, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 2}]",,
Graph Transformers on EHRs: Better Representation Improves Downstream Performance,"['transformers', ' graph neural networks', ' electronic health records']",8705,"[{'mark': [4, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 8, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
O3D: Offline Data-driven Discovery and Distillation for Sequential Decision-Making with Large Language Models,"['Offline In-Context Learning', ' Large Language Model Agent', ' Sequential Decision-Making']",8704,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Counterfactual Fairness from Partially DAGs: A General Min-Max Optimization Framework,"['fairness', ' counterfactual fairness', ' DAG', ' partially DAG']",8703,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 1}, {'mark': [1, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}]",,
On the Scalability and Memory Efficiency of Semidefinite Programs  for Lipschitz Constant Estimation of Neural Networks,"['Semidefinite programming', ' Lipschitz constant', ' Deep learning']",8702,"[{'mark': [3, 3, 4], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 5, 'confidence': 4}]",,
Efficient Recomputation of Marginal Likelihood upon Adding Training Data in Gaussian Processes and Simulator Fusion,"['Gaussian Process', ' bias variance tradeoff', ' marginal likelihood', ' model selection']",8700,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}]",,
Preconditioning for Physics-Informed Neural Networks,"['physics-informed neural network', ' partial differential equation', ' condition number', ' application']",8699,"[{'mark': [4, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [1, 3, 1], 'rate': 1, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
On the Role of Discrete Tokenization in Visual Representation Learning,"['Self-supervised learning', ' Masked image modeling', ' Discrete visual token']",8697,"[{'mark': [4, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 2}]",,
Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models,"['LLMs', ' VLMs', ' Benchmark']",8696,"[{'mark': [4, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech,"['text-to-speech', ' speech synthesis', ' neural audio codec']",8692,"[{'mark': [4, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 4, 4], 'rate': 8, 'confidence': 4}]",,
"AceGPT, Localizing Large Language Models in Arabic","['AceGPT', ' Arabic', ' Large Language Model', ' Localization']",8690,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
Improving Large Language Model Fine-tuning for Solving Math Problems,"['Math Problem Solving', ' Large Language Models']",8689,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels,"['Depthwise Convolutions', ' Explainability', ' Neuroscience', ' Computer Vision', ' ConvNext']",8688,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models,"['XAI', ' Unsupervised node representation learning', ' Counterfactual Explanations']",8687,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}]",,
Reinforcement Learning for Large Group Systems using Hierarchical Kernel Representations,"['Reinforcement learning', ' Group Systems', ' Control Theory']",8686,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}]",,
Optimizing Interpersonal Communication by Simulating Audiences with Large Language Models,"['Communication', ' Interpersonal Relationships', ' Large Language Model Applications', ' Agent Simulations', ' Generative Agents']",8685,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}]",,
Enhancing Neural Network Transparency through Representation Analysis,"['transparency', ' interpretability', ' monitoring', ' alignment', ' ML safety']",8684,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 2}, {'mark': [1, 1, 3], 'rate': 3, 'confidence': 3}]",,
Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations,"['Instruction tuning', ' Large language models', ' BERT family', ' Natural language generation']",8680,"[{'mark': [4, 4, 4], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
SGOOD: Substructure-enhanced Graph-Level Out-of-Distribution Detection,"['out-of-distribution detection', ' graph classification']",8679,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Jorge: Approximate Preconditioning for GPU-Efficient Second-Order Optimization,"['second order optimizer', ' hardware efficiency', ' approximate preconditioning']",8677,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 4, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 4, 3], 'rate': 5, 'confidence': 5}]",,
Imitation Bootstrapped Reinforcement Learning,"['reinforcement learning', ' robotics', ' continuous control']",8676,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}]",,
Exploring the Promise and Limits of Real-Time Recurrent Learning,"['recurrent neural networks', ' real-time recurrent learning', ' online recurrent learning', ' reinforcement learning', ' actor-critic', ' policy gradients']",8675,"[{'mark': [3, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [4, 4, 2], 'rate': 6, 'confidence': 3}, {'mark': [4, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
Attribute-Enhanced Similarity Ranking for Sparse Link Prediction,"['Link Prediction', ' Graph Neural Networks', ' Graph Learning', ' Network Science']",8672,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Measuring Graph Similarity Using Transfer Cost of Forster Distributions,"['Graph similarity', ' Foster distributions']",8671,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [4, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}]",,
TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting,['Forecasting; Time Series; Large Language Model'],8670,"[{'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}]",,
Scaling physics-informed hard constraints with mixture-of-experts,"['Physics-Informed Machine Learning', ' PDEs', ' differentiable optimization', ' neural networks', ' mixture of experts', ' constrained optimization']",8669,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Uncovering Causal Variables in Transformers Using Circuit Probing,"['Interpretability', ' Analysis', ' NLP', ' Pruning']",8667,"[{'mark': [2, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [1, 2, 1], 'rate': 1, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining,"['Large Language Models', ' Pretraining', ' Retrieval', ' Instruction Tuning']",8665,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}]",,
Discrimination-free Pricing with Privatized Sensitive Attributes,"['fairness', ' privatized sensitive attributes', ' privacy', ' insurance pricing', ' local differential privacy', ' noise estimation', ' transparency']",8664,"[{'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 2}]",,
Recursive Score Estimation Accelerates Diffusion-Based Monte Carlo,"['posterior sampling', ' non-isopermetric conditions', ' Monte Carlo', ' SDE']",8663,"[{'mark': [3, 4, 2], 'rate': 5, 'confidence': 3}, {'mark': [4, 2, 4], 'rate': 6, 'confidence': 4}, {'mark': [4, 2, 4], 'rate': 8, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 2}]",,
Ensemble Systems Representation for Function Learning over Manifolds,"['Function learning', ' dynamical systems', ' control theory']",8662,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 1, 'confidence': 3}]",,
Generalization in diffusion models arises from geometry-adaptive harmonic representation,"['diffusion models', ' memorization', ' generalization', ' inductive bias', ' curse of dimensionality', ' denoising', ' geometry-adaptive harmonic basis']",8660,"[{'mark': [4, 4, 4], 'rate': 8, 'confidence': 3}, {'mark': [4, 4, 4], 'rate': 1, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
Simplicity Bias of SGD via Sharpness Minimization,"['Sharpness minimization', ' Implicit bias', ' SGD', ' Simplicity Bias', ' trace of Hessian regularizer']",8659,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}]",,
Structural Fairness-aware Active Learning for Graph Neural Networks,"['Active Learning', ' Graph Neural Networks', ' Structural Fairness']",8658,"[{'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [1, 2, 1], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Neural-Symbolic Recursive Machine for Systematic Generalization,"['Neuro-symbolic AI', ' Systematic Generalization', ' Compositional Generalization']",8657,"[{'mark': [3, 4, 2], 'rate': 6, 'confidence': 4}, {'mark': [4, 2, 3], 'rate': 8, 'confidence': 2}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-Image Generation,"['text-to-image generation', ' text-to-image evaluation', ' Davidsonian semantics', ' large language models', ' scene graphs', ' visual question answering', ' question generation', ' benchmark']",8654,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 3}]",,
Deep Neural Networks Can Learn Generalizable Same-Different Visual Relations,"['abstract relations', ' vision transformers', ' visual concept learning', ' out-of-distribution generalization', ' same-different relation', ' equality relation', ' inductive biases']",8652,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
In-context Curriculum for Mathematical Reasoning in Small Language Models,"['small language models', ' mathematical reasoning', ' in-context learning', ' specialization', ' Chain-of-thought prompting', ' deep learning', ' transformers', ' large language models']",8651,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
The Consensus Game: Language Model Generation via Equilibrium Search,"['language models', ' decoding', ' planning', ' game theory']",8650,"[{'mark': [4, 3, 4], 'rate': 1, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Vector Quantized Representations for Efficient Hierarchical Delineation of Behavioral Repertoires,"['animal behavior', ' neuroscience', ' unsupervised unit discovery']",8649,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 2}]",,
STRUCTDROP: A STRUCTURED RANDOM ALGORITHM TOWARDS EFFICIENT LARGE-SCALE GRAPH TRAINING,"['Efficient Training', ' Randomized Algorithm']",8648,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 4], 'rate': 6, 'confidence': 3}]",,
Talking Models: Distill Pre-trained Knowledge to Downstream Models via Interactive Communication,"['Knowledge Distillation', ' Interactive Communication', ' Distill Foundation Model']",8647,"[{'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 5, 'confidence': 2}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}]",,
Chain of Thought Empowers Transformers to Solve Inherently Serial Problems,"['Chain of thought', ' language modeling', ' circuit complexity', ' deep learning theory']",8645,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 2}, {'mark': [3, 2, 4], 'rate': 3, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 2}, {'mark': [4, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 5}]",,
Tractable MCMC for Private Learning with Pure and Gaussian Differential Privacy,"['Pure Differential Privacy', ' Monte Carlo sampling', ' Gaussian Differential Privacy', ' Exponential Mechanism']",8643,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}]",,
X-InstructBLIP: A Framework for aligning X-Modal instruction-aware representations to LLMs and Emergent Cross-modal Reasoning,"['multimodal language model', ' instruction aware representations', ' multitask', ' zero-shot', ' 3d', ' video', ' audio', ' image', ' language', ' frozenllm', ' alignment']",8642,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 5}]",,
Efficient Multi-task Reinforcement Learning via Selective Behavior Sharing,"['Multi-task Reinforcement Learning', ' Behavior sharing']",8641,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
Optimal Sketching for Residual Error Estimation for Matrix and Vector Norms,"['Sketching', ' Residual error', ' Low-rank approximation', ' sparse recovery']",8639,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Reverse Diffusion Monte Carlo,"['Posterior Sampling', ' Multi-modal sampling']",8638,"[{'mark': [2, 2, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [3, 2, 1], 'rate': 1, 'confidence': 4}]",,
LLM-based Stock Market Trend Prediction,"['Stock Market Trend Prediction', ' Moving Averages', ' Options Volume', ' Market Volatility', ' LLM', ' LSTM Sentiment Analysis', ' Demand & Supply Dependency tree', ' Multi Layer Neural Networks']",8637,"[{'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}]",,
On the Dynamics of Learning Time-Aware Behavior with RNNs,"['recurrent neural networks', ' latent temporal features', ' developmental interpretability', ' phase transitions', ' dynamical systems theory']",8635,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 3, 'confidence': 2}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}]",,
Can LLMs Effectively Leverage Graph Structural Information: When and Why,"['Large Language Model', ' Graph', ' Multimodality', ' Data Leakage', ' Homophily']",8633,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}]",,
Improving Branching in Neural Network Verification with Bound Implication Graph,"['neural network verification', ' adversarial robustness', ' branch and bound']",8632,"[{'mark': [4, 4, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}]",,
Counting Graph Substructures with Graph Neural Networks,"['graph neural networks', ' expressive power', ' representation learning', ' subgraph isomorphism', ' cliques', ' cycles', ' motifs', ' substructures', ' count', ' message-passing']",8631,"[{'mark': [3, 1, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 5, 'confidence': 3}]",,
Optimal algorithms for group distributionally robust optimization and beyond,"['Distributionally robust optimization', ' Convex optimization', ' Fairness']",8630,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 3], 'rate': 5, 'confidence': 4}]",,
Dynamic Mode Decomposition-inspired Autoencoders for Reduced-order Modeling and Control of PDEs : Theory and Design,"['PDEs', ' Autoencoders', ' Reduced-order modeling', ' Control', ' Dynamic mode decomposition']",8629,"[{'mark': [2, 2, 2], 'rate': 6, 'confidence': 3}, {'mark': [1, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 5, 'confidence': 3}]",,
Exploiting Action Distances for Reward Learning from Human Preferences,"['Preference based Reinforcement Learning', ' Human Aware AI', ' Reward Learning']",8628,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}]",,
Is the Glass Half-Empty or Half-Full? A Mixture-Of-Tasks Perspective on Missing Modality,"['missing modality', ' modality competition', ' multimodal learning', ' multimodal fusion']",8627,"[{'mark': [2, 3, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 2}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 3}]",,
Text2Data: Low-Resource Data Generation with Textual Control,"['low resource', ' text-to-data generation']",8626,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [4, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 2}]",,
On the Effect of Defection in Federated Learning and How to Prevent It,"['Incentive Design', ' Optimization', ' Robustness', ' Federated Learning', ' Fairness', ' Adaptive Optimization']",8625,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}]",,
DIG-MILP: a Deep Instance Generator for Mixed-Integer Linear Programming with Feasibility Guarantee,"['mixed-integer linear programming', ' generative model']",8623,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}]",,
Analyzing Complex Interdependencies in Financial Markets: A Neural Network-Based Approach for News Impact Assessment,"['Stock Market Trend Prediction', ' Market Volatility', ' LSTM Sentiment Analysis', ' Demand & Supply Dependency tree', ' Multi Layer Neural Networks', ' Learning Statistics', ' Regressions', ' Depth-First-Search', ' Advance Web Scraping', ' Balance Sheet']",8617,"[{'mark': [1, 1, 1], 'rate': 1, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 1, 'confidence': 5}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}]",,
What's the Magic Word? A Control Theory of LLM Prompting,"['language models', ' control theory', ' LLMs', ' prompt optimization', ' alignment', ' mechanistic interpretability']",8616,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
End-to-end Story Plot Generator,"['automatic story generation', ' end-to-end generator', ' reader-specific reward model', ' rlhf']",8614,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 4, 3], 'rate': 5, 'confidence': 3}]",,
Generalization Guarantees of Gradient Descent for Multi-Layer Neural Networks,"['learning theory', ' generalization analysis', ' gradient descent', ' stability']",8613,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Are Models Biased on Text without Gender-related Language?,"['Large language models', ' bias evaluation', ' gender bias', ' gender co-occurring words', ' gender-invariant', ' pretraining data statistics']",8612,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
Decoupled Actor-Critic,"['Continuous Control', ' Reinforcement Learning', ' Actor-Critic']",8610,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}]",,
Unleashing the Potential of LLMs for Quantum Computing: A Study in Quantum Architecture Design,"['Large Language Models', ' Quantum Computing', ' Variational Quantum Algorithms']",8609,"[{'mark': [2, 3, 1], 'rate': 1, 'confidence': 5}, {'mark': [1, 2, 1], 'rate': 1, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
How do skip connections affect Graph Convolutional  networks  with graph sampling? A theoretical analysis on generalization,"['graph neural network (GNN)', ' skip-connection', ' graph samping', ' generalization analysis', ' deep learning theory']",8606,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 2}, {'mark': [4, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 5, 'confidence': 5}]",,
PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning,"['language-based planning', ' procedural/script knowledge', ' distillation', ' large language models', ' decoding-time algorithm']",8605,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction,"['atomic property prediction', ' pre-training', ' 3D atomic pre-training', ' graph neural networks', ' multi-task learning', ' molecules', ' materials']",8604,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}]",,
"Patch Ranking Map: Explaining Relations among Top-Ranked Patches, Top-Ranked Features and Decisions of Convolutional Neural Networks for Image Classification","['convolutional neural networks', ' deep learning', ' feature selection', ' image classification', ' optimization']",8603,"[{'mark': [1, 2, 1], 'rate': 1, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 1, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}]",,
The Fine-Grained Chip Placement with Hybrid Action Spaces and Feature Fusion,"['Deep Reinforcement Learning', ' Chip Placement', ' hybrid action space', ' feature fusion']",8602,"[{'mark': [1, 1, 1], 'rate': 1, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 1, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}, {'mark': [1, 1, 2], 'rate': 1, 'confidence': 5}]",,
AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents,"['Meta-RL', ' Generalization', ' Long-Term Memory', ' Transformers']",8600,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 4], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 2], 'rate': 8, 'confidence': 3}, {'mark': [3, 2, 4], 'rate': 6, 'confidence': 4}]",,
UniAudio: An  Audio Foundation Model Toward Universal Audio Generation,"['Audio Language Model', ' Universal Audio Generation', ' Foundation Model', ' Zero-shot']",8597,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 1], 'rate': 1, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [4, 4, 4], 'rate': 1, 'confidence': 3}]",,
Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets,"['graph neural networks', ' Datasets', ' molecules', ' molecular graphs', ' Quantum', ' Multi-task', ' foundation model']",8594,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 2}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}]",,
ABKD: Graph Neural Network Compression with Attention-Based Knowledge Distillation,"['Graph Neural Networks', ' Compression', ' Knowledge Distillation']",8591,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Llamas Know What GPTs Don't Show: Surrogate Models for Selective Classification,"['calibration', ' uncertainty estimation', ' large language models']",8590,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
Independent-Set Design of Experiments for Estimating Treatment and Spillover Effects under Network Interference,"['Causal inference', ' Design of experiments', ' Interference', ' Random graph', ' Spillover effects', ' Treatment effects', ' Potential outcomes']",8589,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [4, 2, 2], 'rate': 5, 'confidence': 4}]",,
FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores,"['convolutions', ' GPUs', ' hardware-efficient algorithms', ' long context', ' fast fourier transform', ' I/O awareness']",8584,"[{'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 5}]",,
Towards Understanding The Winner-Take-Most Behavior Of Neural Network Representations,"['deep learning', ' neuron representations']",8583,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 1, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
SHINE: Shielding Backdoors in Deep Reinforcement Learning,"['deep reinforcement learning', ' trojan backdoor', ' explanation']",8582,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 2}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Semi-Supervised Learning of Tree-Based Models Using Uncertain Interpretation of Data,"['semi-supervised learning', ' decision tree', ' tree ensemble', ' random forest']",8579,"[{'mark': [2, 4, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}]",,
Parameter-Efficient Tuning Helps Language Model Alignment,['Alignment; Large Lanugage Models; Controllable Generations'],8577,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
MIMIC: Masked Image Modeling with Image Correspondences,"['Data curation techniques', ' Masked Image Modeling', ' Dense vision tasks', ' Large scale pretraining', ' Self supervised learning', ' Datasets']",8576,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Transformer-VQ: Linear-Time Transformers via Vector Quantization,"['Transformer', ' Transformer Decoder', ' Decoder-Only Transformer', ' Natural Language Processing', ' NLP', ' Vector Quantization', ' VQ', ' K-Means', ' Clustering', ' Causal Attention', ' Autoregressive Attention', ' Efficient Attention', ' Linear-Time Attention', ' Autoregressive Modeling', ' Generative Modeling', ' Gated Attention', ' Compressive Attention', ' Kernelized Attention', ' Kernelizable Attention', ' Hierarchical Attention', ' Segment-Level Recurrent Attention', ' Long-Context Modeling', ' Long-Range Modeling', ' Long-Range Dependencies', ' Long-Term Dependencies', ' Cached Attention', ' Shift-Equivariant Attention']",8575,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 2}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Can adversarial samples benefit few-shot unsupervised implicit neural shape representation learning ?,"['3D reconstruction', ' Implicit Neural Representations']",8574,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 5}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
Understanding Contrastive Learning Through the Lens of Margins,"['Contrastive learning', ' Margins', ' Self-supervised learning']",8573,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}]",,
Efficient Model-Agnostic Multi-Group Equivariant Networks,"['Group equivariant networks', ' efficient equivariant networks', ' large equivariant networks']",8572,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 1, 'confidence': 2}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}]",,
Simple Data Sharing for Multi-Tasked Goal-Oriented Problems,"['goal-conditioned RL', ' offline RL']",8571,"[{'mark': [2, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions,"['In-context learning', ' Transformers', ' Large language models', ' Boolean functions']",8569,"[{'mark': [4, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}]",,
Initializing the Layer-wise Learning Rate,"['Learning Rate', ' Exploding Gradient', ' Vanishing Gradient']",8568,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Relational Convolutional Networks: A framework for learning representations of hierarchical relations,"['representation learning', ' relational architectures', ' relational representation learning', ' hierarchical feature representations', ' compositionality', ' higher-order relations', ' convolutions']",8566,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}]",,
How does overparametrization affect features?,"['deep learning', ' overparametrization']",8564,"[{'mark': [4, 4, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}]",,
The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry,"['linear attention', ' transformers']",8562,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}]",,
Understanding and Robustifying Sub-domain Alignment for Domain Adaptation,"['Sub-domain method', ' Domain/Distribution alignment', ' Robust knowledge transfer', ' Theory driven methodology']",8560,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers,"['relational representation learning', ' attention', ' transformers', ' sequence models', ' abstract representations']",8558,"[{'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 3}]",,
Doubly Robust Instance-Reweighted Adversarial Training,"['adversarial training', ' distributionally robust optimization', ' bilevel optimization', ' instance reweighting']",8556,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}]",,
Estimating uncertainty from feed-forward network based sensing using quasilinear approximation,"['Uncertainty propagation', ' quasilinear approximation', ' stochastic linearization', ' neural networks', ' Kalman filter.']",8555,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}]",,
SOLVING SCHRODINGER BRIDGE PROBLEM VIA STOCHASTIC ACTION MINIMIZATION,"['Schrodinger bridge', ' optimal transport', ' single-cell', ' trajectories']",8551,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 2}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}]",,
Training Diffusion Models with Reinforcement Learning,"['reinforcement learning', ' RLHF', ' diffusion models']",8548,"[{'mark': [3, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
DIRECTIONALITY IN GRAPH TRANSFORMERS,"['graph transformers', ' graph neural networks']",8547,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 4}]",,
Latent Conservative Objective Models for Offline Data-Driven Crystal Structure Prediction,"['crystal structure prediction', ' offline model-based optimization']",8545,"[{'mark': [3, 3, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}]",,
Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning,"['reinforcement learning', ' federated learning', ' temporal difference learning']",8544,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 1, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Explaining the Out-of-Distribution Detection Paradox through Likelihood Peaks,"['out-of-distribution detection', ' normalizing flows', ' manifold hypothesis', ' intrinsic dimension']",8543,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}]",,
Federated Q-Learning: Linear Regret Speedup with Low Communication Cost,"['Federated Learning', ' Reinforcement Learning', ' Q-Learning', ' Regret', ' Communication Cost']",8542,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]",,
The Trickle-down Impact of Reward Inconsistency on RLHF,"['Large language model', ' reward model', ' RLHF', ' consistency']",8541,"[{'mark': [1, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}]",,
Multi-Resolution Learning with DeepONets and Long Short-Term Memory Neural Networks,"['multi-resolution learning', ' operator learning', ' recurrent neural networks', ' DeepONet', ' LSTM', ' dynamical systems']",8539,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 4, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}]",,
Non-stationary Contextual Bandit Learning via Neural Predictive Ensemble Sampling,"['Nonstationary Contextual Bandit', ' Neural Bandit Learning', ' Continual Learning', ' Exploration vs Exploitation']",8538,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 2}]",,
Depth From Camera Model,"['Depth Estimation', ' Camera Model', ' 3D Reconstruction']",8536,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}]",,
Deep probabilistic 3D angular regression for directional dark matter detectors,"['3D', ' Directionality', ' Probabilistic', ' Particle Physics']",8534,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 3}]",,
Unsupervised Sign Language Translation and Generation,"['unsupervised', ' sign language translation', ' natural language processing']",8533,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
Cross-modality debiasing: using language to mitigate sub-population shifts in imaging,"['cross-modality', ' sub-population shift']",8531,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Decompose Time and Frequency Dependencies: Multivariate Time Series Physiological Signal Emotion Recognition,"['Physiological Signal', ' Emotion Recognition', ' Time Series', ' Representation Learning', ' Affective Computing']",8530,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 3], 'rate': 6, 'confidence': 4}]",,
Understanding Your Agent: Leveraging Large Language Models for Behavior Explanation,"['Explainability', ' Behavior Modeling', ' Large Language Models']",8529,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}]",,
Continual Graph Learning for Thermal Analysis of Composite Materials under Interface Variations,"['Graph Neural Network', ' Continual Graph Learning', ' Thermal Analysis']",8528,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 1], 'rate': 5, 'confidence': 4}]",,
Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models,"['Uncertainty Quantification', ' Selective Generation', ' Natural Language Generation']",8527,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}]",,
Stochastic two points method for deep model gradient free optimization,"['zeroth-order optimization', ' gradient free adaptation']",8526,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
SafeDiffuser: Safe Planning with Diffusion Probabilistic Models,"['Diffusion', ' Safe Planning', ' Specification Guarantees']",8525,"[{'mark': [2, 1, 2], 'rate': 1, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 3}]",,
Revisitng graph neural networks for traffic forecasting,"['Graph-structured dynamics', ' Linear model', ' Large network', ' Traffic forecasting']",8523,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 1], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Neural Collapse meets Differential Privacy:  Curious behaviors of NoisySGD with Near-Perfect Representation Learning,['Differential privacy; neural collapse; DP-SGD; representation Learning'],8521,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [1, 3, 1], 'rate': 3, 'confidence': 5}]",,
Efficient Modulation for Vision Networks,"['EfficientMod', ' Efficient Networks']",8518,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
Pre-training LiDAR-based 3D Object Detectors through Colorization,"['3D object detection', ' LiDAR point cloud', ' pre-training', ' autonomous driving', ' self-supervised learning']",8517,"[{'mark': [4, 4, 4], 'rate': 8, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 5}]",,
An Emulator for Fine-tuning Large Language Models using Small Language Models,"['pre-training', ' fine-tuning', ' decouple', ' scale', ' reward', ' alignment']",8516,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 2}, {'mark': [4, 2, 4], 'rate': 8, 'confidence': 5}]",,
Toward Student-oriented Teacher Network Training for Knowledge Distillation,"['Knowledge distillation', ' Teacher-student training', ' Empirical risk minimization']",8515,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}]",,
Language Models Represent Space and Time,"['Interpretability', ' world models', ' probing']",8514,"[{'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}]",,
Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning,"['Causal Reasoning', ' Causal Discovery', ' Structural Causal Models', ' Large Language Models']",8513,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}]",,
Fast-ELECTRA for Efficient Pre-training,"['Language model Pre-training', ' ELECTRA', ' Efficiency']",8511,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 6, 'confidence': 3}]",,
Maximum Entropy Model Correction in Reinforcement Learning,"['reinforcement learning', ' model-based reinforcement learning', ' maximum entropy', ' planning']",8509,"[{'mark': [3, 2, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 4}]",,
Ceci n'est pas une pomme: Adversarial Illusions in Multi-Modal Embeddings,"['security', ' machine learning', ' adversarial perturbations', ' large language models']",8508,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Identifying Latent State Transition Processes for Individualized Reinforcement Learning,"['individualized reinforcement learning', ' latent state transition', ' identifiability']",8507,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}]",,
Learning Multi-Agent Communication using Regularized Attention Messages,"['Multi-Agent Reinforcement Learning', ' Communication', ' Attention', ' Message Compression']",8505,"[{'mark': [1, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
The mechanistic basis of data dependence and abrupt learning in an in-context classification task,"['in-context learning', ' mechanistic interpretability', ' language models', ' induction heads']",8504,"[{'mark': [4, 3, 3], 'rate': 1, 'confidence': 4}, {'mark': [4, 3, 4], 'rate': 1, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 3}]",,
SpaCE: The Spatial Confounding Environment,"['causal inference', ' datasets', ' benchmarks', ' spatial confounding', ' public health']",8502,"[{'mark': [3, 4, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}]",,
Benchmarking Cognitive Biases in Large Language Models as Evaluators,"['Large Language Models', ' Automatic Evaluation', ' Cognitive Biases']",8501,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
PILOT: An O(1/T)-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation,"['min-max optimization', ' adaptive batch size', ' policy evaluation.']",8499,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}]",,
Graph Neural Networks Gone Hogwild,['graph neural network'],8497,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Impact of Molecular Representations on Deep Learning Model Comparisons in Drug Response Predictions,"['Cancer Drug Response Prediction', ' Model Comparison']",8496,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}]",,
Positional Description Matters for Transformers Arithmetic,"['Transformer', ' Arithmetic', ' Language Model', ' Deep Learning']",8495,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}]",,
FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation,"['fresh LLMs', ' search engine-augmented LLMs', "" LLMs' factuality""]",8494,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}]",,
Contrastive Post-training Large Language Models on Data Curriculum,"['large language model', ' curriculum learning', ' contrastive learning', ' alignment']",8492,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 2}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning,"['multi-objective optimization', ' sample complexity', ' variance reduction', ' momentum']",8491,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [1, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
Language Model Detectors Are Easily Optimized Against,"['detector', ' language model', ' learning from preferences']",8488,"[{'mark': [2, 2, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}]",,
The Representation Jensen-Shannon Divergence,"['Statistical Divergence', ' Kernel methods', ' Two sample testing']",8487,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models,"['robot learning', ' diffusion model']",8486,"[{'mark': [2, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
Learning to Reach Goals via Diffusion,"['Goal-conditioned reinforcement learning', ' Offline reinforcement learning', ' Diffusion modeling']",8484,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}]",,
"LUMOS: Towards Language Agents that are Unified, Modular, and Open Source","['language agent', ' interactive NLP', ' tool-augmented LLM']",8483,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [1, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Physics Informed Neurally Constructed ODE Networks (PINeCONes),"['Scientific Machine Learning', ' Neural ODEs', ' PINNs', ' PDEs']",8482,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
CrysFormer: Protein Structure Prediction via 3d Patterson Maps and Partial Structure Attention,"['AI for science', ' protein crystallography', ' Transformer model']",8479,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 3, 'confidence': 3}]",,
Latent Space Simulator for Unveiling Molecular Free Energy Landscapes and Predicting Transition Dynamics,"['molecular dynamics', ' simulation', ' Boltzmann distribution', ' sampling']",8477,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 5}]",,
Causal Estimation of Exposure Shifts with Neural Networks: Evaluating the Health Benefits of Stricter Air Quality Standards in the US,['causal inference; neural networks; air pollution; stochastic interventions; doubly robust inference'],8476,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
An empirical investigation of generalization dynamics in deep ReLU networks via nonlinear mode decomposition,"['learning', ' generalization', ' statistical mechanics', ' teacher-student', ' svd']",8473,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 2}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Efficient Transfer Learning from Arbitrary Pre-Trained Models,"['Transfer learning', ' Foundation models']",8472,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
On the Role of Edge Dependency in Graph Generative Models,"['graph', ' network', ' generative', ' model', ' random', ' dependence', ' overlap', ' triangle', ' cycle', ' bound']",8471,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
DiffDock-Pocket: Diffusion for Pocket-Level Docking with Sidechain Flexibility,"['diffusion', ' diffusion models', ' docking', ' generative model']",8469,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
Learning Diverse Quadruped Locomotion Gaits via Reward Machines,"['Reward Machine', ' Quadruped Locomotion', ' Reinforcement Learning', ' Robotics']",8468,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}]",,
"How Capable Can a Transformer Become? A Study on Synthetic, Interpretable Tasks","['Transformers', ' Capabilities', ' Mechanistic interpretability', ' Synthetic task']",8467,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 4], 'rate': 8, 'confidence': 4}]",,
Auto DP-SGD: Dual Improvements of Privacy and Accuracy via Automatic Clipping Threshold and Noise Multiplier Estimation,"['Differential Privacy', ' tCDP', ' Auto DP-SGD', ' clipping threshold estimation', ' noise multiplier decay']",8466,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 5}, {'mark': [2, 2, 1], 'rate': 1, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
"A New, Physics-Based Continuous-Time Reinforcement Learning Algorithm with Performance Guarantees","['Reinforcement Learning (RL)', ' Continuous Time (CT)', ' Optimal Control', ' Physics-Based']",8465,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 5, 'confidence': 2}, {'mark': [1, 2, 1], 'rate': 1, 'confidence': 4}]",,
Graph neural processes and their application to molecular functions,"['Neural processes', ' molecules', ' drug discovery', ' meta-learning', ' docking']",8464,"[{'mark': [3, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}]",,
Simple Hierarchical Planning with Diffusion,"['Hierarchical Offline RL', ' Hierarchical planning', ' Hierarchical Reinforcement Learning', ' Diffusion-Based Planning']",8463,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [4, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Stochastic Gradient Descent for Gaussian Processes Done Right,"['Gaussian process', ' stochastic gradient descent']",8461,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 4}]",,
Confronting Reward Model Overoptimization with Constrained RLHF,"['rlhf', ' overoptimization', ' constrained RL']",8460,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [4, 3, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
GAFormer: Enhancing Timeseries Transformers Through Group-Aware Embeddings,"['Time-series', ' Transformer', ' Spatiotemporal']",8459,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}]",,
Improved order analysis and design of exponential integrator for diffusion models sampling,['diffusion model;order analysis;fast sampling'],8456,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 1], 'rate': 3, 'confidence': 4}]",,
Setting the Record Straight on Transformer Oversmoothing,"['transformers', ' oversmoothing', ' rank collapse']",8455,"[{'mark': [4, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}]",,
KBFormer: A Transformer-based Diffusion Model of Structured Entities with Heterogeneous Properties,"['Knowledge Bases', ' Structured Data', ' Discrete State Diffusion']",8454,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 2}, {'mark': [3, 3, 4], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}]",,
Bridging Sequence and Structure: Latent Diffusion for Conditional Protein Generation,"['Protein Design', ' Geometric Machine Learning', ' Latent Diffusion', ' Protein Docking']",8453,"[{'mark': [4, 3, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}]",,
Why is SAM Robust to Label Noise?,"['generalization', ' sharpness', ' robustness', ' SAM']",8452,"[{'mark': [2, 3, 3], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}]",,
Gradient descent for matrix factorization: Understanding large initialization,"['Gradient descent', ' matrix factorization', ' large initialization', ' implicit bias', ' incremental learning']",8450,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 2}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 2}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}]",,
How FaR Are Large Language Models From Agents with Theory-of-Mind?,"['Large Language Models', ' Theory-of-Mind', ' Social Reasoning', ' Language Agent', ' Prompting']",8449,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 1], 'rate': 5, 'confidence': 4}]",,
Predicting the Performance of Foundation Models via Agreement-on-the-line,"['robustness', ' OOD performance estimation', ' foundation model safety']",8448,"[{'mark': [2, 2, 1], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
Revisiting the Last-Iterative Convergence of Stochastic Gradient Methods,"['Convex Optimization', ' Stochastic Optimization', ' Last Iterates']",8446,"[{'mark': [3, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
Learning transferrable and interpretable representation for brain network,"['Self-Supervised Learning', ' Masked Autoencoding', ' Characterizing representations', ' Neuroscience']",8443,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}]",,
CNN Kernels Can Be the Best Shapelets,"['Shapelet', ' Covolutional Neural Network', ' Time-series']",8442,"[{'mark': [2, 3, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 5}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]",,
COTIC: Embracing Non-uniformity in Event Sequence Data via Multilayer Continuous Convolution,"['temporal point process', ' time series', ' continuous convolutions', ' neural networks']",8440,"[{'mark': [1, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Stochastic Vision Transformers with Wasserstein Distance-Aware Attention,"['Robust Self-supervised Representation Learning', ' Stochastic Transformer', ' Guassian Embedding']",8438,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 1}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 2}]",,
Fine-Tuning Language Models with Advantage-Induced Policy Alignment,['reinforcement learning with human feedback'],8437,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [4, 3, 3], 'rate': 8, 'confidence': 5}, {'mark': [2, 4, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
Score-Based Multimodal Autoencoders,"['multimodal autoencoders', ' multimodal variational autoencoders', ' multimodal generative models', ' latent-space score-based models']",8436,"[{'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 6, 'confidence': 5}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Fine-Tuning Language Models for Factuality,"['factuality', ' hallucination', ' language model', ' dpo']",8435,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 3, 'confidence': 4}]",,
Improving classifier decision boundaries using nearest neighbors,"['decision boundary', ' computer vision', ' CNN', ' kNN']",8434,"[{'mark': [2, 1, 1], 'rate': 1, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures,"['Self Supervised Learning', ' Joint Embedding Architectures']",8433,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 1}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Malcom-PSGD: Inexact Proximal Stochastic Gradient Descent for Communication Efficient Decentralized Machine Learning,"['Decentralized Machine Learning', ' Proximal SGD', ' Vector Source Encoding', ' Gossip', ' Compressed Communication', ' Model Sparsification']",8432,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}]",,
Absolute Policy Optimization,"['Reinforcement Learning', ' Trust Region Policy Optimization', ' Worst-case Performance Improvement', ' Atari Games']",8430,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling,"['Biological inspired high performance energy efficient vision system', ' data efficient training', ' energy saving sensoring', ' learned saccade', ' reinforcement learning', ' foveated visual sampling', ' continuous scene reconstruction.']",8429,"[{'mark': [2, 2, 3], 'rate': 5, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 2}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}]",,
Approaching an unknown communication system by latent space exploration and causal inference,"['unsupervised learning', ' structure discovery', ' generative adversarial networks', ' causal inference', ' audio']",8428,"[{'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 4, 2], 'rate': 3, 'confidence': 2}, {'mark': [1, 2, 2], 'rate': 5, 'confidence': 2}]",,
Limited-Memory Greedy Quasi-Newton Method with Non-asymptotic Superlinear Convergence Rate,"['Quasi-Newton method', ' limited memory', ' non-asymptotic superlinear convergence']",8427,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}]",,
Overthinking the Truth: Understanding how Language Models Process False Demonstrations,"['Mechanistic Interpretability', ' AI Safety', ' Interpretability', ' Science of ML', ' few-shot learning', ' Large Language Models']",8426,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}]",,
Transforming Smallholder Farmers Support with an AI-Powered FAQbot: A Comparison of Techniques,"['Agriculture', ' FAQBot', ' LLMs', ' Natural Language Processing']",8425,"[{'mark': [1, 1, 1], 'rate': 1, 'confidence': 4}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}]",,
Efficient Subgraph Rule Induction via Tree Folding in Differentiable Logic Programming,"['inductive logic programming', ' subgraph rules', ' gradient-based']",8424,"[{'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 4}]",,
Estimating Unknown Population Sizes Using Hypergeometric Maximum Likelihood,"['multivariate hypergeometric distribution', ' maximum likelihood estimation', ' variational autoencoder', ' genomics']",8423,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [1, 4, 2], 'rate': 3, 'confidence': 4}]",,
"Regularized Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy Gradient, and Sample Complexity","['risk-sensitive reinforcement learning', ' robust Markov Decision Processes']",8422,"[{'mark': [3, 2, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}]",,
Federated Binary Matrix Factorization using Proximal Optimization,"['federated learning', ' binary matrix factorization', ' boolean matrix factorization', ' proximal operator', ' differential privacy']",8420,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}]",,
Feature Learning in Infinite Depth Neural Networks,"['Tensor Programs', ' mup', ' deep learning', ' optimization', ' optimal hyperparameter transfer']",8419,"[{'mark': [3, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 3, 4], 'rate': 6, 'confidence': 4}]",,
Two Facets of SDE Under an Information-Theoretic Lens: Generalization of SGD via Training Trajectories and via Terminal States,"['generalization', ' information theory', ' SGD', ' SDE']",8418,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}]",,
VideoDirectorGPT: Consistent Multi-Scene Video Generation via LLM-Guided Planning,"['Text-to-Video Generation', ' Large Language Models', ' Layout-Guided Video Generation', ' Temporal Consistency', ' Multi-Scene Video Generation', ' Layout Control']",8416,"[{'mark': [2, 2, 3], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Out-of-domain Fact Checking,"['fact checking', ' misinformation', ' natural language processing', ' distribution shift', ' text classification']",8415,"[{'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}]",,
Language Models Linearly Represent Sentiment,"['NLP', ' Mechanistic Interpretability', ' Large Language Models']",8411,"[{'mark': [2, 2, 4], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 6, 'confidence': 3}]",,
Improved Techniques for Training Consistency Models,"['Consistency Models', ' Consistency Training', ' Diffusion Models', ' Score-Based Generative Models', ' Score-Based Diffusion Models', ' Distillation']",8410,"[{'mark': [2, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}]",,
A Theoretical Study of the Jacobian Matrix in Deep Neural Networks,['Theory;Deep Neural Networks; Jacobian Matrix'],8409,"[{'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [1, 3, 1], 'rate': 3, 'confidence': 4}]",,
Why Do We Need Weight Decay in Modern Deep Learning?,"['Weight decay', ' overparameterization', ' implicit regularization', ' large language models', ' optimization dynamics.']",8408,"[{'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 4, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Demystifying Poisoning Backdoor Attacks from a Statistical Perspective,"['backdoor attack', ' machine learning safety', ' asymptotic', ' statistical risk']",8404,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
Concept Alignment as a Prerequisite for Value Alignment,"['Human-AI alignment', ' concept alignment', ' cognitive science']",8403,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [2, 2, 1], 'rate': 1, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 3}]",,
Learning to make adherence-aware advice,"['Human-AI interaction', ' Reinforcement Learning']",8402,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 1, 2], 'rate': 5, 'confidence': 3}]",,
Provable Compositional Generalization for Object-Centric Learning,"['compositional generalization', ' identifiability', ' object-centric learning', ' generalization', ' OOD generalization', ' unsupervised learning', ' slot attention', ' disentanglement', ' autoencoders', ' representation learning']",8400,"[{'mark': [2, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 3}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 4}]",,
"Battle of the Wordsmiths: Comparing ChatGPT, GPT-4, Claude, and Bard","['ChatGPT', ' Bard', ' Claude', ' GPT-4', ' large language models', ' chatbots', ' conversational agents']",8398,"[{'mark': [2, 3, 3], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
iHyperTime: Interpretable Time Series Generation with Implicit Neural Representations,"['Time series generation', ' implicit neural representations']",8397,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
Bridging the Fairness Divide: Achieving Group and Individual Fairness in Graph Neural Networks,"['Graph Neural Networks', ' Fairness in Graph Learning', ' Individual Fairness', ' Group Fairness']",8396,"[{'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 1, 'confidence': 4}]",,
Beyond Spatio-Temporal Representations: Evolving Fourier Transform for Temporal Graphs,"['Temporal Dynamic Graphs', ' Spectral Transform', ' GNN']",8395,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 1, 3], 'rate': 6, 'confidence': 4}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
RoCA: A Robust Method to Discover Causal or Anticausal Relation by Noise Injection,"['Causal or Anticausal Relation Discovery', ' Semi-Supervised Learning']",8394,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 2}]",,
Cycle Consistency Driven Object Discovery,"['cycle consistency', ' object discovery', ' downstream RL']",8392,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
RF-POLICY: Rectified Flows are Adaptive Decision Makers,"['robot learning', ' imitation learning', ' flow-based policies']",8391,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [1, 2, 3], 'rate': 5, 'confidence': 4}]",,
Rectifying Group Irregularities in Explanations for Distribution Shift,"['explainability', ' distribution shift', ' group robust']",8390,"[{'mark': [2, 2, 3], 'rate': 6, 'confidence': 3}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 2}]",,
Contrastive Decoding Improves Reasoning in Large Language Models,"['natural language processing', ' language models', ' contrastive decoding', ' decoding', ' reasoning']",8389,"[{'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 5}]",,
Sufficient conditions for offline reactivation in recurrent neural networks,"['computational neuroscience', ' offline reactivation', ' replay', ' recurrent neural networks', ' path integration', ' noise']",8388,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 5}]",,
Centroid-Based Learning for Malware Detection and Novel Family Identification,['malware; graphs; GNN;'],8386,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 1, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 4}]",,
GUARD: A Safe Reinforcement Learning Benchmark,"['Safe Reinforcement Learning', ' Reinforcement Learning Benchmark', ' Safe Reinforcement Learning Algorithm', ' Customizable', ' Robotics']",8384,"[{'mark': [4, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}]",,
Forward Learning of Graph Neural Networks,"['graph neural networks', ' forward learning', ' forward-forward algorithm']",8383,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [4, 2, 3], 'rate': 6, 'confidence': 3}]",,
Size Generalization of Graph Neural Networks on Biological Data: Insights and Practices from the Spectral Perspective,"['Graph neural networks', ' Out of distribution', ' Size-induced distribution shifts']",8382,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]",,
Self-Supervised Learning with the Matching Gap,"['optimal transport', ' self-supervised learning']",8379,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}]",,
COMPARATOR: Reference-free machine translation evaluation by inter-system comparison,['Machine Translation Evaluation'],8378,"[{'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [4, 4, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
Multi-timestep models for Model-based Reinforcement Learning,"['Model-based Reinforcement Learning', ' Compounding errors', ' Multi-timestep models']",8377,"[{'mark': [2, 3, 1], 'rate': 1, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [1, 3, 2], 'rate': 3, 'confidence': 4}]",,
Multisensory Geospatial Models via Cross-Sensor Pretraining,"['geospatial pretraining', ' multisensor modalities', ' cross-sensor pretraining', ' remote sensing applications', ' masked image modeling']",8376,"[{'mark': [2, 3, 3], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}]",,
Embedding Improves Neural Regularizers for Inverse Problems,"['Inverse Problems', ' High Dimensional Embedding', ' Dictionary Learning']",8375,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 2}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}]",,
SwapTransformer: Highway Overtaking Tactical Planner Model via Imitation Learning on OSHA Dataset,"['Autonomous driving', ' Imitation learning', ' highway', ' overtaking', ' machine learning', ' transformer']",8374,"[{'mark': [1, 3, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}]",,
GEO: Generative Engine Optimization,"['generative models', ' search engines', ' datasets and benchmarks']",8373,"[{'mark': [1, 2, 2], 'rate': 3, 'confidence': 5}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Clarify When Necessary: Resolving Ambiguity with Language Models,"['Language Models', ' Ambiguity', ' Uncertainty']",8372,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 4, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}]",,
From gradient attacks to data poisoning,"['data poisoning', ' safety', ' attacks', ' gradient attack', ' manipulation.']",8371,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 5}, {'mark': [1, 1, 1], 'rate': 1, 'confidence': 5}, {'mark': [2, 1, 2], 'rate': 5, 'confidence': 4}]",,
Curriculum reinforcement learning for quantum architecture search under hardware errors,"['Quantum Computing', ' Reinforcement Learning', ' Quantum Chemistry', ' Quantum Architecture Search', ' Optimization']",8370,"[{'mark': [2, 1, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}]",,
Does CLIP’s generalization performance mainly stem from high train-test similarity?,"['robustness', ' foundation models', ' CLIP', ' LAION', ' ImageNet', ' generalization', ' OOD robustness', ' distribution shift', ' vision language models', ' self-supervised learning', ' contrastive learning', ' ObjectNet', ' ImageNet-R', ' ImageNet-Sketch', ' ImageNet-A', ' ImageNet-V2']",8369,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 5}]",,
State-wise Constrained Policy Optimization,"['Safe Reinforcement Learning', ' State-wise Safety Guarantee', ' Trust Region Optimization']",8367,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 8, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}]",,
Out of the Ordinary: Spectrally Adapting Regression for Covariate Shift,"['Distribution-Shift', ' Domain-Adaptation', ' Robust-Machine-Learning']",8365,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}]",,
A Unified Approach for Online Continuous DR-Submodular Maximization,"['Stochastic optimization', ' submodular maximization', ' Frank-Wolfe algorithm']",8364,"[{'mark': [3, 4, 4], 'rate': 1, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 3], 'rate': 6, 'confidence': 3}]",,
Fast Sampling via De-randomization for Discrete Diffusion Models,"['Sampling', ' Discrete Diffusion', ' Text Generation']",8363,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
A Linearly Convergent GAN Inversion-based Algorithm for Reverse Engineering of Deceptions,"['reverse engineering deceptions', ' GAN inversion', ' optimization', ' adversarial attacks', ' generative models', ' inverse problems']",8358,"[{'mark': [2, 3, 2], 'rate': 6, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 2}]",,
Amortized Bayesian Inference with Hybrid Expert-in-the-Loop and Learnable Summary Statistics,"['Bayesian inference', ' summary statistics', ' generative models', ' amortized inference', ' expert-in-the-loop']",8356,"[{'mark': [2, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [2, 3, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}]",,
SEArch: A Self-Evolving Framework for Network Architecture Optimization,"['network architecture optimization', ' network pruning', ' knowledge distillation']",8353,"[{'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}]",,
"When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method","['LLM finetuning', ' Scaling Laws', ' Full-model finetuning', ' Parameter efficient tuning', ' Machine Translation', ' Multilingual Summarization']",8351,"[{'mark': [2, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [4, 4, 3], 'rate': 8, 'confidence': 3}]",,
Instance Needs More Care: Rewriting Prompts for Instances Yields Better Zero-Shot Performance,"['Natural Language Processing', ' Large Language Models', ' Prompt Engineering']",8350,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}]",,
Learning to design protein-protein interactions with enhanced generalization,"['protein-protein interactions', ' protein design', ' generalization', ' self-supervised learning', ' equivariant 3D representations']",8349,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [3, 4, 4], 'rate': 8, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 5}]",,
Robustness to Multi-Modal Environment Uncertainty in MARL using Curriculum Learning,"['Multi-Modal Uncertainty', ' Robustness', ' Multi-Agent Reinforcement Learning']",8348,"[{'mark': [2, 2, 2], 'rate': 1, 'confidence': 4}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 1, 1], 'rate': 3, 'confidence': 5}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]",,
AlphaFold Distillation for Protein Design,"['Inverse Protein Folding Design', ' Protein Design', ' Model Distillation', ' AlphaFold', ' Protein Folding']",8347,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [1, 2, 2], 'rate': 3, 'confidence': 5}]",,
Video2Demo: Grounding Videos in State-Action Demonstrations,"['multimodal applications', ' vision language models', ' large language models', ' task planning', ' open-vocabulary recognition']",8346,"[{'mark': [2, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [3, 4, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}]",,
Causal Representation Learning in Temporal Data via Single-Parent Decoding,"['Causal representation learning', ' causal discovery', ' causality', ' climate science', ' meteorology', ' teleconnections']",8344,"[{'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}]",,
Deep Independent Vector Analysis,"['multimodal fusion', ' nonlinear IVA', ' MISA', ' iVAE']",8343,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 6, 'confidence': 2}]",,
G-Local Attention Graph Pooling for Graph Classification,"['Graph neural networks', ' graph pooling', ' pooling layer', ' data augmentation']",8341,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 5}]",,
Relational Constraints On Neural Networks Reproduce Human Biases towards Abstract Geometric Regularity,"['human cognition', ' geometry', ' abstraction', ' vision', ' cognitive science', ' relational', ' human intelligence']",8336,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 5}, {'mark': [3, 2, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}]",,
Compositional Search of Stable Crystalline Structures in Multi-Component Alloys Using Generative Diffusion Models,"['Multi-Component Alloys', ' Generative Diffusion Models', ' Composition Search', ' Inverse Design']",8335,"[{'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 2}]",,
Modelling Microbial Communities with Graph Neural Networks,"['graph neural networks', ' microbial communities', ' microbiology', ' genomes']",9504,"[{'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [3, 2, 1], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 3}]","Understanding the interactions and interplay of microorganisms is a great challenge with many applications in medical and environmental settings. In this work, we model bacterial communities directly from their genomes using graph neural networks (GNNs). GNNs leverage the inductive bias induced by the set nature of bacteria, enforcing permutation invariance and granting combinatorial generalization. We propose to learn the dynamics implicitly by directly predicting community relative abundance profiles at steady state, thus escaping the need for growth curves. On two real-world datasets, we show for the first time generalization to unseen bacteria and different community structures. 
To investigate the prediction results more deeply, we created a simulation for flexible data generation and analyze effects of bacteria interaction strength, community size, and training data amount.
","[{'summary': 'The paper aims at predicting steady-state composition of microbial communities from the gene content of their genomes using graph neural networks.\n', 'strengths': 'Understanding how distinct bacteria form communities is an important problem, and the manuscript provides a solid introduction to the topic and, in the experimental section, asks important questions about our ability to understand community formation.\n', 'weaknesses': 'The proposed approach for using GNNs for bacterial communities is vaguely described and not well justified. The key methods section (2.2) provides a generic description of existing GNN approaches, and is missing key microbiome specific information (in particular, what is the topology of the graph). That information is provided in Supplementary information: the graph is fully connected. This makes statements in the manuscript such as “By using k graph convolutional layers after one another we can achieve k-hop information propagation” rather misleading. \nOverall, the proposed method - applying GNN model in a straightforward way to a very small, fully-connected graph - is poorly justified and weak on novelty.\n', 'questions': 'What is the rationale for using a GNN on a very simple graph?\nWhat is the benefit of focusing on predicting steady state, instead of focusing on dynamical changes to the relative abundances (e.g., dysbiosis).\n'}, {'summary': 'The paper tested the idea of using MPGNN or GraphSAGE to learn generalizable microbial community steady-state dynamics. The proposed models were tested on  simulated and previous publicly available microbial datasets and compared with the MLP-based implementation to show the effectiveness, with the discussions on the generalizability of GNN-based implementations.\n', 'strengths': 'The presented comparison results with MLP-based implementation demonstrates the potential of GNN-based implementations to model microbial community dynamics.\n', 'weaknesses': '\nThe methodological contribution is limited as the presented work is mostly implementing GNNs for microbial steady state predictions. \n\nThe main core of the paper is based on the assumption that if there is a steady state solution to the dynamics of bacterial species, then that steady state can be predicted using the genome data of the species in the system. This is a reasonable assumption to make. However the fact that this method works only for steady state solutions needs to be emphasized. Indeed in the GLV setting in the famous example of foxes and rabbits, there could be steady state and oscillatory solutions even though the participating genomes are foxes and rabbits in both the cases. It might also be a good idea to highlight why authors expect to find (or not) only steady state solutions in systems involving microorganisms such as bacteria. This will add more strength to the paper.\n\nFor simulations, the GLV equations along with initial conditions and parameters μi,Ki,ai,j drawn from different probability density functions are used to generate data. Did all such simulations lead to steady state solutions? Were any simulations that did not lead to steady state solutions discarded? Do the authors also have any comments on the frequency of steady state solutions when random parameters are used?\n\nGiven the GLV equations, the steady state solutions can be found by solving a system of |S| linear algebraic equations:\n ∑j=1|S|ai,jnj=Ki.\nThe steady state is entirely determined by the parameters ai,j and Ki. The authors use a vector composed of [μi,Ki,νis,νir,random] (where ai,j≈νis.νjr) to simulate the genome data in their simulation. It would be a good idea to highlight that within the simulated genome vector only the components [Ki,νis,νir] determine the steady state solution.\n\nThe parameter ai,j (broken into two vectors νis,νjr to simulate the genome) contains information on the pairwise interaction between different species. On the other hand, the information in a genome is completely intrinsic to a particular species. The authors should square these two facts.\n\nA proper simulation would entail simulation of the genome data. The genome data typically do not include information on interaction between species. But for simulations, the interaction matrix was used to derive ν vectors. The claim of interpretability seems to be questionable. \n\nThe authors appear to be confused on equivariance and invariance. The permutation invariance justification for using graph neural networks is confusing. For example, GLV models are widely used to model the dynamics of microorganisms. But the GLV model is not permutation invariant. The authors stated ""\\textit{When shuffling the order of bacteria within the train and test communities, the accuracy of MLPs drops significantly, clearly showing that the dynamics learned by MLPs are not invariant to permutations...}"" It is to be expected that shuffling the data will lead to reduction in performance of MLP based models. But as long as all the training and testing is done with a particular order of species, it should not matter.\n\nThe authors need to provide details on how the node (genome) attributes were obtained, especially ν\'s, as in real-world data, the ground-truth interaction aij is not available.\n\n\n', 'questions': '\nHow the nodes, edges and their associated attributes/features were constructed, especially based on the real-world data? \n\nHow scalable is the GNN-based implementation with respect to the number of microbial species?\n\n\n'}, {'summary': 'The paper looks at modeling bacterial communities and their interactions using graph neural networks (GNNs). They rely on two open datasets, total n = 552 samples. The authors have downloaded genomes for the bacteria that was converted to growth encodings. To address the issue with limited data the authors also used a simulator based on the Lotka-Volterra model. They compare three different models, MLP as the standard, GNNs and MPGNN. Using GNN/MPGNN the authors were able to model but the models were sensitive to variations and generalizing to larger systems was poor. Models were better than MLP but only marginally.\n', 'strengths': ""I found the paper interesting and I think the authors are correct that a better modeling of bacteria would open up a much better understanding of a wide range of fields. Key strengths:\n\nThe authors' comparative approach between models is commendable.\nThe paper addresses a clinically relevant topic, shedding light on bacterial interactions.\nThe authors' transparency regarding the challenges in scaling the mod\n\n"", 'weaknesses': ""While I enjoyed reading something on the outskirts of my experience, although I have grown my own tuberculosis communities in the early days of my research, I struggle with some of the basic premises:\n\nMotivation & Context: The paper's motivation needs clearer alignment with real-world applications. The authors cite that understanding these communities is essential for gut, industry and space but I find the step from this paper to extrapolating to gut seems huge. The largest studied communities are 26 and this needs to be put in context with the other fields, citing Wikipedia “1010 to 1011 cells per gram of intestinal content” seems far off from the estimated single colonies. The types of bacteria should also be matched with the environment that you aim to generalize for.\nSample Size & DNA Inclusion: I'm concerned about the limited independent samples, especially in combination with the attempt to include DNA. Making sense of DNA has proven much more difficult than thought of in the beginning and I’m not convinced that the addition made sense. Adding it to the paper risks of overfitting the data even more. I wonder if the field wouldn’t benefit more from going from 500 samples to 1-2000 more than this paper. My experience with building models on this type of data is that they are frustratingly brittle due to the lack of data.\nClarity & Explanation: Coming from medicin to ML is always a challenge. It would be helpful if the paper could provide clearer explanations for terms and metrics, especially for readers transitioning from medical backgrounds. E.g. keystone bacteria are not explained, good vs acceptable R2 is unclear to the reader (I can’t even find clearly how is this calculated, despite looking in appendix A which I should not have to for the main outcome), I assume that R2 is highly dependent on the underlying complexity, also the datasets have completely different bacteria suggesting that their purpose was different but this is unclear to me despite reading it several times.\nSimulation Impact: The paper should provide a clearer explanation of the effect of simulated colonies on the models' stability.\nRegarding the conclusion I’m a little confused as to why it doesn’t recommend including more data. I believe the authors have devoted significant time to this paper and before we put others down this path, perhaps we should wait for more data or do the authors truly feel that GEMs will be the solution?\n\n"", 'questions': 'See weaknesses. \nMy main question is if it is true that the lack of data was your biggest challenge? And if so I would like to have it clearly stated so that others may look for additional data sources or make their own datasets available before we dive into new models.\n'}, {'summary': 'The study focuses on understanding the interactions between microorganisms, which is of significant importance in both medical and environmental contexts. The authors introduce a novel approach by modeling bacterial communities using graph neural networks (GNNs) directly from the genomes of the bacteria. The inherent properties of GNNs, such as permutation invariance, allow them to effectively capture the relationships within the bacterial set, thus offering combinatorial generalization.\n', 'strengths': '\nNovel problem setup and the first use of GNN to tackle this problem. \nThe use of GNN matches with the data well since it is modeling a dynamic system. \nVery interesting set of experiments and they are extensive. \nThe presentation is nice and clear.\nNice simulation data construction and results.\n\n', 'weaknesses': '\nMethodological novelty is limited since it is basically fitting a GNN on a bacterial community graph. This is not to say the novelty of the paper is limited. Since I do believe it is tackling an interesting new problem with impact. I would suggest the authors consider a journal paper instead.\n\n', 'questions': 'Where are the circles for fig3A (models not on permuted data)? Why only select some of the combinations and not showing all of them? It would also be great if the authors could compare with standard practice of this task instead of just comparing with GraphSAGE. For example, by fitting the mechanistic model.\nHave the authors experimented with other GNN models? Since graphsage is only one instantiation and there are many recent ones with more expressive powers. \nModeling the dynamics sounds interesting. Could the authors also use GNN in an iterative way to model the dynamics? For example, using ideas from this paper: http://proceedings.mlr.press/v119/sanchez-gonzalez20a.html\n'}]"
TabR: Tabular Deep Learning Meets Nearest Neighbors in 2023,"['tabular', ' tabular data', ' architecture', ' deep learning', ' neural networks']",9502,"[{'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}, {'mark': [4, 4, 2], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}]","Deep learning (DL) models for tabular data problems (e.g. classification, regression) are currently receiving increasingly more attention from researchers.
However, despite the recent efforts, the non-DL algorithms based on gradient-boosted decision trees (GBDT) remain a strong go-to solution for these problems.
One of the research directions aimed at improving the position of tabular DL involves designing so-called retrieval-augmented models.
For a target object, such models retrieve other objects (e.g. the nearest neighbors) from the available training data and use their features and labels to make a better prediction.
In this work, we present TabR -- essentially, a feed-forward network with a novel k-Nearest-Neighbors-like component in the middle. On a set of public benchmarks with datasets up to several million objects, TabR marks a big step forward for tabular DL: it demonstrates the best average performance among tabular DL models, becomes the new state-of-the-art on several datasets, and even outperforms GBDT models on the recently proposed ""GBDT-friendly"" benchmark (see Figure 1).
Among the novel findings and technical details powering TabR, the main ones lie in the attention-like mechanism that is responsible for retrieving the nearest neighbors and extracting valuable signal from them.
In addition to the much higher performance, TabR is simple and significantly more efficient compared to prior retrieval-based tabular DL models.
","[{'summary': 'This paper considers the problem of making predictions on tabular data. The authors propose a retrieval-augmented approach where a predictor takes the representation not of the table being predicted but also the representation of the nearest neighbors from a training dataset. The encoding representations and the predictors are training together and use straightforward architecture architectures. The main result is that a combination of the carefully crafted techniques outperforms GBDT on an ensemble of tasks. The training time is higher than GBDT but not unreasonable, and better compared to prior deep learning methods. The prediction times are better\n', 'strengths': '\nThe results seem to be a significant advance over prior work in tabular data predictions. In particular, the first deep learning model to outperform GBDT on an ensemble of datasets.\nThe experiments and analysis are quite extensive. Multiple datasets of different kinds of data, analysis of training and prediction times.\nClear articulation of which techniques helped. the techniques are overall not too complex.\n\n', 'weaknesses': 'A comparison of the inference and query complexity between the methods is lacking.\n', 'questions': '\nInference time and compexity -- are the studies based on normalized inference time between models? If not, could you comment more? How does the inference complexity depend on the size of the table data?\n\nCould a different selection of datasets prove that the tabR is not superior to GBDT? In other words, are these datasets highly representative?\n\nIs it not surprising that Step-1 (adding context labels) did not help that much? One would guess that this is a big component of signal in retrieval augmentation.\n\nNot a question, but the methodology here reminds one of extreme classification and specifically this paper. https://arxiv.org/abs/2207.04452\n\n\n'}, {'summary': 'This work proposes a retrieval-augmented deep learning architecture for tabular regression/classification. The model passes x, the row to be classified/predicted, as well as additional retrieval context rows, through a learned encoder. TabR then retrieves the rows most similar to the encoded form of x, where similarity is defined as the Euclidean distance between the encoded versions of two rows, mapped through a linear layer. The top retrieval candidates and their respective labels are then sent through some more learned transformations before being aggregated and combined with the encoded form of the row to be classified/regressed. This combined embedding goes through more MLP layers to result in the output.\nThe paper goes through variants of the architecture and how each respective change impacts performance. It then compares against other deep learning-based models as well as gradient boosted decision trees. In both default-hyperparameter and tuned-hyperparameter settings, TabR performs well.\n', 'strengths': ""\nThe extensive amount of open-sourcing and experiment reproducibility is greatly appreciated.\nStrong results relative to both deep learning and boosted tree methods, and TabR-S's relatively strong performance relative to out-of-the-box boosted tree libraries suggests this isn't just excessive parameter tweaking and overfitting via architecture search.\nEasy to read, with key pieces of information generally emphasized appropriately.\n\n"", 'weaknesses': '\nPaper doesn\'t go into detail describing differences with prior deep learning-based tabular methods. What might explain the performance differences? Ex. ""prior work, where several layers with multi-head attention between objects and features are often used"" but was this what led to retrieval\'s low benefit in the past?\nInsufficient discussion of categorical variables. Is accuracy or training time particularly affected by their relative abundance relative to numerical features?\nThe steps of Section 3.2 seem rather arbitrary. Some of the detail could be compressed to make room for more intuition why the final architecture makes more sense (content from A.1.1). Description of architectural changes that didn\'t work would also be very insightful.\nPaper describes training times in A.4, but I believe a summary of this is important enough to warrant inclusion in the main paper. Something like a mention of the geometric mean (over the datasets) of the ratio between TabR\'s training time to a gradient boosted methods, described in the conclusion, would be sufficient. While the ratio is likely >1, it is better to acknowledge this weakness than to hide it.\n\n', 'questions': 'See weaknesses. Also, what is Icand? Is it all rows of the table that labels have been provided for? It\'s mentioned in page 3 that ""we use the same set of candidates for all input objects"" but what it the set of candidates exactly?\n'}, {'summary': 'The paper introduces TabR, a retrieval-augmented tabular deep learning model that outperforms gradient-boosted decision trees (GBDT) on various datasets. TabR incorporates a novel retrieval module that is similar to the attention mechanism, which helps the model achieve the best average performance among tabular deep learning models and is more efficient compared to prior retrieval-based models.\n', 'strengths': '\nTabR demonstrates superior performance compared to GBDT and other retrieval-based tabular deep learning models on multiple datasets.\nThe new similarity module in TabR has a reasonable intuitive motivation, allowing it to find and exploit natural hints in the data for better predictions.\n\n', 'weaknesses': '\nSome aspects are not clear, see the questions section.\n\n', 'questions': ""\nWhat's the reason for choosing m to be 96? How does m affect the performance of TabR?\nWhat's the inference efficiency of TabR and how does it compare with other baselines (e.g., GBDT)?\nIs TabR applicable to categorical features? It seems like the paper only considers continuous features.\n\n""}, {'summary': 'The authors meticulously designed a supervised deep learning model for tabular data prediction, which operates in a retrieval-like manner. It outperformed tree-based models on middle-scale datasets, as well as other retrieval-based deep learning tabular learning models. To achieve this, they introduced a k-Nearest-Neighbors-like idea in model design.\n', 'strengths': '\nAs emphasized by the authors, their method has managed to outperform tree based models like xgboost on middle-scale datasets.\n\nOverall, the presentation is clear, and the experiments are comprehensive. The details are clear and the model is highly reproducible.\n\nThis model is the best-performing retrieval based model.\n\n\n', 'weaknesses': ""\nThe motivations behind the module designs are not entirely clear. It appears that the authors made meticulous module (equation) optimization based on its performance on some datasets empirically. Then:\n\n(1) Why does employing the L2 distance, instand of the dot product, lead to improved performance (as shown in Eq. 3)? \n(2) Why is the T function required to use LinearWithoutBias? \n(3) We are uncertain about the robustness of the designed modules. If the dataset characteristics are changed, is it likely that the performance rankings will change significantly? The performances only on middle-sized datasets cannot show the robustness.\n...\nI suggest that providing a theoretical analysis or intuitive motivation would enhance the reader's understanding of those details.\n\nSome sota DL approaches are not compared, such as T2G-Former (an improved version of FTT)[1], TabPFN [2], and TANGOS [3]. Especially, TabFPN is relatively similar to TabR. These papers are current SOTA, and may outperforms tree based models.\n\n[1] T2G-Former: Organizing tabular features into relation graphs promotes heterogeneous feature interaction\n[2] TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second\n[3] TANGOS: Regularizing Tabular Neural Networks through Gradient Orthogonalization and Specialization\n\nThe major comparison lies among middle-scale datasets, accompanied with some results on few other datasets shown in Table 3. In scenarios involving sparse, medium, and dense data-distributed datasets (which typically occur in small, medium-sized, and large-sized datasets, respectively), I suppose that there exists a variance in the nearest neighbor retrieval pattern. Hence, conducting tests solely on medium-sized datasets may not suffice. Furthermore, the issue of inefficiency when dealing with large-scaled datasets appears to have hindered the authors from proving the method's effectiveness in large-scaled datasets.\n\nThe method proposed by the authors appears to have achieved slight performance advantages on certain datasets (although some SOTA are not compared). However, due to the lacks of explanation for the model details that are designed empirically, it seems unnecessary and risky to apply this method in real-world scenarios (for example, it's unclear whether L2 distance may fail when uninformative features are present; or, for instance, when a table has a feature with values [f_1, f_2, f_3, ..., f_n], and we take the logarithm of these values [log f_1, log f_2, log f_3, ..., log f_n] or their reciprocals, the method may perform poorly in such cases).\n\n\n"", 'questions': '\nIn Section 3.1, you mentioned ""continuous (i.e., continuous) features."" Could this be a typographical error?\n\nI am curious if the L2 design is sensitive to uninformative features? You can offer some analysis or conduct experiments by adding some gaussian noise columns (uninformative features are commonly seen in tabular datasets) and observe the change of performances. Some transformation like logarithm may impact the results.\n\nSome questions in weakness.\n\n\n'}]"
Neural Evolutionary Kernel Method: A Knowledge-Based Learning Architechture for Evolutionary PDEs,"['Numerical PDE', ' structure preserving neural network', ' operator learning', ' boundary integral']",9498,"[{'mark': [2, 3, 3], 'rate': 6, 'confidence': 2}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 3}]","Numerical solution of partial differential equations (PDEs) plays a vital role in various fields of science and engineering. In recent years, deep neural networks (DNNs) have emerged as a powerful tool for solving PDEs. DNN-based methods exploit the approximation capabilities of neural networks to obtain solutions to PDEs in general domains or high-dimensional spaces. However, many of these methods lack the use of mathematical prior knowledge, and DNN-based methods usually require a large number of sample points and parameters, making them computationally expensive and challenging to train. This paper aims to introduce a novel method named the Neural Evolutionary Kernel Method (NEKM) for solving a class of evolutionary PDEs through DNNs based kernels. By using operator splitting and boundary integral techniques, we propose particular neural network architectures which approximate evolutionary kernels of solutions and preserve structures of time-dependent PDEs. Mathematical prior knowledge are naturally built into these DNNs based kernels through convolutional representation with pre-trained Green functions, leading to serious reduction in the number of parameters in the NEKM and very efficient training processes. Experimental results demonstrate the efficiency and accuracy of the NEKM in solving heat equations and Allen-Cahn equations in complex domains and on manifolds, showcasing its promising potential for applications in data driven scientific computing.
","[{'summary': ""The paper introduces a novel approach called Neural Evolutionary Kernel Method (NEKM) for solving time-dependent semi-linear Partial Differential Equations (PDEs). The authors leverage a combination of operator splitting, boundary integral techniques, and Deep Neural Networks (DNNs) to construct evolutionary blocks that approximate solution operators. NEKM incorporates mathematical prior knowledge into each block, utilizing convolution operations and nonlinear activations tailored to the specific PDEs under consideration. This approach offers several noteworthy contributions:\n\nEfficiency and Generalizability: The use of boundary integral techniques is a standout feature of NEKM, allowing for a reduced requirement of network parameters and sampling points. This not only improves training efficiency but also relaxes the regularity assumptions on solutions. The capacity to apply NEKM to problems in complex domains and on manifolds showcases its versatility and potential real-world applicability.\n\nCompatibility with Time Discretization Schemes: NEKM can be effectively combined with time discretization schemes that possess structure-preserving properties, such as energy stability. This demonstrates the adaptability of the method to diverse mathematical contexts.\n\nTreatment of Singular Boundary Integrals: The paper introduces a method for computing singular boundary integrals that arise from fundamental solutions. This addition contributes to the overall training efficiency and robustness of NEKM.\n\n\nThe empirical validation of NEKM is conducted through testing on heat equations and Allen-Cahn equations in complex domains and on manifolds. The results demonstrate the method's high accuracy and its capacity to generalize across various domains.\nIn summary, the paper presents an innovative and promising approach, NEKM, which addresses the solution of time-dependent semi-linear PDEs. The combination of mathematical prior knowledge, boundary integral techniques, and DNNs provides a compelling method that improves training efficiency, generalizability, and adaptability to different mathematical scenarios. The successful testing on various equations and domains underscores the method's potential significance in the field of mathematical modeling and scientific computing.\n"", 'strengths': 'The strengths of the paper ""Neural Evolutionary Kernel Method (NEKM) for Solving Time-Dependent Semi-Linear PDEs"" include:\n\nInnovative Approach: The paper introduces a novel approach, NEKM, which combines operator splitting, boundary integral techniques, and Deep Neural Networks (DNNs) to address the solution of time-dependent semi-linear Partial Differential Equations (PDEs). This innovation offers a fresh perspective on tackling complex mathematical problems.\n\nEfficiency Improvement: NEKM leverages boundary integral techniques to reduce the need for extensive network parameters and sampling points. This not only enhances the efficiency of training but also relaxes regularity assumptions on solutions. This efficiency improvement is a significant advantage in solving real-world problems.\n\nGeneralizability: The paper demonstrates that NEKM can be applied to problems in complex domains and on manifolds, showcasing its generalizability across different mathematical contexts. This broad applicability enhances its potential usefulness in a wide range of scientific and engineering applications.\n\nCompatibility with Time Discretization Schemes: NEKM\'s compatibility with time discretization schemes that possess structure-preserving properties, such as energy stability, is a valuable feature. This adaptability makes it easier to integrate NEKM into existing mathematical frameworks.\n\nTreatment of Singular Boundary Integrals: The paper provides a method for computing singular boundary integrals that arise from fundamental solutions. This contribution adds to the method\'s efficiency and robustness, making it more practical for real-world applications.\n\nEmpirical Validation: The authors validate the NEKM approach through rigorous testing on heat equations and Allen-Cahn equations in complex domains and on manifolds. The high accuracy demonstrated in these tests underscores the practical utility of NEKM.\n\nMathematical Rigor: NEKM incorporates mathematical prior knowledge into its framework through convolution operations and nonlinear activations. This mathematical rigor ensures that the method is well-founded and theoretically sound.\n\nInterdisciplinary Relevance: The paper\'s focus on solving complex mathematical problems with machine learning techniques has broad interdisciplinary relevance, as it can find applications in various fields, including physics, engineering, and computational science.\n\n\nOverall, the strengths of the paper lie in its innovative approach, efficiency improvements, generalizability, compatibility with existing mathematical schemes, and the rigorous empirical validation of the proposed method. These qualities make NEKM a promising addition to the field of mathematical modeling and scientific computing.\n', 'weaknesses': 'While the paper on ""Neural Evolutionary Kernel Method (NEKM) for Solving Time-Dependent Semi-Linear PDEs"" offers several strengths, there are also some potential weaknesses to consider:\n\nComplexity: The proposed NEKM method, while innovative, is complex in its approach, involving the integration of operator splitting, boundary integral techniques, and Deep Neural Networks. This complexity might make it challenging for practitioners who are not well-versed in all of these areas to implement and understand.\n\nComputational Resources: The paper does not extensively discuss the computational resources required for training and applying the NEKM method. Deep learning methods often demand significant computational power, which could be a limitation for some users, particularly those without access to high-performance computing resources.\n\nLimited Real-World Use Cases: While the paper demonstrates NEKM\'s effectiveness in solving specific mathematical problems, it remains largely theoretical. More real-world use cases and practical applications in various domains would strengthen the paper\'s relevance and utility.\n\nInterpretability: The paper discusses the use of neural networks, which are often seen as ""black-box"" models. While the paper addresses some interpretability challenges, it might not provide a complete solution to the interpretability issues associated with deep learning approaches.\n\nAlgorithm Complexity: The proposed method involves a combination of different techniques, such as boundary integral representation and neural networks. This may make the implementation and understanding of NEKM challenging for some users, potentially limiting its widespread adoption.\n\nEmpirical Validation Scope: While the paper includes empirical validation on heat and Allen-Cahn equations, the scope of the empirical validation might be limited. A more extensive range of test cases across different scientific and engineering domains would strengthen the method\'s generalizability.\n\nScalability: The paper does not explicitly address the scalability of the NEKM method. As the complexity of problems increases, it remains to be seen whether NEKM can efficiently scale to handle more complex and larger-scale scenarios.\n\nComparison to Existing Methods: The paper lacks a comprehensive comparison of the NEKM method with existing approaches for solving similar problems. Such comparisons would help to better assess the relative strengths and weaknesses of NEKM.\n\n\nIn conclusion, while the NEKM method offers several promising advantages, such as efficiency improvements and generalizability, it also has some potential limitations, including complexity, computational resource requirements, and the need for more extensive real-world applications and validation. These weaknesses should be considered when evaluating the method\'s suitability for specific applications.\n', 'questions': '\nCan you provide more insight into the computational resources required for training and applying the NEKM method? What kind of hardware and software infrastructure is necessary for its practical implementation?\n\nThe NEKM method is quite complex, involving a combination of operator splitting, boundary integral techniques, and neural networks. How user-friendly and accessible is the implementation for researchers and practitioners who may not be experts in all these areas?\n\nThe paper mentions empirical validation on heat and Allen-Cahn equations. Are there plans to expand the empirical validation to a broader range of mathematical problems or real-world applications to further assess the generalizability of NEKM?\n\nHow does NEKM address the interpretability challenge often associated with deep learning methods? Can you provide more details on how NEKM helps users understand and trust its results, especially in cases where interpretability is critical?\n\nThe paper mentions combining NEKM with time discretization schemes that possess structure-preserving properties. Could you elaborate on specific scenarios or use cases where this combination has proven to be advantageous?\n\nNEKM proposes the treatment of singular boundary integrals arising from fundamental solutions. Can you discuss the impact of this addition on the overall efficiency and robustness of the method in practical applications?\n\nIn the real world, problems often scale in complexity. How does NEKM address the scalability challenge, especially when dealing with larger and more complex scenarios beyond the examples provided in the paper?\n\nThe paper does not include a comprehensive comparison of NEKM with existing methods for solving similar problems. Could you share insights into how NEKM performs in comparison to other approaches, and in what scenarios it may have a comparative advantage?\n\nAre there any specific plans or ongoing research aimed at addressing some of the potential weaknesses or limitations identified in the paper, such as making the method more accessible or broadening the scope of empirical validation?\n\nHow do you envision the practical adoption of NEKM in various scientific and engineering domains? Are there specific industries or areas where NEKM is expected to have a significant impact, and if so, what are the next steps for its real-world application?\n\n\nThese questions aim to seek further clarification and insights from the authors regarding the NEKM method and its potential applications and improvements.\n'}, {'summary': ""This paper aims to tackle solving partial differential equations (PDEs) traditionally solved by numerical methods with deep neural networks (DNNs). The authors address the challenges of solving PDEs with DNNs that a majority of these methods do not use any mathematical or physical parameters and require a large amount of parameters to tune. The authors propose the Neural Evolutionary Kernel Method (NEKM) to solve a type of evolutionary PDEs with DNN based kernels. The core idea is to incorporate pre-trained Green's functions. NEKM is an alternating two-step procedure that first analytically or numerically solves a nonlinear ODE to obtain a flow map and then numerically integrate the related linear PDE with a convolutional kernel.\n"", 'strengths': '\nNice abstract that motivates the need for PDEs in science and engineering problems and use of numerical methods to solve them.\nThe paper and abstract are well-written.\nIncorporating ideas from numerical methods, e.g., Green\'s function, boundary conditions and energy stability is very nice. In particular, I like to the discussion in subsection 2.2 on energy conservation and would like more details in the Appendix.\nThe generalization and use of the pre-trained Green\'s function is nice.\nThe computational savings of defining the Green\'s function on the boundary rather than the interior domain is nice. For other boundary integral representations for conservation laws, see Hansen, et. al, ""Learning physical models that can respect conservation laws"", ICML 2023 (https://arxiv.org/abs/2302.11002).\nNice high dimensional simulations in Figures 6-7.\nGeneralizability to different manifolds and boundary conditions.\n\n', 'weaknesses': '\nThe authors should define earlier what they mean by evolutionary PDEs.\nConnection to other kernel operator methods such as the Fourier Neural Operator (FNO) should be considered. It is only briefly discussed in one sentence of related work with a majority on the PINNs literature. In particular, in the related works, the authors discuss in detail how boundary conditions are incorporated into Physics-Informed Neural Networks (PINNs). The related in Neural Operator community should be discussed, such as how to incorporated boundary conditions into Neural Operators in Saad et. al, ""Guiding continuous operator learning through Physics-based boundary constraints"", ICLR 2023.\nThe method only works on semi-linear PDEs. This is actually a very strong assumption and limitation. The authors should discuss the extension to nonlinear PDEs.\nEvaluation: the method is only tested on the simple linear heat/diffusion equation and Allen-Cahn equations. The heat equation is smooth and parabolic and very easy for numerical methods to solve. It would be nice to test hyperbolic problems with shocks, e.g., in the GPME benchmarking framework in Hansen, et. al, ""Learning physical models that can respect conservation laws"", ICML 2023 (https://arxiv.org/abs/2302.11002).\nThe method seems to have strong limitations if the first step requires an analytical or numerical solution to the ODE. \nIn particular, the authors should clarify this in the last paragraph of the introduction. I don\'t understand where the nonlinear ODE is coming from in step 1 and then how there is ""numerically integration"" for the related linear PDE. Typically, in numerical methods a (non)linear PDE is first discretized in space and then the resulting semi-discrete form of the ODE is discretized in time. The authors should clarify what they mean here.\nI think some of the equation details of BINet in the related work should be moved to an appendix or background section.\nCare should be taken with the discretization because this adds a first order error into the scheme. For example, the first equation should not be discretized with the 1st order accurate Forward Euler without even citing the method. This is an explicit method and there are necessary bounds on Δt/τ to ensure numerical stability.  See Krishnapriyan et. al, ""Learning continuous models for continuous physics"", 2023 (https://arxiv.org/pdf/2202.08494.pdf) on how the time discretization matters in NeuralODE and the 4th order RK4 is advantageous but even that scheme without being careful about the numerics can lead to convergence issues.\nIdeally the method and presentation wouldn\'t need to be separated into separate cases for linear equations or not.\nIt seems like the method depends too strongly on the BINet method and the authors should better differentiate the novelty between the two.\nThe exposition of the method in Section 2 isn\'t too clear and some of the details can be moved to an appendix.\nThe unique features of the NEKM subsection seems like it could be incorporated with the contributions subsection in the intro.\nLabel x and y axis in Figure 3.\nAnother major weakness in the evaluation is just comparing to the exact solution and no other baseline methods, especially to related neural operator based methods.\n\nMinor\n\nFirst paragraph of related works can be longer and combined with parts of the longer second paragraph.\nheat equation shouldn\'t be plural in the last bullet point of the contributions.\ncomma after ""In this section"" at the beginning of Section 2 Method\nI would name Section 2 with the specific method name Neural Evolutionary Kernel Method (NEKM) rather than the generic Method.\nCould use standard notation from numerical methods Δt instead τ\nComma missing after Equation 7.\nLarger title lave on Figure 6.\n\n', 'questions': '\nDoes the method only work on semi-linear PDEs? If so, this is a bit limiting and the authors should discuss the extension to nonlinear PDEs.\n\n'}, {'summary': 'The paper presents the Neural Evolutionary Kernel Method (NEKM) for solving semi-linear time-dependent PDEs. NEKM distinguishes itself by utilizing operator splitting and boundary integration, enabling efficient network architectures. The method is demonstrated to be effective and stable in solving classic PDEs, such as the heat equation and the Allen-Cahn equation.\n', 'strengths': 'NEKM can be combined with time discretization schemes that preserve energy stability, which is crucial for modeling physical systems.\nThe method incorporates an evolutionary kernel, which inherently preserves the structure of the problem.\nThe method incorporates an evolutionary kernel, which inherently preserves the structure of the problem.\n', 'weaknesses': 'While NEKM is claimed to work in complex domains, the paper primarily provides examples in small and relatively simple domains. It would be beneficial to demonstrate its performance in more complex and realistic domains, similar to the level in the referenced paper (https://arxiv.org/pdf/2309.00583), including real-world scientific and engineering geometries.\nThe paper lacks references to related work that adopts neural networks only at the spatial level while using time discretizations to evolve spatial fields over time. Including references to papers like ""Evolutional deep neural network (Physical Review E 2021),"" ""Implicit Neural Spatial Representations for Time-dependent PDEs (ICML 2023),"" and ""Neural Galerkin Scheme with Active Learning for High-Dimensional Evolution Equations"" could help provide context and comparisons.\nThe paper does not provide information about the computational cost and scalability of NEKM compared to classical numerical methods, especially for larger 3D problems. It would be valuable to include performance comparisons in terms of computational efficiency.\n', 'questions': ""My biggest confusion and concern is the relationship between this paper (Lin et al., 2023a) as well as (Lin et al., 2023b). Those paper also use a convolution representation of the solutions using Green's functions. What exactly is the author's contribution except working with time-dependent problems?\nThe paper focuses on semi-linear PDEs, but it would be interesting to know if NEKM can be extended to handle nonlinear PDEs. Clarification on the limitations and potential extensions of the method for nonlinear problems would be beneficial.\n""}, {'summary': 'This paper proposes a neural network-based algorithm, namely the Neural Evolutionary Kernal Method (NEKM), for solving evolutionary PDEs. The method involves the operator splitting technique and the idea of boundary integral network. Specifically, the method pre-trains a neural network representation of the Green function and then solves the evolutionary PDE by applying the Green function block and kernel function block alternatingly with an ODE solver. Experiments on the heat equation and Allen-Cahn equations are conducted to demonstrate the performance.\n', 'strengths': '\nThe paper is well-written and easy-to-follow.\nThe proposed method is interesting and mathematically grounded.\nExperimental results seem strong.\n\n', 'weaknesses': '\nIt seems the method heavily relies on the closed form formula of the fundamental solution G0. The numerical error of the integration involving G0 seems troublesome.\nThe experimental results of Allen-Cahn equation is not compared with the exact one or any other method.\nSome minor issues: Figure 12 is too small.\n\n', 'questions': '\nNow that the Green function G is computed by pre-training a neural network, the error of this step may propagate to solving the time evolutionary PDE. Was this problem an issue in the experiments? How accurate should the numerically approximated Green function be so as not to affect the performance?\nAs mentioned in the paper, the possible singularity of G0 may demand special handling. But the form of G is generally unknown. How can the singularity appearing in G be dealt with?\nEnergy stsability is claimed as one of the contributions. Is this only empirically observed or grounded with some particular design?\n\n'}]"
PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs,"['PINN', ' machine learning', ' physics-informed machine learning']",9493,"[{'mark': [3, 3, 3], 'rate': 5, 'confidence': 3}, {'mark': [4, 4, 4], 'rate': 6, 'confidence': 3}, {'mark': [2, 4, 1], 'rate': 1, 'confidence': 5}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 3}]","While significant progress has been made on Physics-Informed Neural Networks (PINNs), a comprehensive comparison of these methods across a wide range of Partial Differential Equations (PDEs) is still lacking. This study introduces PINNacle, a benchmarking tool designed to fill this gap. PINNacle provides a diverse dataset, comprising over 20 distinct PDEs from various domains including heat conduction, fluid dynamics, biology, and electromagnetics. These PDEs encapsulate key challenges inherent to real-world problems, such as complex geometry, multi-scale phenomena, nonlinearity, and high dimensionality. PINNacle also offers a user-friendly toolbox, incorporating about 10 state-of-the-art PINN methods for systematic evaluation and comparison. We have conducted extensive experiments with these methods, offering insights into their strengths and weaknesses. In addition to providing a standardized means of assessing performance, PINNacle also offers an in-depth analysis to guide future research, particularly in areas such as domain decomposition methods and loss reweighting for handling multi-scale problems and complex geometry. While PINNacle does not guarantee success in all real-world scenarios, it represents a significant contribution to the field by offering a robust, diverse, and comprehensive benchmark suite that will undoubtedly foster further research and development in PINNs.
","[{'summary': 'This paper provides both a collection of benchmark datasets as well as a standardized suite of PINN-type neural network PDE solution approximators arranged as a python package.\nIt further shows benchmark numbers of the different PINN methods on the benchmark datasets.\n', 'strengths': 'Providing any meaningful benchmark to the community is a valuable service.\nIn addition to creating the benchmark data sets, the authors have made a big effort in collecting and unifying PINN methods into a unified framework.\nThe paper appendix contains detailed specifications about the particular setup for the data benchmark.\n', 'weaknesses': 'While providing a benchmark data set to the community is a valuable service, several aspects could be improved.\nMinor: \n-It would be great to have a table or list (in the appendix) detailing a comparison of the provided data sets to those in PDEarena (and PDEbench).\nMajor: \n\nThe relative error values in the results tables are for the most part shockingly bad and simply not useful for many numerical analysis contexts. Given that PINNs seem to be mostly providing different function spaces for PDE solutions, one original base PINN should be included in the benchmark, which is to give each hat function on a finite element mesh one parameter, and hence include finite element methods. Because some of the data sets were created using FEM, the original mesh would yield 0 error, but different meshes may not, and in particular coarser meshes would accumulate error. Analyzing a curve of remeshing from same resolution to coarse would provide a baseline for the performances of the other PINNs.\n\nIn the above sense, it also becomes important to quantify flop counts. It appears that most PINNs need to be fitted for each PDE solution, incurring the typically high flop count of solving an optimization problem (compared to one forward pass), and only some of them can learn solutions conditional on hyperparameters given as input and require only forward passes to solve e.g. from different inital conditions.\nFor all cases, there should be 3 different flop counts provided: 1) The number of flops required to create the training set 2) The number of flops required for any general training of the method  3) the number of flops required to evaluate/fit the method on a particular example. Many PINNs, and the FEM baseline would only have nonzero counts in point 3, and it would be good to compare them.\nHaving flop counts or even wall time counts would allow answering questions like ""at equal error rate, does fitting a PINN or fitting FEM cost more computational power?"" and ""At equal computing power, can FEM beat the error rates of the listed PINNs?""\n\ncontinuing the discussion about flop counts, methods learning from multiple data sets/examples should be included in order to compare flop counts and provide additional reference error values. In particular for the time propagating PDEs, solutions using U-nets or FNOs from e.g. PDE bench should be included as reference values, in terms of performance, flops required for training, flops required to generate the required training data, and flops required to run a forward pass to obtain a solution. Then one can assess how many PINNs or FEM solutions one can compute for the same budget as a certain number of forward passes of the propagator network. The should be a break-even point at some number of forward passes justifying the training effort.\n\n\nWithout these points, the benchmark is unfortunately sitting just beyond actual widespread utility. I would highly encourage the authors to add these baselines to make the benchmark useful. Despite my positive bias towards benchmarking efforts I cannot recommend acceptance of this paper in its current state.\n', 'questions': 'Would it be possible to address the major issues listed above among weaknesses?\n'}, {'summary': 'This paper provides a comprehensive comparison of PINN training methods, problems, and data. The paper visits common problems with training PINNs, namely the complex geometry, the multi-scale phenomena, nonlinearity of some PDE ofrs, and the high dimensional PDE problems. They also provide various training mechanisms such as domain decomposition and loss reweighting methods.\n', 'strengths': '\nThe paper is well-written; it seems obvious this work has gone through a few rounds of polishing and review.\nThe literature review is detailed and comprehensive.\nThe challenging aspects of training PINNs are decomposed and categorized well.\nThe appendix section of the paper is thorough and contains quality information.\nThe suite of experiments is admittedly comprehensive; there are more than 20 PDE forms, 10 methods considered and compartmentalized well in this paper.\nThe scale of the experiments and the analyses of the hyper-parameters is certainly admirable.\n\n', 'weaknesses': ""\nI'm saying out of respect to the author's work, but this paper may be more suited for a journal format. In particular, the page limit constraint is hitting the work hard in my opinion.\n\n\nBy the time the authors present the data and experiments, there is less than half a page left to interpret the results and provide discussions and conclusions.\n\nMany key discussions, at different points in the main text, were deferred to the appendix. While they do exist in the appendix and carry out important information, they carry more scientific content than the existing paper's text.\nTo be clear, the paper's topic is certainly relevant to ICLR and could benefit the ICLR community. However, the conference format may not be the most suitable to present the work as best as it could have been.\n\n\n\nThe work utilizes 10 different methods for training PINNs, but a brief description of these methods in a single mathematical framework is missing. Adding such a description and correlating the numerical findings to the theoretical properties of each method is probably the most important, yet under-performed, part of the work in my opinion.\n To be clear, I understand the paper's space constraints, but this is very important in my opinion. The least the authors could do is to add such a section, however briefly, to the appendix.\n\n\n"", 'questions': 'See the weaknesses section.\n'}, {'summary': 'The paper provides a benchmarking tool called PINNacle which was lacking in the domain of PINNs. The tool provides a diverse set of 20 different PDEs spanning over various application domains. The tool also provides implementations of 10 state-of-the-art techniques in PINNs and shows extensive experiments to show the strengths and weaknesses of each method.\n', 'strengths': '\nThe paper is overall well written and easy to follow.\nThe paper provides an extensive comparison of the different SOTA methods for different PDEs.\n\n', 'weaknesses': '\nThe paper lacks technical novelty to be considered for the main track. In my opinion, the paper is more suitable for an application/dataset track, for e.g., NeurIPS Dataset/Benchmark Track.\nThe insights provided in the paper are not novel and are also well-known in the PINN literature which the paper cites as well.\n\n', 'questions': '\nTable 3 shows that all of the selected SOTA methods fail on the KS Equation. However, some PINN methods can solve KS Equations such as Causal PINNs [1]. \nWhen comparing the effect of the parametric PDEs on different PINN variants (shown in Table 4), using the Average L2RE is not a good choice. It would be more informative to show the mean and the standard deviations for the different parameter choices. The average L2RE can be skewed if one (or few) of the parameter settings fails (i.e., have L2RE of 100%) while others have very low errors (such as ~1e-4).\n\n[1] Wang, S., Sankaran, S., & Perdikaris, P. (2022). Respecting causality is all you need for training physics-informed neural networks. arXiv preprint arXiv:2203.07404.\n'}, {'summary': 'None\n', 'strengths': 'The article introduces ""PINNacle"", a robust benchmark suite tailored for Physics-Informed Neural Networks (PINNs). This suite boasts a rich assortment of over 20 intricate PDE challenges, complemented by a user-centric toolbox that houses over 10 of the latest PINN techniques. These techniques are segmented by the authors into categories: loss reweighting, advanced optimizers, unique loss functions, and groundbreaking architectures. An exhaustive analysis is then executed with this benchmark dataset to scrutinize these variations.\nMany of the challenges pinpointed in the dataset resonate with a multitude of real-world scenarios. Thus, the efficacy of a method in tackling these challenges becomes a credible measure of its real-world utility. To generate the data, the authors employ the FEM solver from COMSOL 6.0 for intricately geometric problems and the spectral method from Chebfun for the more chaotic issues. This dataset encompasses challenges like the heat equation, Poisson equation, Burgers\' equation, Navier-Stokes equation, among others.\nThe paper outlines a uniform criteria to gauge the performance of varied PINN techniques across all challenges, promoting a methodical comparison of different tactics. Performance assessment is conducted using various metrics, such as accuracy, convergence rate, and computational prowess. Moreover, the authors shed light on the advantages and limitations of these methods, providing direction for subsequent studies, especially in fields like domain decomposition and loss reweighting.\nIn essence, the article\'s merits lie in its crafting of a dataset that mirrors significant challenges confronted by PINNs, establishing a uniform assessment criteria for different PINN approaches, and giving valuable insights on the strengths and pitfalls of these methods. This work undeniably propels the growth of PINNs, igniting further creativity and advancements in this burgeoning domain.\n', 'weaknesses': ""This paper stands out with several merits, accentuating its importance in the realm of Physics-Informed Neural Networks (PINNs).\nTo begin with, it offers an all-encompassing benchmark suite for PINNs, showcasing a varied dataset containing over 20 intricate PDE challenges, supplemented by an accessible toolbox with more than 10 leading PINN techniques. This suite facilitates an organized comparison of multiple approaches and delivers a uniform metric to evaluate the efficacy of various PINN methodologies across tasks.\nNext, the authors embark on an in-depth evaluation using the benchmark dataset to appraise these variations. They measure the performance through multiple indicators such as accuracy, convergence speed, and computational prowess. Their findings elucidate the advantages and pitfalls of these methods, charting a course for prospective studies, especially in areas like domain decomposition and loss reweighting.\nMoreover, the challenges pinpointed in the dataset find parallels in many real-world scenarios. Hence, how a method navigates these challenges becomes a tangible testament to its applicability in practical contexts. This tangible applicability amplifies the relevance of both the benchmark suite and the research's findings to field professionals and researchers.\nIn conclusion, this work marks a significant leap in the trajectory of PINNs, fueling further innovation and exploration in this riveting domain. The paper's offerings, spanning from the benchmark suite to the critical insights, are poised to galvanize more in-depth investigations and advancements in PINNs, ushering in enhanced solutions for real-world quandaries.\n"", 'questions': ""The paper has some areas it could improve on.\nFirst, the authors only discuss PINN methods. They didn't look at other common methods. It would be good to see how PINN methods compare to these.\nSecond, they didn't give much detail on what computer stuff is needed for PINN methods. They did say if the methods work fast or slow. But, it would be helpful to know what computer tools or power is needed. People who want to use these methods would find that information useful.\nLast, the authors worked with a set of 20 PDE problems. But they might have missed some other important problems. In future studies, it would be good to add more problems to their list. This way, we can learn even more.\n""}]"
SaNN: Simple Yet Powerful Simplicial-aware Neural Networks,"['Graph Neural Networks', ' Higher-order Representation Learning', ' Simplicial Complexes', ' Simplicial Neural Networks', ' Weisfeiler-Lehman Isomorphism Test']",9491,"[{'mark': [4, 3, 4], 'rate': 8, 'confidence': 4}, {'mark': [3, 4, 3], 'rate': 8, 'confidence': 2}, {'mark': [4, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 4}]","Simplicial neural networks (SNNs) are deep models for higher-order graph representation learning. SNNs learn low-dimensional embeddings of simplices in a simplicial complex by aggregating features of their respective upper, lower, boundary, and coboundary adjacent simplices. The aggregation in SNNs is carried out during training. Since the number of simplices of various orders in a simplicial complex is significantly large, the memory and training-time requirement in SNNs is enormous. In this work, we propose a scalable simplicial-aware neural network (SaNN) model with a constant run-time and memory requirements independent of the size of the simplicial complex and the density of interactions in it. SaNN is based on pre-aggregated simplicial-aware features as inputs to a neural network, so it has a strong simplicial-structural inductive bias. We provide theoretical conditions under which SaNN is provably more powerful than the Weisfeiler-Lehman (WL) graph isomorphism test and as powerful as the simplicial Weisfeiler-Lehman (SWL) test. We also show that SaNN is permutation and orientation equivariant and satisfies simplicial-awareness of the highest order in a simplicial complex. We demonstrate via numerical experiments that despite being computationally economical, the proposed model achieves state-of-the-art performance in predicting trajectories,  simplicial closures, and classifying graphs.
","[{'summary': 'The paper describes an efficient, and effective approach for learning representations for simplices in a simplicial complex. The central idea is that of using injective functions for aggregating simplicial features, as it ensures that the embeddings are unique. The simplicial features are aggregated over upper, lower, boundary and co-boundary adjacencies. The paper provides precise definitions and theorems and statements on the properties of the networks. The proofs are summarized in the main body and provided in full detail in the appendices. The method is further experimentally validated and shows that the proposed model (SaNN) is both efficients (significantly faster than any of the other baselines) and effective (performance within the uncertainty intervals on accurcies, or above the baselines).\n', 'strengths': '\nI am impressed by the clarity of presentation in the paper. I find talking and reading about simplicial complex often a messy business given all the types of simplices and adjacencies, and the abstract notion in the first place. It is clear that the authors though well about how to present the math. This includes proper use of figures.\nThe goal of the paper itself -efficiency whilst not compromising on expressivity- is relevant and important, and it is great to see the authors succeeding in reaching this goal.\nI appreciate the summary of the proofs after the formal statements.\nNext to a sound theoretical exposition, the experiments are thorough as well and include many ablation studies that are used to distill insightful take home messages.\n\n', 'weaknesses': 'I only have 1 important concern:\n\nAlthough the main principles are clear, I am still confused about the actual architecture/predictive models. In the end we have equation 8, but it describes a representation for each of the N sets of k-simplices, each consisting of the Nk simplices. It is unclear how to distill a global prediction out of all these representations, as would be needed for e.g. the classification tasks. Details on how the architectural design for each of the benchmarks is missing.\n\n', 'questions': 'Could you respond to the above concern, and additionally address the following questions/comments?\n\nOn several occasions the notion of ""non-deep baselines"" is used. What is meant by this. Could you clarify what non-deep means here, which methods are these?\n\nIn section 2 when presenting the symbols it is mentioned that k=1,2,…,N+1. Does k always run up all the way to N+1?\n\nIn section 4. The sentence that starts with ""The theorem implies that any arbitrary ..."" is extremely long and hard to comprehend. I suggest to split it 2 or 3 sentence to improve readability.\n\nJust above property 1 it is mentioned ""other commonly used sum, mean, or max read-out functions are not injective"" I am not fully sure I understand it correctly. The paragraph above explains that sum aggregation is the best injective aggregator, in contrast to mean aggregation. I think the statement that I just quoted is about aggregating over the different Y\'s? Perhaps this can be clarified.\n\nIn the tables: since colors red and blue are used you might as well color the text in the caption as well. I.e. ""The {\\color{red}first} and {\\color{blue}second} best performances ...""\n\nThe insights section says ""The deep models are observed to perform exceptionally better than logistic regression"", where do I see this? Logistic regression taking what as input? Could this be clarified.\n\n\nThank you for considering my comments and questions.\n'}, {'summary': 'The authors propose a class of simple simplicial neural network models, referred to as simplicial-aware neural\nnetworks (SaNNs), which leverage precomputation of simplicial features. The authors theoretically demonstrate that under certain conditions, SaNNs are better discriminators of non-isomorphic graphs than the WL and SWL test. Empirically, SaNNs are shown to perform competitively against other SNNs and GNNs on tasks such as trajectory prediction, simplicial closure prediction, and several graph classification tasks over various datasets.\n', 'strengths': '\nThe theoretical results are intriguing. Indeed, a competitor to the WL and SWL tests would be a valuable contribution to the graph ML community. \n\nA wide variety of benchmarks over several tasks and datasets are conducted to demonstrate the efficacy and efficiency of SaNNs. \n\nSaNNs inherit several valuable invariance properties of other SNNs including permutation invariance, orientation invariance, and simplicial-awareness. \n\nCompared to MPSNs, consideration of higher-order simplices does not blow up computation complexity.\n\n\n', 'weaknesses': ""\nIt is unclear for a research with limited expertise in this rather niche area to conclude the strength of the conditions prescribed in Theorems 4.1 and 4.2. (See questions.) \n\nThere do not appear to be any results describing the pre-computation time which should be included in any run-time comparisons which I imagine should scale near-exponentially with graph size and order of simplices considered. \n\nSaNNs are often not outright the winner in terms of prediction accuracies for the tasks displayed in Tables 1 and 3. For example, in Table 1, the SaNN is outcompeted by Projection and Scone on 3/4 of the datasets and the run-time savings of SaNN are not significant enough to justify usage of the SaNN. In Table 3, SaNN is not the leader in 4/5 of the datasets and it is not even the fastest. On the other hand, the time savings against MPSN are quite significant, but since many practitioners of graph learning expect training to take significant amounts of time, accuracy is the topmost priority, so there wouldn't be a strong enough justification to go with a SaNN.\n\n\n"", 'questions': '\nIs assuming the learnable transformation functions gk(t)⋅) are injective too strong? Although the MLPs will be injective, appealing to the Universal Approximation Theorem to declare that gk can be injectively-approximated is probably not practical. \n\nI may have missed this but are pre-computation times explicitly indicated in the results?\n\n\n'}, {'summary': 'The authors present a Simplicial Graph Neural Network, which considers higher-order structures in the input graphs. In comparison to previous work, the features from k-simplices are precomputed without trainable parameters and only then fed into a GNN. This leads to lower runtime during training since features can be reused in each epoch, which is validated by the authors theoretically and empirically.\nThe authors prove that their method is more powerful than the WL test and as powerful as the Simplicial WL (SWL) test, when it comes to distinguishing non-isomorphic subgraphs. Further, they prove permutation equivariance, orientation equivariance, and simplicial-awareness.\nThe method is evaluated on trajectory prediction, simplicial closure prediction, and graph classification, where it is on par/slightly outperforms previous works with better training runtimes.\n', 'strengths': '\nThe goal of the work, achieving better scalability of expressive networks by using non-parametric simplicial encoders makes sense.\nThe authors thoroughly analyze their method theoretically and provide proofs for all relevant properties.\nThe presented method seems to find a good trade-off between expressiveness, runtime and empirical quality.\nThere is theoretical value in the non-parametric encoder for simplices that keeps equivariant properties and simplicial-awareness\nThe paper is mostly well written\n\n', 'weaknesses': '\nRuntime and asymptotic comparisons in this work are done by excluding the precomputation of features. I think this is misleading, since in practice, the precomputation is certainly part of the computation, especially during inference. Thus, the presented gains seem to be only valid during training, when the features need to be computed only once for many iterations of training. \n\nAt the same time, the method only performs on par with previous work, with small gains on some datasets.\n\nThe method requires many hyper parameter choices like hops, T, k, which seem to have different optimal settings on different datasets. The result quality differs substantially depending on the configuration.\n\nI am skeptical regarding the practical relevance of the presented method due to above reasons.\n\nThe method lacks conceptual novelty. The main idea of precomputing features by non-learnable functions has been seen in other areas, e.g. non-parametric GNNs. The general structure of the work follows a long line of work about GNN expressiveness (higher order and WL-level) without presenting many novel insights.\n\n\n', 'questions': '\nI wonder how the method compares to previous methods in inference runtime, when feature precomputation needs to be included.\n\n'}, {'summary': 'This paper considers the design of neural networks for simplicial complexes, which are more general combinatorial structures than graphs, but less general than hypergraphs. The authors propose to use multihop aggregation schemes to build an architecture that is more expressive than the simplicial Weisfeiler-Lehman isomorphism test, while satisfying useful invariance, equivariance, and expressivity properties. They also demonstrate the efficientcy of their proposed method, and its performance for a few different tasks in simplicial data processing.\n', 'strengths': ""\nFor the most part, this paper is well-written, and is easy to digest for someone who is familiar with graph neural networks. I don't think the intended audience of this paper includes someone not familiar with GNNs, but this is fine in my opinion.\n\nThe proposed method is demonstrated to be quite efficient in comparison to existing ones, with similar performance as well.\n\n\n"", 'weaknesses': '\nCertain definitions regarding the types of operators and features are not laid out clearly enough, which leads to ambiguity in the paper on a technical level. As noted in the list of questions and suggestions, the claimed properties of the proposed models are not clearly true, possibly due to this misunderstanding.\n\n', 'questions': 'My most important concern is summarized in point 1 -- in particular, the ambiguities around orientation equivariance and the use of oriented operators built from the incidence matrices are what cause me to suggest this paper be rejected. If the authors are to focus on either of the two points in order to change my mind on this paper, it should be the first one.\n\nThere are some details missing regarding the type of data being handled. In particular, the incidence matrices are not defined in a way sufficient for the discussion following in the paper. Normally, the incidence matrices have values of +-1 depending on a chosen reference orientation (usually given by some ordering of the nodes). Coupled to this, the signs of the features on the simplices are determined relative to the same reference orientation -- this gives meaning to the notion of orientation equivariance. Without discussing these things, orientation equivariance is not a meaningful concept within the context of the paper.\n\na. This calls into question the validity of the example in Section 4.1. You say that all simplices are given a feature value given by some scalar a -- yet, the matrices acting on these feature vectors/matrices have an orientation associated to them. It seems as if you are using an oriented operator to act on unoriented features. Property 1 in this example is thus difficult to claim, as the property of orientation equivariance is one describing the action of oriented operators acting on oriented features, and how the choice of orientation to begin with is irrelevant to the computation. \nb. Furthermore, this problem yields a comparison for isomorphism testing incorrect, as the erroneous imposition of differently-oriented features relative to the chosen orientations could be used by SaNN to yield a ""false negative,"" i.e., saying that two isomorphic complexes are different. \nc. A more minor comment in this direction comes from the Insights section of Section 5.1. It is not correct to say that ""the superior performance of SaNN also proves the orientation equivariance of SaNN experimentally."" Orientation equivariance is a simple mathematical property, and does not guarantee good performance, nor are all performant architectures on a given dataset orientation equivariant. These properties are possibly linked, but the claim that one proves the other in some way is not justified. \nd. Moreover, based on my reading of the appendix, many of their experimental setups for tasks other than trajectory prediction use ""unoriented data"" by simply assigning scalar values to high-order simplices, which is again incompatible with the use of oriented operators. Perhaps something in the implementation of SaNN in these examples does not use oriented operators such as the incidence matrices, but this is not clear to me. \nPlease either justify, clarify, or revise the paper\'s discussion regarding orientation equivariance.\n\nRelated to the above point, the claims in Section 4.2 seem reasonable at first glance, but are not explained well enough. Permutation equivariance is easily seen to hold, so is not much of a concern. Orientation equivariance is subject to the problems noted above, so more clarification on the type of simplicial features and relevant operators needs to be made. That is not to say that the result proved in the appendix is wrong, but it needs to be clarified in order to be understood in a way that acts on oriented features. Simplicial awareness is more subtle than the other two, based on the definition from (Roddenberry et. al., 2021). For instance, some of the existing convolutional-type SNNs in the literature fail to satisfy simplicial awareness if they are implemented without nonlinear activation functions, due to the fact that the square of the (co)boundary operator is the zero operator. Perhaps it is the case that the assumptions of Theorem 4.2 are sufficient to exclude such methods, but a clearer connection is needed. It would be very helpful for the authors to briefly survey some of the methods they compare to, and clarify whether Theorems 4.1 and 4.2 apply or don\'t apply to them.\n\n'}]"
FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search,"['Neural Architecture Search', ' Performance Predictor', ' Graph Neural Network']",9483,"[{'mark': [3, 3, 2], 'rate': 3, 'confidence': 5}, {'mark': [2, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [3, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 4}]","Neural Architecture Search (NAS) has risen to prominence as a pivotal tool for identifying optimal configurations for deep neural networks suited to particular tasks. However, the process of training and assessing numerous architectures introduces considerable computational overhead. One approach to mitigate this is through performance predictors, which offer a means to estimate an architecture's potential without exhaustive training. Given that neural architectures fundamentally resemble directed acyclic graphs (DAGs), graph neural networks (GNNs) become an apparent choice for such predictive tasks. Nevertheless, the scarcity of training data can impact the precision of GNN-based predictors.
To address this, we introduce a novel GNN predictor for NAS. This predictor renders neural architectures into vector representations by combining both the conventional and inverse graph views. Additionally, we incorporate a tailored feature loss within the GNN predictor to ensure efficient utilization of both types of representations.
We subsequently assess our method's efficacy through experiments on benchmark datasets including NASBench-101, NASBench-201, and the DARTS search space, with a training data range of 50 to 400 samples. The results demonstrated a notable performance improvement, achieving an enhancement of 3%-16% in terms of prediction accuracy when compared to state-of-the-art GNN predictors across the board.
The source code will be made publicly available.
","[{'summary': 'This paper proposes a new GNN performance predictor for NAS that considers the forward and reverse computational graph of architectures. Furthermore, the authors also propose a loss function that minimizes the variance between the dual encodings of the forward and backward pass. Experiments in standard tabular and surrogate benchmarks show improvements NPNAS and NPENAS.\n', 'strengths': '\nThe paper presents a simple and effective way to improve the predictive performance of GNNs for NAS. The empirical evaluation demonstrates that the performance increases with the number of datapoints, which is nice to see.\n\nEasy to read and clearly written.\n\nCompared to NPNAS and NPENAS, the proposed algorithm shows significant improvements.\n\n\n', 'weaknesses': '\nThe proposed method to encode both the forward and backwards encoding is well-known in literature (see section 3.4 in [1] for instance) as well as in NAS [2]. The linear scalarization of the prediction loss with the loss term that minimizes the variance between the two encoders is trivial.\n\nThe authors evaluate their method on 3 tabular/surrogate benchmarks. I think this is not enough considering the diversity of available NAS benchmarks out there. There are more interesting NAS benchmarks (see NAS-Bench-Suite [3]) that also have evaluated NPENAS, and therefore makes the comparison to the proposed method possible.\n\nNo code available at submission time.\n\n\nReferences\n[1] https://arxiv.org/pdf/1904.11088.pdf\n[2] https://arxiv.org/pdf/2010.04683.pdf\n[3] https://arxiv.org/pdf/2201.13396.pdf\n', 'questions': '\nCan the authors evaluate their method on the same framework as used in [4]? It would be great to see how FR-NAS performs under the same settings as those methods are evaluated.\n\nWhat is the performance of the predictor inside a NAS algorithm? Can you evaluate FR-NAS as done in NAS-Bench-Suite (see Table 2)?\n\n\nReferences\n[4] https://arxiv.org/pdf/2104.01177.pdf\n'}, {'summary': ""This paper proposes FR-NAS, a neural architecture performance predictors that estimates performance using both the forward-pass and backwards-pass representation of a NAS architecture. FR-NAS uses an Instance Relation Graph (IRG) loss to train the dual encoder. The author's evaluate the method on three NAS-Benchmarks and compare to known predictors NPENAS and NPNAS, outperforming both.\n"", 'strengths': 'There is some novelty to considering the backwards pass representation of a NAS architecture when making a prediction. \nThe evaluation shows that FR-NAS conclusively defeats NPNAS and NPENAS on NAS-Bench-{101, 201, 301} at every training dataset size.\nThere are additional ablation studies for some components.\n', 'weaknesses': 'The novelty of this work is somewhat limited as its really only using a dual encoder with adjacency matrix transpose, while components like the IGR loss are heavily borrowed from different work.\nThis work only considers experiments on cell-based NAS Benchmarks but not on real NAS problems, which are outperformed by macro-based NAS structures like Once-for-All/MobileNets/EfficientNets. Also, no search is applied and no found architectures are evaluated. \nThere are probably simpler ways to consider the backwards-pass representation of a NAS DAG which this paper does not consider. The trivial method would be to simply cast the DAG as a fully-directed graph (for every edge (i, j), add edge (j, i)) and still use a simpler encoder. Another way, also simpler than this would be to consider weighted edges, e.g., forward-pass edges have weight \'1\', backwards-pass have weight \'-1\', and you use torch.nn.GINEConv instead of torch.nn.GINConv. \nThe IGR loss in this paper is somewhat counter-intuitive. The intuition behind considering the transposed adjacency matrix is that you are providing the predictor with new information not found in the forward-pass adj. matrix. This information should allow the predictor to learn a better understanding of architecture performance, which would help performance. Under this assumption, you would expect the encodings of the forward encode and backwards encoder to probably be different as they should be learning on distinct information, and that the concatenation of that information (graph embeddings from each encoder) benefits predictor performance. Instead, the IGR loss is counter to this as it forces both the forward/backwards encoders to \'learn the same thing\' using different views of the same data. In other words, in Figs 2-3, showing how the IRG matrix values goes down with the addition of the loss and more samples seems counter-intuitive.\nAnalysis in Figures 2 and 3 is missing NAS-Bench-201 using the IGR loss, NAS-Bench-301 400 samples with the loss, even though the manuscript is not even 9 pages.\nAuthor\'s mention Graph Attention Networks (GAT) a few times in the paper, but do not use them to perform any analysis on their encoders, e.g., highlighting the nodes/edges assigned high attention scores. This would be a good way to highlight how their method learns and the benefits of their design, and rebut the hypothesis that FR-NAS outperforms NPNAS and NPENAS simply because the predictor has more parameters.\nThere are a lot of missing entries in the related work section. Some of which should be added, and compared to, e.g.,\n\nTNASP [1] and PINAT [2] deal with special encodings for the adjacency matrix, like this paper.\nCDP [3] is a cross-domain predictor which cases 201 and 301 to be like 101, to deal with limited target data like this paper.\nGENNAPE [4] also deal with limited target data like CDP, but they also utilize a robust form of Computational Graph that covers the entire architecture, not just the NAS cell design.\nMulti-Predict [5] show how to leverage other information like Zero-Cost Proxies [6] and device latency/FLOPs to aid prediction - both of which this paper does not acknowledge, yet it is a critical concern of NAS.\n\nFor the above reasons I would recommend rejection of this manuscript. \nReferences:\n[1] Lu et al., ""TNASP: A Transformer-based NAS Predictor with a Self-Evolution Framework"", in NeurIPS 2021.\n[2] Lu et al., ""PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor"", in AAAI-23.\n[3] Liu et al., ""Bridge the Gap Between Architecture Spaces via a Cross-Domain Predictor"", in NeurIPS 2022.\n[4] Mills et al., ""GENNAPE: Towards Generalized Neural Architecture Performance Estimators"", in AAAI-23.\n[5] Akhauri and Abdelfattah, ""Multi-Predict: Few Shot Predictors For Efficient Neural Architecture Search"", in AutoML Conf 2023.\n[6] Abdelfattah et al., ""Zero-Cost Proxies for Lightweight NAS"", in ICLR 2021.\n', 'questions': 'Not a question but minor nitpick: Eq. 2 should be Enc(A_{T}, O; W_2)\n'}, {'summary': 'The FR-NAS paper devised a new graph neural network (GNN) based surrogate model for neural architecture search. The adjacency matrix is passed to a GNN which encodes the forward propagation of the neural network. Its transpose is passed to another GNN which encodes the backward propagation. These encodings are passed to their respective predictors (pf and pr) and the final predictor is an average of these two. pf and pr are trained using mean squared error loss between the predicted and the true accuracies of the networks. To ensure that the forward and backward embeddings are consistent with each other, they used an additional loss to enforce that the relative distance between two architectures in the forward embedding space and the backward embedding space is similar.\n They report the results on NasBench-101, NasBench-201 and Darts search space. In their ablation studies, they bolster the case for using both the forward and the backward pass encodings.\n', 'strengths': '\nUsing two encoders to capture the forward and backward propagation encodings and using the IRG loss to synchronize them is novel.\nTheir algorithm outperforms the other 2 baselines on NASBench-101, NASBench-201 and the DARTS search space.\n\n', 'weaknesses': '\nPlease compare against [1], [2] which are also GCN based predictors. \nIt is also important to demonstrate that the surrogate model is competitive to other baselines such as those included in Neural architecture optimization (NAO) [3], BANANAS [4] and other predictors in  [5]\nFor all the baselines, please report the time taken to train the predictors and to compute the correlations on all the 3 benchmarks.\n\n[1] BRP-NAS: Prediction-based NAS using GCNs,  Dudziak et al.\n[2] Bridging the gap between sample-based and one-shot neural architecture search with bonas, Shi et al.\n[3] Neural Architecture Optimization, Luo et al.\n[4] BANANAS: Bayesian Optimization with Neural Architectures for Neural Architecture Search, White et al.\n[5] How Powerful are Performance Predictors in Neural Architecture Search? White et al.\n', 'questions': '\nCan you please tabulate figure 5? Given that the NPENAS-FR and FR-NAS plots are very close to each other as the training data increases, it would be good to see the actual correlation values.\n2.Did you consider other alternatives to the feature loss?  Given that both Lpf and Lpr are predicting the accuracy of the same architecture, what would happen if you minimize the divergence between the outputs of Lpf and Lpr predictors?\nGiven that the algorithm is trained to minimize the feature loss, it would have the least Diff(i,j) when compared to those that are trained without them. So is figure 3 a fair comparison?\n\n'}, {'summary': 'This paper proposed a GNN-based performance predictor for NAS, the bidirectionality information is employed for performance improvement, and some experiments are conducted for verification.\n', 'strengths': 'Using the bidirectionality information to improve the performance of the predictor is quite interesting because almost all existing works did not recognize this point.\n', 'weaknesses': 'The peer competitors used for comparison in this paper are not SOTA. This paper should not only compare the methods based on GNN but also SOTA performance predictors based on other techniques.\nThe experiments should also go to ImageNet, instead of only the measures for performance predictors, the final goal of which is for NAS.\n', 'questions': 'See Above\n'}]"
Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models,['Large Language Models; Prompt Engineering; Boosting Mechanism;'],9482,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 3}, {'mark': [3, 2, 3], 'rate': 8, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 6, 'confidence': 3}, {'mark': [3, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 3, 3], 'rate': 8, 'confidence': 3}]","The reasoning performance of Large Language Models (LLMs) on a wide range of problems critically relies on chain-of-thought prompting, which involves providing a few chain of thought demonstrations as exemplars in prompts. Recent work, e.g., Tree of Thoughts, has pointed out the importance of exploration and self-evaluation in reasoning step selection for complex problem solving. In this paper, we present Boosting of Thoughts (BoT), an automated prompting framework for problem solving with LLMs by iteratively exploring and self-evaluating many trees of thoughts in order to acquire an ensemble of trial-and-error reasoning experiences, which will serve as a new form of prompting to solve the complex problem. Starting from a simple prompt without requiring examples, BoT iteratively explores and evaluates a large collection of reasoning steps, and more importantly, uses error analysis obtained from the LLM on them to explicitly revise prompting, which in turn enhances reasoning step generation, until a final answer is attained. Our experiments with GPT-4 and Llama2 across extensive complex mathematical problems demonstrate that BoT consistently achieves higher or comparable problem-solving rates than other advanced prompting approaches.
","[{'summary': 'The paper proposes a new framework Boosting of Thoughts (BoT) with large language models (LLMs) for task-specific prompting. It provides how to construct prompts and use the trial-and-error reasoning approach to interact with the LLM to generate the final responses. The experiments show the effectiveness of the proposed method.\n', 'strengths': ""\nPrompt engineering is a non-trivial task, and crafting effective prompts may require specialized training for human experts. The paper introduces an innovative framework for iterative prompting, leveraging LLM's feedback on its own reasoning, thereby reducing the need for human prompt engineering.\n\nAddressing complex problems is crucial in LLM applications. This approach effectively demonstrates the power of prompt engineering and expands the capabilities of LLMs without the need for retraining or fine-tuning. Experiments conducted on multiple datasets show competitive performance compared to other prompting approaches.\n\n\n"", 'weaknesses': '\nI agree that prompt engineering is crucial for LLM applications. However, it\'s worth noting that prompt engineering is often model-dependent, and the techniques may evolve as LLM capabilities improve. This may not offer long-term guidance for research unless it uncovers fundamental insights. This distinction is critical in differentiating academic research from practical production. Therefore, while the paper does offer valuable techniques for prompting the model and achieving good results on evaluation sets, it lacks in-depth discussion of the underlying reasons. This makes the paper better suited for application-oriented conferences rather than ICLR.\n\nLLMs can be unstable and prone to hallucination, which could result in bad or incorrect feedback when using the Boosting of Thoughts (BoT) iterative prompting framework. Is there analysis on the impact of ""bad"" LLM feedback? Further, as the iterative produces are automatic, spurious feedback could get amplified over iterations. Some discuss may be necessary.\n\nDetails are lacking on key components like aggregation strategies and generating edge weights for trees. More analysis or ablation studies are also helpful.\n\n\n', 'questions': '\nIn Section 3.2, it is not quite clear how to calculate the weights for the weighted binary tree.\n\n'}, {'summary': 'The paper presents an extension of the Chain of Thought (CoT) and Tree of Thoughts (ToT) method, named Boosting of Thoughts (BoT). BoT refines the problem-solving process in large language models (LLMs). BoT harnesses error analysis to improve the LLM\'s problem-solving accuracy iteratively. The ""Boosting of Thoughts"" (BoT) procedure is a two-step process that first generates a diversity of reasoning paths from a Large Language Model (LLM) in the form of a weighted binary tree, enhancing problem-solving by creating a hierarchy of potential solutions. Then, it employs a novel aggregation strategy that iteratively refines and combines these paths. Through best-first and greedy aggregations, BoT selects and optimizes the most promising chain of thought, using iterative feedback to progressively improve the LLM\'s performance on complex problem-solving tasks. The paper reports improved performance on complex mathematical problems when tested with GPT-4 and LLAMA2, compared to CoT and ToT.\n', 'strengths': ""\nThis is an innovative extension of the Chain-of-Thought (CoT) and Tree-of-Thought (ToT) methods. Compared to CoT and ToT, the author adopts the idea on leveraging error analysis to refine the LLM. This can be a limitation of CoT and ToT, as they do not conduct error analysis and more importantly, learn from errors. The motivation is intuitive and clear.\n\nUnlike ToT, which expands multiple reasoning tree branches, the BoT method iteratively refines a single line of thought. This focus on iteration rather than expansion allows for a more concentrated and efficient improvement of the reasoning path. The computation moves from exploring the tree into learning from erroneous trials. \n\nThe Boosting of Thoughts (BoT) concept shows a clear advancement in problem-solving methodologies within large language models. It effectively combines generation and evaluation steps to progressively enhance reasoning, demonstrating a significant leap in the model's ability to handle complex tasks. \n\nThe experiments are clear, the results are effective. And all experiments are classic experiments from CoT and ToT, so it is clear to compare BoT’s performance over CoT and ToT.\n\n\n"", 'weaknesses': ""The mauscript need polished in their figures' presentation, e.g., the authors need give more detailed examples in Fig1.\n"", 'questions': 'Q1: In the prompt, I wonder whether the “error input” are included, or only the “experience” is included? From figure 1, I only see “error report” like “step 1 is not closer to 24”, no “error input” like what is step 1, 2, 3. How the LLM know what step 1 mean, and how can LLM learn from error, if LLM does not know specific input?\nQ2: How about you consider the entire (input, error analysis) as an In-context Learning example? Then the entire method is similar to CoT, meaning that you can manually construct an exemplar consisting of (input, error analysis) pair. Then use the CoT idea to follow the strategy to generate analysis and think about the correct answer.\n'}, {'summary': 'The paper proposes a Boosting of Thoughts (BoT) framework, which aims to achieve the boosting mechanism that embraces aggregation and experience, thereby enabling the progressive refinement of unreliable reasoning steps (weak thoughts) by learning from errors to solve various problems, eventually.\n', 'strengths': 'This paper reiterates their proposition that a simple prompt can be enhanced by gradually accumulating error analysis on its generated thoughts to address complex tasks.  The authors present a novel framework, the Boosting of Thoughts (BoT), to implement such progressive prompt enhancement for effective thought generation with an experience-driven iteration process. Iteratively exploring and self-evaluating the generated simplistic trees of thoughts enables a simple initial prompt to be gradually enhanced by an ensemble of trial-and-error reasoning experiences, resulting in accurate solutions. \nThis work seems like a quite comprehensive investigation with well-structured and easy to read sections.\n', 'weaknesses': 'The paper is based on the motivation that starting with a simple prompt without human annotations for LLMs, BoT may get weak thoughts. However, with aggregation, BoT is capable of deriving a more logical and effective thought chain from them, thereby guiding the subsequent refinement.\nCould the authors expand on this statement ""Experience consistently leads to thought revision, but too much can have the opposite effect.""? If one is looking to recreate the study, are there any guidelines or steps one could adopt to as where should be the stopping point?\nVery interesting findings, however Experimental results reported are limited. The authors evaluated LLM models only on a single testing procedure. However, the analysis doesn\'t seem concrete due to the smaller sample set considered and it would truly be insightful if the analysis was done on a larger dataset to infer results.\nFurther experiments should be performed using statistical metrics, and statistical distribution of the results should be extracted. These outcomes help better support the conclusions\' claims.\nThe paper would be greatly strengthened if the proposed algorithm would outperform state-of-the-art methods\n', 'questions': 'Please review the weakness section\n'}, {'summary': 'This paper proposes a new framework called Boosting of Thoughts (BoT) for complex problem solving with large language models. BoT aims to iteratively explore many possible trees of thoughts and learn from ineffective thoughts/errors to progressively refine the prompt and elicit effective reasoning from LLMs. It aggregates the best reasoning chains from the trees and analyzes them with the LLM to gain experience on errors and revisions. Experiments on mathematical reasoning show BoT matches or exceeds previous SOTA approaches without needing human annotations.\n', 'strengths': '\nThe paper proposes a novel framework, Boosting of Thoughts (BoT), that utilizes an iterative trial-and-error approach to refine prompting and elicit complex reasoning from LLMs. The key idea of learning from errors/ineffective thoughts is creative and mimics human problem-solving.\nAuthors involve interesting techniques like weighted binary trees and heterogeneous growth strategies to generate diverse, shallow thought structures from a simple prompt.\nEvaluations on mathematical reasoning benchmarks demonstrate effectiveness of BoT. It matches or exceeds state-of-the-art methods without needing human annotated prompts. Also, the authors conduct ablation studies to further explain the mechanisms.\n\n', 'weaknesses': ""\nAlthough this article proposes several practical strategies, its reasoning framework remains inherently reliant on the Tree-of-thoughts model, thereby limiting its novelty. BoT's structure is restricted to binary trees. Expanding to more complex graph structures will further improve reasoning but is not explored.\nFor analysis, the prompts used to seed BoT could introduce biases and variances. More evaluations on OOD data would be useful to assess the robustness and generalizability of the improvements.\nThe evaluations are mainly limited to mathematical reasoning. For generality, testing BoT's performance on other domains like commonsense reasoning or symbolic reasoning is needed.\nIn the 'Competitors' paragraph, authors mentioned incorporating CoT-SC and Complex CoT as  baselines, yet CoT-SC is not shown in the 'mathematical reasoning' part. I hold the view that comparing the proposed method with prevailing baselines like SC(5) or SC(10) will offer a more direct reflection of BoT's efficacy. If it can outperform Complexity-based SC with fewer resources, it would make the work more solid.\n\n"", 'questions': ""\nAs for the statement on page 3, 'Our paper embraces ToT due to its high ability and leaves GoT and BoT for future work,' is 'BoT' a typo error here? Or you mean combining BoT method with GoT? Regardless, I believe that including GoT in the comparison would make this work more interesting and informative.\nIn the 'Competitors' paragraph in experiments, could you clarify how many reasoning chains are sampled for Complex-CoT and PHP respectively?\nThe study conducts experiments based on GPT-4, which can lead to substantially high experimentation costs. Have the authors considered or utilized more cost-effective options like GPT-3.5-turbo? I'm aware of the recent variability in performance of this model. However, if there are experimental results showing that GPT-3.5 combined with BoT can outperform GPT-4 with CoT/CoT-SC, it would render the study's findings more convincing.\n\n""}, {'summary': 'The paper looks at optimizing prompting for GPT-4 and Llama2 for solving mathematical problems. They provide an iterative strategy to prompting models for complex problems. The key challenges are SVAMP (1000 tasks), GSM8K (8500 tasks), AQUA (100 000 tasks), and MATH (12 500 tasks). The BoT, especially when enhanced with CoT, outperforms alternative methods.\n', 'strengths': 'When we reach the limits by simply increasing language models, optimal interaction becomes increasingly interesting. Exploring new ways of pushing the models to do more complex tasks can get more value out of existing LLMs and is highly relevant. \nThe paper provides code that is easy-to-read (although a Readme would be a nice addition).\nThe method shows that BoT and CoT perform above the comparisons.\n', 'weaknesses': 'The use of the term \'boosting\' in the context of refining \'weak thoughts\' introduces some ambiguity. In traditional machine learning, boosting involves the iterative enhancement of quantifiably weak learners. In the BoT framework, the concept of a \'weak thought\' is more abstract, and its ""weakness"" is not as straightforward to measure. This led me to perceive the process more as a \'pruning of weak thoughts\' rather than \'boosting\' in the conventional sense. It would be beneficial for the paper to clarify how the model aggregates and refines these thoughts in the tree structure, and how the ""weakness"" of a thought is determined and improved upon.\nI think the paper comes across unnecessarily complicated, compared to the code the text is hard to fully grasp. The figures all depict Game of 24, adding examples from both a successful and a failed example of BoT for the other tasks would be beneficial.\nFor complete reproducibility and clarity, it would be beneficial to provide the full codebase, including modules like \'llmpebase’s residual_tree_of_thoughts\', which is referenced several times but not included.\nThe title suggests a general problem-solving approach using Large Language Models. However, the content is specifically focused on mathematical problems. It might be beneficial to make the domain-specific nature of the research clearer in the title or early in the abstract to set accurate expectations for readers.\n', 'questions': 'Do I understand correctly that T 10 was maximum 10 prompts and M 15 consisted of 15 instances that generated binary trees that you then averaged over?\n'}]"
Farzi Data: Autoregressive Data Distillation,"['Data Distillation', ' Meta Learning', ' Recommender Systems', ' Language Modeling']",9481,"[{'mark': [3, 3, 3], 'rate': 6, 'confidence': 3}, {'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [4, 4, 3], 'rate': 6, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 2}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 4}]","We study data distillation for auto-regressive machine learning tasks, where the input and output have a strict left-to-right causal structure. More specifically, we propose Farzi, which summarizes an event sequence dataset into a small number of synthetic sequences — Farzi Data — which are optimized to maintain (if not improve) model performance compared to training on the full dataset. Under the hood, FARZI conducts memory-efficient data distillation by (i) deriving efficient reverse-mode differentiation of the Adam optimizer by leveraging Hessian-Vector Products; and (ii) factorizing the high-dimensional discrete event-space into a latent-space which provably promotes implicit regularization. Empirically, for sequential recommendation and language modeling tasks, we are able to achieve 98 − 120% of downstream full-data performance when training state-of-the-art models on Farzi Data of size as little as 0.1% of the original dataset. Notably, being able to train better models with significantly less data sheds light on the design of future large auto-regressive models, and opens up new opportunities to further scale up model and data sizes.
","[{'summary': 'This paper proposes FARZI, a data distillation method for auto-regressive ML tasks/event-sequence datasets. The method summarizes a large dataset into a set of synthetic sequences in latent space which can be decoded later. They show that model performance is upheld/enhanced when compared to training on the complete dataset on the downstream tasks of sequential recommendation and language modeling. For data distillation, the paper shows Adam to be better than SGD as inner loop optimizer, and derives an efficient reverse mode differentiation of Adam such that its memory complexity is independent of the number of inner loop steps.\n', 'strengths': '\nOriginality and Significance: The latent parametrization that makes FARZI optimization friendly, and the proposed trick that enables reverse mode differentiation of Adam such that its memory complexity is independent of the number of inner loop steps are great contributions and of practical value.\nQuality and Clarity: The paper is well written with extensive experiments whose details and evaluations are that are clearly described. The results are impressive. The method is able to achieve better performance on downstream tasks compared with using the full dataset.\n\n', 'weaknesses': '\nIt is not clear whether this method will be practical and scale for larger language models and larger datasets. It would be great if the authors can elaborate on this.\nThere is not a clear analysis of the total time gains of this method in comparison with training from scratch. Providing some values would make the case for this method more compelling.\n\n', 'questions': 'Listed in weakness section.\n'}, {'summary': 'The paper introduces FARZI, a data distillation framework for machine learning tasks. The goal is to condense the original large dataset into a much smaller number of synthetic sequences, so that downstream performance on the synthetic data matches (or even improves) performance on the full real dataset. The authors cast the problem using a bi-level optimization formulation, similar to meta-model matching based dataset distillation. The naive formulation is infeasible due to the very large token vocabulary and the maximum sequence length. To address this, the authors propose to factorize the synthetic dataset into a latent data summary and a token-decoder matrix. This renders the optimization continuous (as opposed to discrete), while it provides flexibility to sample synthetic sentences from a distribution (as opposed to having a fixed small set of synthetic sentences). Furthermore, the authors suggest to replace SGD in the inner loop by the Adam optimizer. To mitigate the large memory footprint, they derive an efficient approximation for reverse-model differentiation of the Adam optimization. The authors assess FARZI on sequential recommendation and language modeling tasks, where they manage to match or even exceed the downstream full-data performance using as little as 0.1% of the original dataset. The authors conduct several experiments and ablation studies to shed light on various aspects of their framework.\n', 'strengths': 'The paper makes several interesting contributions. The meta-model matching based dataset distillation was originally proposed for continuous data (e.g., image data), as opposed to language data that use discrete tokens. The use of a latent space addresses this challenge by ensuring that the optimization can be performed in a continuous space, but by also allowing us to sample the synthetic sentences from a compact distribution. Furthermore, the observation that the Adam optimizer is a much better choice for the inner loop optimization (compared to SGD) is very interesting and dramatically improves downstream performance. To address the large memory footprint, the authors derive an efficient approximation of the reverse-mode differentiation of the Adam optimizer, which nicely complements their finding that Adam is better than SGD. Interestingly, this may be more broadly applicable in other bi-level optimization tasks (e.g., in a meta-learning context).\nThe paper is well written and the related work is covered quite extensively. The authors describe in detail the various insights of their framework. When it comes to the experimental evaluation, they provide a lot of information on the metrics, datasets, hyperparameters, objectives, and even architectures.\nThe experimental evaluation is quite convincing and supports the claims made by the authors. It is very interesting that FARZI can even outperform downstream performance on the full original dataset, which could indicate the improved robustness with dataset distillation. I liked the fact that the authors investigated various aspects of FARZI, such as the versatility of the synthetic data, the cross-architecture generalization, the performance of different meta-objectives, the cold start problem, and the impact of pre-trained trajectories.\n', 'weaknesses': '\nEven though this paper makes interesting contributions to the DD literature for autoregressive tasks, it is not so obvious that it would be \nvery helpful for much larger text corpora and large language models with millions or billions of parameters. The memory footprint might end up being very large, rendering the whole framework infeasible. Furthermore, a compression rate of 0.1% may not be extremely helpful for very large datasets consisting of billions of sentences. This may limit the applicability of FARZI to settings consisting of ""reasonably large but not very large"" language corpora.\n\nIt was not clear to me how time-consuming the FARZI dataset generation process is. For example, how long did it take to generate the synthetic datasets for the tasks considered in this work? In particular, did FARZI improve the total runtime? For instance, if generating the synthetic data takes very long, then there may be very little benefit (if any) from this process. Furthermore, it is not automatically obvious that a smaller dataset can be trained faster than a larger one. There is the added question of the number of epochs required to reach convergence. The synthetic dataset may require more rounds. This was not obvious in the experimental evaluation. If I am not mistaken, I feel that the subject of runtime was only superficially touched in this work, and a more thorough discussion (with detailed pros and cons) would be needed.\n(Theoretically, this may not be a big issue if the same synthetic dataset could be successful used on several downstream tasks, but this is not immediately true. If we need dataset distillation for each separate task, then we may end up performing FARZI several times.)\n\n\n', 'questions': '\nCould the authors elaborate more on the total runtime (total time for synthetic dataset generation + total time for downstream training with synthetic vs. full data)? It would be helpful if the authors could shed light on the various questions/comments raised in Weakness (2) above.\n\nIn Equation (2), \\Omega is a set containing initializations for the inner loop, if I understand correctly. But instead of picking the initialization randomly, these come from a small number of training trajectories on the full dataset. If that is true, then the \\theta_i in the definition of \\Omega has nothing to do with the update rule for \\theta_t in Equation (2). This may still be confusing to some readers though because the same symbols are used (theta with a subscript, so the authors may want to clarify this point (i.e., what exactly is in \\Omega).\n\nI was not clear how exactly the authors chose the final hyperparameters for each setting. Did they exhaustively try all corresponding combinations in the hyperparameter table and picked the best one?\n\nIs a new synthetic batch created at the beginning of each outer-loop step based on the latent factorization?\n\n\n'}, {'summary': 'This paper proposes a method for distillation of ""auto-regressive data"", in this case meaning any data that is represented as event sequences. This can include natural language text, but also general time-series data. Their method aims to summarize a dataset into a sequence of latent embeddings (which can subsequently be decoded) given a downstream task such that they achieve similar performance to training on the complete dataset. They do this through a meta-learning procedure, optimizing directly through Adam for data which lowers downstream task loss.\n', 'strengths': ""My review comes from the point of view of someone familiar with training on natural language (and associated downstream evaluation), but not general event forecasting problems. I was not familiar with the benchmarks used by the author prior to reading this paper. \nOriginality and Significance\n\nThe paper seems original. Aspects of this work (e.g. using meta-learning/second order methods) for distillation have been touched on in the past, but usually for smaller datasets, and generally not for auto-regressive tasks. Most past works I have seen which work on large corpuses revolve around finding mixing coefficients for existing datasets [1]. This method doesn't work on datasets of that size, however this shows an improvement in scaling. \nGetting a meta-learning approach to work on such dataset sizes is quite difficult, given difficulties with estimating second-order components over the full dataset. Scaling this to even larger language-style datasets would be an interesting (future) contribution.\n\nQuality and Clarity\nThis paper is quite well-written. Experimental details are clear, and the method is properly motivated. Diagrams clarify the algorithm and the key difficulties to this method are highlighted appropriately.\n[1] The Pile: An 800GB Dataset of Diverse Text for Language Modeling, Gao et al. 2021\n"", 'weaknesses': ""Weaknesses\n\nThe authors touch on language datasets as a motivation, however do not study this (or other large-sequence tasks) due to practical model/sequence length scaling constraints. Are there reasonable paths forward that would allow this to scale to longer sequence lengths/larger models? \nGiven that the outer loop evaluates across the full original dataset, and the inner loop needs to be run several times to get updated parameters (Figure 5), what's the overall cost saving versus just training a model on the original dataset for more time (until matching student performance), if any? \nHave the authors thought about cases where there is significant noise in the training corpus? Given that the loss is computed with respect to the original dataset, it seems like this could be a problem if one ever tried to directly filter a noisy web-crawl.\n\n"", 'questions': 'All questions have been included in the ""Weaknesses"" section above.\n'}, {'summary': 'The paper provides an extension of dataset distillation to sequence modeling along with a few other innovations, such as a low rank approximation of the distilled dataset and an efficient trick to save memory during meta-learning. Overall, the paper contains strong (albeit limited) empirical results on the sequence modeling (penn tree bank) and recommendation systems datasets.\n', 'strengths': '\nThe high level motivation of the problem is quite the need of the hour, as with larger models we need to better understand their dependencies on the data\nPursuit of this research direction could potentially yield methods that enable us to train SOTA transformer models for a fraction of the input cost\nEmpirical results are thorough, although a bit limited in terms of number of datasets for sequence modeling (only PTB is used)\n\n', 'weaknesses': 'A number of points about the approach were unclear to me from the writeup, and I would appreciate clarifications from the authors:\n\nIt is said that the complexity of the dataset distillation algorithm scales by the size of the vocabulary (page. 4) and the size of the sequence that we wish to model. I can see the latter to be the case, since the loss will now be summed over the entire sequence as opposed to one forward pass (so the complexity of the forward pass is increased). However, I do not see how the time complexity increases with the vocabulary size. Do we mean space complexity? Also, more than the forward pass the dominant factor in dataset distillation is the computation of a bunch of hessian vector products in the meta gradient. Those terms do not depend on the vocabulary size either… please clarify..\n\nIt would be nice to provide an intuition for what is saving the memory, making things O(1) in memory.  Currently the big algorithm block does not provide an intuition for how this approach is O(1) in memory regardless of the number of timesteps of unrolling. This is important to clarify, since this is an important contribution, if clearly explained. If this approach is essentially gradient checkpointing, then it is worth noting that Deng and Russakovsky already implement a version of this in their code. \n\nLooking at Eqn. 2, I am a bit puzzled as to how \\Omega, namely the trajectories from the real data are incorporated in the DD process. From what I am able to understand, \\theta_0 \\sim Omega -- namely the init is sampled from the pretrained trajectories, and then from the right hand side of eqn. 2 I understand that the rest of the trajectory is obtained using Adam on the synthetic data. Where is the role of the pretrained trajectories then? Please explain..\n\nRank regularization has been done in the previous work (Deng and Russakovsky) for dataset distillation. It should be cited that this has been done, and not be presented as a novelty..\n\n\n', 'questions': 'My major questions concern the clarifications about the approach listed above, without which it is really hard to judge the technical correctness / soundness of the paper.\n'}, {'summary': 'The authors introduce a dataset distillation (DD) method called Farzi Data for data with a ""left to right"" (autoregressive) causal structure. Their algorithm has two novel elements: 1) the parameterization of the synthetic distilled data, which allows them to apply it to discrete data (such as the tokens in language modeling); and 2) a method for computing the outer loop gradient for DD when the inner loop is performed with Adam, which has a constant memory footprint independent of the number of inner optimization steps. They conduct extensive experiments with their proposed method on language modeling and sequential recommendation tasks. Compared to existing DD methods (adapted to discrete data via their parameterization), they obtain improved performance across the tested datasets, often obtaining downstream performance better than training a model on the entire original dataset.\n', 'strengths': 'Algorithmic Contribution. Algorithm 1 for computing the gradient through the inner-loop optimization with Adam using constant memory is a significant contribution. Among existing dataset distillation methods, those which take into account the entire training trajectory on the distilled data tend to obtain better accuracy (as compared to other methods which use surrogates for this objective such as the gradient matching objective in dataset condensation). However, the computational burden of these methods (specifically the memory requirement, which necessitates keeping the entire computation graph) renders them infeasible for application to larger datasets. Farzi Data takes a significant step towards addressing this problem by introducing an algorithm for differentiating through an inner loop optimized with Adam, whose memory does not scale with the number of steps in the inner loop (see Fig. 5). This is an important improvement for DD to be practically useful in real ML applications.\nEmpirical Results. The empirical results are also impressive. The authors obtain better performance than competing methods across several different real-world benchmarks. There are even scenarios where their distilled data consistently outperforms training on the entire original dataset (cf. Table 1), indicating that Farzi Data implicitly promotes some sort of ""data cleaning"" whereby samples that hurt model performance are removed or discounted. This is similar to, e.g., removing mislabeled points or data with negative Shapley values, but Farzi Data is not explicitly trained for this task.\n', 'weaknesses': 'Presentation and Clarity. While the actual prose of the paper was generally clear and easy to read, there are some major concerns with notation/presentation that limit understanding of some of the main contributions of the paper.\nP1. There are many cases where important notation is not defined. For instance, Rep(F,D) is defined in the Appendix, but not the main text, and is critical to interpreting Theorem 3.1. It is not stated what the terms dm, dx, and dw in Algorithm 1 are supposed to be, so it is impossible to determine if the expressions are correct or not. How to construct the output of the algorithm from these quantities is also not clear. What is the correspondence of the quantities in Alg. 1 to the DD problem, i.e., what will we actually update using the meta-gradient once we know how to compute it? Some (but not all) of these details can be found in the Appendix, but as they are critical to being able to understand the results, they should be moved to the main text and given appropriate explanations.\nP2. Stylistically, there is also some nonstandard notation. For instance, O(100) (3rd bullet point, pg. 2). I suppose the authors meant ""on the order of 100x"", but big-O notation has a mathematically precise meaning that doesn\'t make sense here. Another instance is Proposition 3.2. ""Correctness of Algorithm 1, Line 13"" is not a complete mathematical statement (or a complete sentence). The result should be stated completely and precisely.\nTheoretical Results. There are also issues with the theoretical results.\nT1. The most critical problem is that the proof of the main theorem (Theorem 3.1) is not mathematically sound. Specifically, the authors want to show that the expected representativeness of their low-rank synthetic data parameterization is strictly less than the expected representativeness of a naive synthetic data parameterization, under some suitable conditions and for quadratic classifiers: E[Rep(F,DF)]<E[Rep(F,DN)]. (DF and DN stand for Farzi and naive data, respectively.) In their proof in Appendix B.1, they show that E[Rep(F,DF)]<B1 and E[Rep(F,DN)] for some bounds B1 and B2. Then, since B1<B2, they conclude the desired result. This is not valid: a<b, c<d, and b<d does not imply that a<c. There needs to be a lower bound on the representativeness for the naive parameterization.\nI remark that I believe the result is (at least ""morally"") correct. The theorem essentially reduces to saying that the Rademacher complexity resulting from the low-rank parameterization is smaller than the Rademacher complexity from a general parameterization, which is intuitively obvious. However, the proof has a fatal error and must be corrected somehow.\nT2. For Lemma B.3 to hold, there must clearly be some assumptions on the loss function l; in order to apply the lemma from Shalev-Shwartz, the Rademacher complexity of the loss composed with the models in F must be considered, not F itself. As stated, I believe this lemma is not correct and the loss must be accounted for. Apart from the logical error, the motivation for the use of quadratic classifiers in the theorem wasn\'t clear to me. What connection do such models have to the auto-regressive tasks that Farzi Data is applied to?\nT3. This is related to the presentation problems regarding the notation used in Algorithm 1, but the proof of Proposition 3.2 is also suspect. What is meant by dm=dm+∂wt∂mt⋅dw? Is wt supposed to be wT, or is this expression meant to be a recursive formula? What about the formulas for the other quantities, and how are these combined to compute the meta gradient?\nIf these issues can be satisfactorily addressed, along with the questions in the section below, I would be willing to raise my score to accept, given how promising the empirical results are.\n', 'questions': ""Q1. The authors mention that training with the reference trajectories Ω is important for obtaining the best performance, as compared with training only from randomly initialized networks. However, it wasn't clear to me if this might just have been the result of a greater number of training steps when learning the distilled dataset. That is, are the results in Fig. 6(b) with the total number of meta-gradient steps constant, or do the additional precomputed trajectories result in more meta-gradient steps?\nQ2. On a related note, it was not clear to me exactly how the precomputed trajectories were used. My assumption was that instead of training the network in the inner loop only from random initializations, instead the network from the inner loop will be initialized with parameters from one of the training trajectories. Is this correct?\nQ3. Why isn't FMLP also used as a teacher network in Table 1?\n""}]"
BATTLE: Towards Behavior-oriented Adversarial Attacks against Deep Reinforcement Learning,"['deep reinforcement learning', ' preference-based reinforcement learning', ' adversarial reinforcement learning']",9480,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 3], 'rate': 5, 'confidence': 4}]","Evaluating the performance of deep reinforcement learning (DRL) agents under adversarial attacks that aim to induce specific behaviors, i.e., behavior-oriented adversarial attacks, is crucial for understanding the robustness of DRL agents. Prior research primarily focuses on directing agents towards pre-determined states or policies, lacking generality and flexibility. Therefore, it is important to devise universal attacks that target inducing specific behaviors in a victim. In this work, we propose BATTLE, a universal behavior-oriented adversarial attack method. In BATTLE, an intention policy is trained to align with human preferences for flexible behavior orientation, while the adversary is trained to guide the victim policy to imitate the intention policy. To improve the attack performance, we introduce a weighting function that assigns importance weights over each state. Our empirical results over several manipulation tasks of Meta-world show the superiority of BATTLE in behavior-oriented adversarial attack settings, outperforming current adversarial attack algorithms. Furthermore, we also demonstrate that BATTLE can improve the robustness of agents under strong attacks by training with adversary. Lastly, we showcase the strong behavior-inducing capability of BATTLE by guiding Decision Transformer agents to act in line with human preferences across various MuJoCo tasks. Our videos are available in https://sites.google.com/view/jj9uxjgmba5lr3g.
","[{'summary': 'This paper studies behavior-oriented attacks agains deep RL agents, where the adversary forces the victim to have specific behaviors. The proposed attack first learns an intention policy based on human preference, and then trains an adversary to perturb the victim observation such that the behavior follows the intention policy. The adversary also adopts importance weights of states to optimize the attack objective. Experiments on multiple meta-world and mujoco show that the proposed method is able to manipulate the victim with high success rates, including offline policies based on decision transformer. The method can be also used to improve the robustness of agents.\n', 'strengths': 'This paper proposes an interesting type of attacks that are oriented by desired behaviors. Compared to prior works focusing on reward minimizing, the proposed attack can be more widely applicable. In real-world environments where rewards are not well-defined, such attack objective can be interesting to investigate. Learning the intention policy from human preference is also an interesting idea, although I have some concerns on it (see weakness).\n', 'weaknesses': ""\nThe human preference-based intention policy learning brings extra requirement and uncertainty to the process - the collection of human preference data can be expensive. More importantly, to obtain human preference labels, one need to first collect diverse behavior data so that human can pick the intended policy. Would the collection of the behavior data already involve a pre-defined target policy? (If that's the case, why not directly use the target policy for attacks?)\nIn experiments, the authors mainly evaluate the attack success rate. However, it is not clear how the success rate is defined. Is it based on whether the victim acts as the intention policy suggests? But would it be biased since the intention policy is just an approximation of the real human intention? What if the intention learning does not learn a desired reward model or intention policy?\nFor baselines, the authors used the codebases of SA-RL and PA-AD and modified their attack's reward as the learned reward. However, this straightforward modification of the PA-AD baseline contradicts with the original method (PA-AD's formulation is for a reward-minimizing adversary, so directly replacing the attacker's reward may not work). Since the original PA-AD method is to use an RL director to find the target policy and to use an actor to conduct targeted attack, a more natural modification of PA-AD in the behavior attack scenario can be to directly use the learned intention policy as the target of actor (a^ in Equation (G) in the original paper).\n\n"", 'questions': 'How are the behavior sequences generated for human preference labeling?\n'}, {'summary': 'They introduce a method to attack reinforcement learning policies. There are three key components. First, they use PbRL to train a policy to exhibit the desired behavior. This is a relatively novel step because most work in adversarial RL assumes that the desired target behavior is already known and incentivized by a reward function. Second, they train a weighting function to help prioritize relevant states and keep the next step from policy drift. Finally, they attack the target policy with an adversarial policy that makes it behave similarly to the target behavior using the weighting function.\n', 'strengths': '\nWorking with both classic RL agents and decision transformers makes for much more thorough experiments.\nAdversarial policies that result in targetedly bad behavior is an area of research I believe is important and neglected.\n\n', 'weaknesses': '\nWriting\nI have found some of the writing to be confusing and verbose. For example, “intention policy” is not defined until multiple mentions in. The description of what it is in the abstract is very ambiguous. “Inner” and outer” level loss are not described. I don’t see a definition for “success rate” in the paper. I don’t think the paper does as good of a job as it could with laying out things in a way that is clear and quick to understand.\nI do not understand the rationale in the first paragraph of section 4.1. I do not think this makes sense as an explanation of why an intention policy is needed instead of a direct attack.\nI do not understand figure 1. Why is there an arrow between reward learning and the replay buffer?\nNumerous grammar mistakes. I would recommend using a grammarly browser plugin.\n\n\nThis may speak to either issues with my reading of the paper, its writing, or the quality of the experiments. But I am unsure why BATTLE trains an intention policy with PbRL instead of just training the adversarial policy directly with PbRL. This would seem to be substantially simpler. \nI do not understand how SA-RL can perform so poorly relative to BATTLE unless it is just due to reward shaping. What is the reward function used for SA-RL? If an adversarial policy is directly trained to minimize the agent’s reward, how can this do worse than BATTLE at making the target agents’ reward be minimized? If the key difference truly is just reward shaping, then this paper would just seem to be one about how PbRL makes reward shaping automatic and implicit. And if so, then this paper would seem to have no novelty.\nRelatedly, I do not understand why this paper is about adversarial attacks. BATTLE could be used to make RL policies do anything — not just to targetedly adversarially attack them. But in reality, to make RL policies do things, we just finetune them directly. This relates to why I do not understand why the intention policy was used. Why not just finetune the target angent or adversary directly wit pbrl?\n\n', 'questions': '\nWhich experiments were performed with real humans and which were with synthetic feedback?\nSee weaknesses\n\n'}, {'summary': ""The paper introduces BATTLE, an adversarial attack framework targeting DRL agents. The main focus is on behavior-oriented adversarial attacks, which aim to induce specific behaviors in a DRL agent, as opposed to merely reducing the agent's rewards or driving it to a pre-determined state. BATTLE uses an intention policy aligned with human preferences and an adversary to guide the victim DRL agent to imitate the intention policy. A weighting function is also introduced to optimize the effectiveness of the attack. The authors claim that BATTLE outperforms existing methods in inducing specific behaviors and can also be used to improve the robustness of DRL agents when used in an adversarial training setup.\n"", 'strengths': ""The availability of both code and demos enhances the paper's reproducibility. The paper enhanced the proposed methodology with convergence guarantees for BATTLE, adding rigor to the work.\n"", 'weaknesses': ""\nThe presentation quality could benefit from further refinement for better clarity and impact.\nThe method's reliance on extensive human labeling hampers its real-world applicability, raising concerns about scalability.\nThe paper could be strengthened by including more motivating examples from real-world scenarios. The assumption that an adversary can modify observations is strong and raises questions about practicality. For instance, if an adversary has the ability to control the sensor, they might as well directly control the effector, making an agent-based adversarial approach seem more practical. Additionally, the rationale for using preference-based RL remains unclear.\nThe paper lacks some critical methodological details. For example, it doesn't specify how the victim policy approximator is trained or the volume of data required, leaving gaps in the understanding of the implementation.\nThe experimental setup and evaluations could be more convincing. The choice of baselines (PA-AD and SA-RL), which are un-targeted attacks, makes the comparison seem potentially unfair. Moreover, while various defense methods like adversarial training, robust learning, policy ensemble, and policy distillation exist, the authors have limited their experimentation to ATLA.\n\n"", 'questions': '\nCould the authors elaborate on potential real-world applications for the proposed method and discuss the challenges that might arise in such contexts?\nExpanding the experimental results to include additional comparison metrics would be valuable. Specifically, how does PALM fare against targeted attacks and various other defense methods?\nWhat is the extent of annotation required, especially in relation to the complexity of the task at hand?\nCould you provide details on the training process for the victim policy approximator, including the amount of data needed for effective training?\nHow generalizable is the weighting function across different types of tasks and domains?\n\n'}, {'summary': 'This paper introduces BATTLE, a novel universal behavior-oriented adversarial attack method designed to induce specific behaviors in deep reinforcement learning (DRL) agents. Unlike prior approaches that focus on directing agents towards predetermined states or policies, BATTLE employs an intention policy aligned with human preferences for flexible behavior orientation, guiding the victim agent to imitate it. The paper demonstrates the effectiveness of BATTLE through empirical results across various manipulation tasks in Meta-world, showing its superiority over existing adversarial attack algorithms. Additionally, BATTLE enhances the robustness of DRL agents by training with the attacker, achieving a convergence guarantee under mild conditions, and proving effective even against the latest Decision Transformer agents. In summary, the paper makes contributions in the realm of behavior-oriented adversarial attacks on DRL agents, both in theory and practical applications.\n', 'strengths': '\nThe paper introduces an interesting and novel concept, proposing a new type of attack based on preference-based RL.\n\nThe design of the inner-level optimization and outer-level optimization is well-founded, and the paper provides theoretical analysis of the algorithm.\n\nThe paper sets up different scenarios for evaluating various agents and conducts detailed ablation studies.\n\n\n', 'weaknesses': '\nThe writing needs improvement, particularly in clarifying several terms and diagrams. For example, some terms like ""find a precise weighting function to balance the state distribution"" need better explanation. Clarification is also needed for the diagram in Figure 2.\n\nThe presentation of experimental results is somewhat confusing. The differences of scenarios in Figure 4 and 5 are not clear, and additional explanations are required for the target coordinates mentioned for Figure 4. Captions of Figures 7 (a) and (b) might need to be swapped, and sections (c) and (d) require clearer explanations.\n\nThe paper lacks a discussion of limitations, which should be addressed.\n\n\n', 'questions': ""\nIt's disappointing that the paper doesn't include RADIAL-RL[1] or WocaR-RL[2] as baselines when discussing robust training. Even if only ATLA is selected as a robust baseline, it would be valuable to mention other adversarial robust RL papers in the related work.\nIn the introduction, the paper illustrates the practical implications of targeted attacks on robotics, but the concern is raised that BATTLE is a white-box attack applying perturbations to states. In the context of robotics, its practical applicability is very limited. The paper could benefit from a more thorough clarification or discussion of this concern and its potential implications for practical applications. It fails to persuasively underscore the significance and relevance of this work within the field.\n\n[1]Robust deep reinforcement learning through adversarial loss\n[2]Efficient adversarial training without attacking: Worst-case-aware robust reinforcement learning\n""}]"
Understanding Large Language Models Through the Lens of Dataset Generation,"['Large Language Model', ' dataset generation']",9477,"[{'mark': [3, 4, 3], 'rate': 8, 'confidence': 4}, {'mark': [4, 3, 3], 'rate': 6, 'confidence': 4}, {'mark': [2, 3, 3], 'rate': 5, 'confidence': 4}, {'mark': [2, 3, 2], 'rate': 3, 'confidence': 5}]","There has been increased interest in using Large Language Models (LLMs) for text dataset generation subject to a desired attribute, e.g., for use in downstream fine-tuning or training. These works generally focus on a single quality metric of the generated text, typically accuracy on a downstream task. However, this fails to consider whether the model even has the ability to faithfully model the data distribution of the desired real-world domain. In contrast, in this work, we additionally focus on important distributional metrics agnostic to the downstream task, such as data diversity and faithfulness. We show that even in simple domains, generated datasets reveal inherent trade-offs between these metrics across models and training regimes. Further, we find that our metrics not only describe the generated dataset, but also capture key aspects of the underlying model. This allows us to characterize the generated datasets, individual models and by comparison the properties of different model families and training paradigms. By focusing on sub-distributions well-represented in the training data of LLMs, we can, for example, show that popular instruction-tuning techniques strongly decrease the LLM’s text generation abilities, with respect to distributional aspects like diversity.
","[{'summary': 'This work studies the attributes of dataset generation, which has recently been explored as a way to train task networks without needing a natural, human-generated dataset. Particularly, this work studies 4 domains/tasks that dataset generation can be applied to (e.g. SST-2), and studies the trade-offs between different attributes: faithfulness, diversity, conformity, complexity, and performance, all of which the authors measure automatically. The authors find significant differences between different model types, especially finding that instruction-tuned models differ from classical LMs. Neither paradigm seems to completely dominate.\n', 'strengths': '\nOverall, this type of contribution is sorely needed in dataset generation, which is still not a well-understood field\nThe attributes to study are diverse and relevant\nVery interesting and informative conclusions drawn about the tradeoffs, e.g. the loss of diversity in generated datasets when using instruction-tuned models\npaper is well presented and quite clear\n\n', 'weaknesses': '\nI have concerns wrt the measurement of some of the aspects:\nfaithfulness is measured as the accuracy on the synthetic set with a model trained on the reference (human) set. While being unfaithful is one reason this value may be low, it is not the only one. It is easy to imagine a faithful dataset on which this classifier will perform poorly, due to issues like style shift or poor generalization of the classifier. To be more concise: staking faithfulness on the accuracy of a classifier ignores the fact that this may be an issue of the classifier rather than the dataset that is being evaluated. \nsimilar issue with complexity, which is measured as inverse accuracy on a held out chunk of the synthetic set. While I agree that lower complexity will indeed raise this accuracy, high complexity is not the only reason this accuracy may decrease.\n\n\nOverall, I would suggest renaming these metrics. They likely correlate with the values they are described as, but it is overly presumptuous to label them this way as there are many other factors. More direct names (e.g. complexity -> self-accuracy or something like this) might be more accurate, leaving discussion of factors affecting these values (like complexity) to the discussion\nTradeoffs (Figure 2) are only shown in terms of temperature, which may be a confounding factor. It would be good to show other curves, e.g. for values of top-p, because it is not clear if these tradeoffs may have to do specifically with the specific warping effect that temperature has on sampling distributions. Alternatively, being more precise in the paper text, that these are tradeoffs over temperature as the variable, rather than general tradeoffs.\n\n', 'questions': 'Have you tried variables besides temperature to test the tradeoffs?\n'}, {'summary': 'This paper studies the text generation capabilities of various large language models, proprietary and open, instruction-tuned and vanilla, by evaluating synthetic datasets generated from them. The datasets are evaluated in terms of\n\ndiversity in vocabulary\ncomplexity, or difficulty in modeling them given by the performance of a model trained and evaluated in-distribution.\n\nBy comparing the generated datasets to existing (reference) datasets in similar tasks and domains, they are also evaluated in terms of\n3) faithfulness, given by the performance of models trained on the reference datasets and evaluated on the generated ones\n4) conformity, given by a measure of distributional similarity between the reference and generated datasets\n5) performance, given by the performance of models trained on the generated datasets and evaluated on the reference datasets\nBased on this evaluation framework, the paper discusses the tradeoffs between these aspects of generation quality, how they change across model families, and how instruction tuning affects these tradeoffs.\n', 'strengths': 'The evaluation framework is sensible and analyzing the capabilities of language models in terms of the tradeoffs between various aspects of generation quality is quite informative. The results of studying the effect of model size, the impact of instruction tuning, and that of the level of instruction tuning can potentially inform how to finetune future versions of language models.\n', 'weaknesses': 'This study has some missing details, several limitations, and potential confounders not accounted for in the experiments.\nMissing details\nMD1:The evaluation is done over four classification datasets, but the actual details of the tasks are missing in Section 4. Particularly for AGNews and ELI5, it is unclear what is being classified After reading the Appendix, the AGNews task seems to be some news genre classification, and the ELI5 task seems to be subreddit classification (maybe it should just be called ""subreddit classification""?) This issue can easily be fixed by including explicit details in Section 4.\nMD2: The motivation behind the chosen evaluation metrics is somewhat unclear. Particularly, faithfulness, conformity, and performance seem to be measuring the difference between the generated and reference data distributions. Why do we need these three variants? Relatedly, one would expect these metrics to correlate highly with each other. Analyzing this further would be helpful.\nLimitations and potential confounders\nL1: It is unclear how noise in the datasets (due to inaccurate labels) affects the trends seen in tradeoffs. For example, is the increase in diversity beyond the the conformity threshold in Fig 2 simply be due to noise? Having humans classify (subsets of) the generated datasets, and introducing the accuracy of the synthetic datasets as an additional metric could make this clearer.\nL2: The biases in the reference datasets could also be affecting conformity, faithfulness and performance. It might help to include multiple reference datasets per domain-task combination to evaluate whether the trends hold across them.\nL3: It is possible that the models used for generating datasets have seen the reference datasets either during pretraining or instruction-tuning. This would inflate the quality measures according to conformity, faithfulness, and performance. This issue cannot be dealt with directly, but it would help to check the zero-shot performance of the large language models on the reference datasets, and take it int account while inferring the tradeoffs.\n', 'questions': '\nIt would be helpful to put the reported diversity and complexity values in context. What are these values for the reference datsets?\nCan you elaborate on the motivation behind the three metrics comparing generated and reference datasets (see MD2)?\n\n'}, {'summary': ""This work studies the quality of synthetic data generated by LLMs. The major contribution of this work is proposing a framework to evaluate LLM's ability to generate synthetic data for specific tasks, and compare behavior across different LLMs. The evaluation framework consists of five different axes: performance, complexity, conformity, diversity and faithfulness. These properties are either evaluated using accuracy-based metrics, or modified version of existing tools (e.g., distict-n, mauve, etc.). Using this framework, this work compares LLMs with different size, from different model families and with or without instruction tuning. The empirical study reveals interesting tradeoffs among the five axes, and also report general performance trends on overall performance.\n"", 'strengths': '\nGenerating synthetic datasets is a very popular application of LLMs. This work provides a useful framework on evaluating this ability of LLMs.\nThe empirical study shows interesting tradeoff from the models, and the reported performance trends can be useful for related applications.\n\n', 'weaknesses': '\nI like the general idea of the proposed evaluation framework, but my biggest concern about this framework is the heavy use of DistilBERT accuracies in the evaluation framework. For the faithfulness metric, the framework is evaluating the performance of DistilBERT on the generated dataset. This confounds faithfulness with the difficulty (or complexity) of the dataset. This makes some of the finding questionable. For example, is there really a tradeoff between faithfulness and diversity/complexity, or is this correlation comes from the correlation between difficulty and diversity/complexity? I wonder if the authors can provide gold evaluation results for the DistilBERT models. \nThis study only focuses on synthetic data generation for relatively simple classification tasks. It would be great if this work can include evaluation on some more complex tasks.\nWhile this paper proposes four other properties addition to the performance. There is not much discussion on the relationship between these properties and the final performance. So while this study show many interesting findings, it is unclear what users should do besides checking the performance rankings.\n\n', 'questions': '\nFor the value k in the diversity metric, are you keeping the example size the same, or the token size same?\nHow do design or select prompts for the study conducted in your paper? Have you checked the sensitivity of the findings with respect to different prompts?\n\n'}, {'summary': 'This paper examines the generation of text datasets using Large Language Models (LLMs) with a focus on distributional metrics like data diversity and faithfulness. It reveals trade-offs between these metrics across different LLMs and training methods, highlighting the impact of popular instruction-tuning techniques on LLM text generation abilities.\n', 'strengths': '\nThe studied task on using LLMs for data generation is interesting and can be useful for the research community.\n\nThe authors conduct experiments on various datasets and LLMs (including both open-sourced and close-sourced models).\n\nThe paper is overall easy to read.\n\n\n', 'weaknesses': '\nThe authors only consider the most simple prompts for the target tasks. However, there are several works that aim to improve the quality of prompts to yield higher-quality datasets, some examples include:\n\n\nChung et al. ""Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions."" ACL 2023.\n\nYu et al. ""Large language model as attributed training data generator: A tale of diversity and bias."" NeurIPS D&B Track, 2023.\n\n\nIt is also important to note that some dimensions (e.g. diversity) have already been studied in this work. As a result, some of the conclusions in this paper are already known and there are not many new insights about using LLMs for data generation.\n\nUnsupported Claims. The paper raises a claim that ""reinforcement learning with human feedback (RLHF) in ChatGPT leads to a significant degradation in synthetic dataset generation capabilities."" However, the paper lacks a clear explanation of how the authors attribute this performance drop specifically to RLHF. A more detailed description of the experimental setup and results related to this assertion would enhance the paper\'s clarity and credibility.\n\nIn the main paper, the author only considers the average performance over different patterns, which can be less informative as different datasets show diverse patterns (according to Figure 5).\n\nFor the metrics, it is somehow not clear why using unique number of tokens as the metrics of Diversity.\n\n\n', 'questions': '\nCould you elaborate on why this paper primarily relies on simple prompts for target tasks, especially when recent research has emphasized advanced prompt engineering techniques for improving dataset quality? How might incorporating more sophisticated prompts affect the study\'s outcomes?\n\nGiven that some dimensions, like diversity, have already been studied in this work, what new insights or contributions does this paper bring to the field of using LLMs for data generation? \n\nIn the paper, you assert that ""reinforcement learning with human feedback (RLHF) in ChatGPT leads to a significant degradation in synthetic dataset generation capabilities."" Could you provide a more detailed explanation of the experimental design and results that support this claim?\n\nWhat conclusions can be made after your study? What are the recommendations for practitioners to use LLMs for training data generation? Currently, it is not very clear after reading this paper, so I feel readers will not benefit much from this paper.\n\n\n'}]"
Temporal Parallelization for GPU Acceleration of Spiking Neural Networks,"['Spiking neural networks', ' High-performance computing', ' GPU acceleration']",9476,"[{'mark': [1, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [3, 1, 2], 'rate': 3, 'confidence': 5}]","Inspired by neurobiological structures, Spiking Neural Networks (SNNs) are heralded as a significant advancement in deep learning, given their potential for superior computational efficiency. However, this potential often remains untapped on contemporary hardware platforms. Specifically, when deployed on standard GPUs, SNNs tend to require extended computation times, placing them at a disadvantage compared to traditional Artificial Neural Networks (ANNs). Such inefficiencies have somehow diminished enthusiasm for SNN research and presented the tangible challenge to achieving scalability. To address such a challenge, this study introduces a temporal parallelization method specifically tailored for accelerating the propagation dynamics of SNNs on GPUs. Furthermore, we furnish two distinct implementations\footnote{The source code will be made publicly available.} based on the CUDA and JAX frameworks respectively, ensuring adaptability across both single and multi-GPU setups. When benchmarked against several established SNN implementations, the empirical analysis confirmed the efficacy of our proposed method. Notably, with the Leaky Integrate-and-Fire model as a test case, the CUDA-based implementation achieved 5× to 40× acceleration on the A100 GPU.
","[{'summary': 'The authors describe a method and code for accelerating spiking neural\nnetworks (SNNs) on GPUs. They first claim to parallelize the temporal\nmembrane integration of a layer in an SNN and secondly divide the\ncompute onto multiple GPUs. They provide a template how to implement\nit in common ML frameworks such as JAX. Finally, they show that their\nimplementation outperforms other toolboxes.\n', 'strengths': 'The implementation seems to outperform current toolboxes in terms of runtime.  The authors show that this layer-first\napproach gives a considerable speedup on GPUs due to reduced memory movement.\n', 'weaknesses': 'While better implementation of simulating SNNs using GPUs has its merits,\nthe task is merely a software\nengineering task. The paper does not add any value in terms of novel\ninsights. This is in particular true since the ""temporal\nparallization"" argumentation is indeed a misnomer as the temporal dimension is not\ncomputed in parallel, but instead time of one layer is simply handled\nwithin one GPU kernel (but still computed sequentially if I understand it correctly).\nIf one wanted to design a custom CUDA kernel and would assume that\nonly feed-forward layers are allowed, this would be just the standard\napproach to do, I don\'t see any innovative aspects here. In\nparticular, equation 3 is just a re-writing (inserting) of x(t−1,n),\nthere is no ""transformation"" I can see. Note that vi(t,n) still\nis a function of previous times, vi(t−1,n). All what is done is to\ncompute all time steps per layer first before sending the full output\nspike train to the next layer. This will obviously not work for\nrecurrent SNNs. \nAlso, the authors do not even provide their own optimized CUDA kernel\n(which would have more merit), but instead rely on generic toolboxes\nlike JAX. The code listings do not provide any details of the\nimplementation and are more like a tutorial how to use it.  \nOverall, while the implementation might be useful as it improves the\nruntime of SNNs compared to the (apparently very non-optimized)\nstandard SNN packages, the paper does not provide any new scientific\ninsights. It is also not discussed that the approach works only for\nfeed-forward SNNs. Moreover, the presentation of ""temporal\nparallelization"" is not correct (as it just points to a fused\nsequential CUDA-kernel). Finally, the layer-first approach (fusing\nkernels to reducing memory operations) and dividing the compute for\nmultiple GPUs are rather standard practices in GPU programming in\ngeneral and not novel enough for a research oriented conference\ncontribution in my opinion.\n', 'questions': '\nIn Eq 3: xi(t,n) should be xi(t,n−1)\n\n'}, {'summary': 'This paper trys to use a temporal parallelization method to accelerate the propagation dynamics of SNNs on GPUs. The feature it claims is a cross-timestamp acceleration of LIF model. With the Leaky Integrate- and-Fire model as a test case, the CUDA-based implementation achieved 5× to 40× acceleration on the A100 GPU.\n', 'strengths': 'The author proposed temporal parallelisation method tailored for universal SNN units on single and multiple GPUs. It supports both CUDA and JAX frameworks.\n', 'weaknesses': ""\nThe motivation behind this paper lacks clarity. Spiking Neural Networks (SNNs) are not typically intended for deployment on GPUs, meaning that a GPU is not the most suitable platform for SNN deployment. Without a demonstration of the clear benefits of utilizing GPUs for SNNs deployment as opposed to other platforms, the paper's underlying motivation remains unconvincing.\n\nHow does this paper leverage GPU to implement true spiking mechanism? It is not clear or discussed. Is it only considering simulating the mechanism of the Leaky-Integrate-and-Fire model behavior? Plus, there’s no true spiking signals in GPU, addressing the temporal information is not really Spiking implementation. This paper doesn’t clarify the basic concept. \n(In some sense, parallelizing temporal information is possible, but there’s conversion between spiking temporal information and the muti-bit digital temporal information for GPU? Then what’s the conversion cost?)\n\nAlthough this paper is based on the computational model of LIF, but it does not clearly describe how training and inference is done, respectively. Training an SNN is hard, and it is not discussed at all in this paper, so it’s only about inference, or even, the simulation of inference?\n\nLast but not least, most importantly, this paper does not provide any AI-model based results, such as accuracy, performance, respective speed-up, etc, let alone thorough analysis based on the comparison of results. The only result is a table based on a single-layer toy model? For multi-GPU, where is Fig. 4, seems this paper is incomplete?\n\n\n"", 'questions': '\nHow SNN neuron spiking behaviour described in Eq.1 and Eq. 2 reflected in GPU?\n\n'}, {'summary': 'This paper presents an SNN-based acceleration strategy with parallelized temporal computation that supports both single and multiple GPUs.\n', 'strengths': 'Largely improved SNN inference speed compared to the previous implementation. \nCompatibility with both single and multi-GPU processing.\n', 'weaknesses': 'W1: Figure 4 is missing. \nW2: The biggest bottleneck of this work is that the accuracy benchmarking is completely missing in the paper. I understand the inference speed-up is very important in SNN, but I cannot see the reason why the paper chose not to report the accuracy. It is important to verify the proposed implementation with different SNN model architectures. E.g.. ResNet vs. VGG. \nW3: It seems like the implementation can only accelerate the inference rather than training, which I think is not powerful enough.\n', 'questions': 'Please refer to the Weakness.\n'}, {'summary': 'This paper proposes a temporal parallelization method for SNNs that can accelerate SNNs on both single or multi GPUs with up to 40x acceleration.\n', 'strengths': 'The training of deep SNNs requires much more time and memory consumption. Thus, it is meaningful to explore the acceleration of simulating SNNs on GPUs.\n', 'weaknesses': 'The details of the proposed method are not described clearly in this paper. To make matters worse, the Supplementary Material is the same as the main paper.\n', 'questions': 'In Figure 3, how the propagation of the spiking neuron layer is paralleled? I assume that V[t] is still computed in serial. For an input sequence with length T, the time complexity is still O(T).\nIn section 3.2, the authors claim that the SNN accelerated by pipeline in multiple GPUs may have a faster speed than using a single GPU. However, I am afraid that the communication time between GPUs will be the bottleneck. According to my experience, the communication time is much longer than any other time. Thus, the pipeline method is seldom used in training, and the Distributed Data Parallel is the mainstream.\nIn Table 1, the time of SpikingJelly with or without CuPy does not have much difference, which is against my experience. \nWhere is Figure 4?\n'}]"
FSN: Feature Shift Network for Load-Domain Domain Generalization,"['Fault diagnosis', ' Deep learning', ' CNN', ' Domain Generalization', ' Load-domain Domain Generalization']",9472,"[{'mark': [2, 1, 1], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 5, 'confidence': 3}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 4}, {'mark': [2, 2, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 2, 1], 'rate': 3, 'confidence': 5}, {'mark': [2, 4, 2], 'rate': 6, 'confidence': 4}]","Conventional deep learning methods for fault detection often assume that the training and the testing sets share the same fault pattern spaces and domain spaces. However, some fault patterns are rare, and many real-world faults have not appeared in the training set. As a result, it’s hard for the trained model to achieve desirable performance on the testing set. 
In this paper, we introduce a novel domain generalization, Load-Domain (LD) domain generalization, which is based on the analysis of the CWRU bearing dataset and its domain division method. For this scenario, we propose a feature shift model called FSN (Feature Shift Network). In the bearing dataset, domains are divided based on different operating conditions which have specific loads, so it’s equivalent to load-based domain division. Moreover, the domain label corresponds to the actual load magnitude, making it unique as it contains physical information, which can boost detection accuracy on unknown domain beyond the training set. According to the knowledge above , FSN is trained for feature shift on adjacent source domains, and finally shifts target domain features into adjacent source domain feature space to achieve the purpose of domain generalization.
Extensive experiments on CWRU demonstrate that FSN is better than the existed models in the LD domain generalization case. Furthermore, we have another test on MNIST, which also shows FSN can achieve the best performance.
","[{'summary': 'This paper targets a domain generalization problem for fault diagnosis of the bearing dataset and proposes a new model, called the feature shift network (FSN), to adjust the features between source and target domains. The numerical experiment using CWRU and MNIST datasets is conducted to evaluate the effectiveness of the proposed FSN.\n', 'strengths': '\nThe motivation to exploit the additional information of the problem by assuming the specific task of fault diagnosis in bearing datasets is good.\nThe domain generalization problem treated in this paper is important.\n\n', 'weaknesses': '\nThe paper is not well written and has a lot of unclear points. For example, the detailed setting, such as loss function and calculation of each model component, is omitted. It is hard to understand the technical novelty and advantages of the proposed method.\nI cannot find the formal definition of the load-domain (LD) generalization problem treated in this paper.\nIn Table 1, the performance gain of the proposed FSN variants is marginal.\nThe motivation of the evaluation using the MNIST dataset is unclear.\n\n', 'questions': '\nWhat does the ""Relation"" mean in Table 1?\nHow does the proposed FSN exploit the physical meaning of domain labels for model training?\nIs the target domain data accessible in the load-domain generalization? In general, the target domain data is not accessible in domain generalization.\n\n'}, {'summary': 'Traditional deep learning methods for fault detection usually assume that the training set and the test set share the same fault mode space and domain space. Based on the analysis of CWRU bearing data set and its domain division method, this manuscript proposes a Feature Shift model called FSN (Feature Shift Network) to improve the detection accuracy of unknown domain, which can divide domains according to different operating conditions with specific loads, and take advantage of the physical significance of domain labels.\n', 'strengths': '1.This manuscript proposes the idea of ""exploitability"" of domain-related information, and it may be a point worth exploring further.\n2.This manuscript is written in a standard and clear hierarchy,  and the structure is easy to follow.\n', 'weaknesses': ""1.In this manuscript, a parameter with physical significance is used as a domain label, and then the related features of the domain are used to assist classification. But now that labels have physical meaning, what happens if they are input directly to the network with other data? We didn't see the related comparison experiments. So it is not  convincing.\n2.Few comparison experiments are conducted.\n3.The detailed design of the model, including the loss function, is not explained in sufficient detail.\n"", 'questions': '1.Why label a domain with a piece of information that can be numerically and physically meaningful, and how is that different from feeding it directly into a neural network?\n'}, {'summary': 'The paper aims to address the multi-source domain generalization problem by proposing a feature shift network (FSN). Distinct from traditional domain generalization, the problem of interest has additional information of inter-domain linear relations in the form of domain labels. By taking advantage of such information explicitly in the proposed model, superior performance can be achieved.\n', 'strengths': '--The paper attempts to addresses the domain generalisation problem derived from a real-world application. The problem itself is somewhat novel and has not been extensively studied and hence solving such a problem is of great significance.\n', 'weaknesses': '--The introduction section lacks essential information of problem definition, description of methods and brief experimental results. This makes it less readable to the readers. For example, it is not clear what the ""Load-Domain"" means and how the feature shift model handles the problem.\n--The section of related work is not well organized. More focus should have been put on the most closely related works (i.e. domain generalization in fault detection problems) rather than a broad review of fault detection methods. In addition, the relations between existing works and this work should also be discussed.\n--In table 1, Multi FSN does not perform the best as Multi DANN has a result of 83.3.\n--The authors fail to compare with SOTA domain generalization methods.\n--There exist language issues/typos/notation inconsistency in the manuscript. E.g., ""P(1), P(2), ..., P^{(K)}""; ""edge distribution"" should be ""marginal distribution""; ""1 data of source domain a+1 and 9 data...""; ""This thesis DANN domain adaptive network...""; ""the ERM said empirical ..."";\n', 'questions': '\nWhat is the loss function of the network?\nWhat is the input (images?) and the output of the model?\n\n'}, {'summary': 'This paper introduces a special domain generalization scenario termed Load-Domain domain generalization and proposes a new model, the Feature Shift Network (FSN), tailored for this scenario. The authors conduct experiments on the CWRU bearing dataset and the MNIST dataset, comparing FSN with classical fault diagnosis methods and other domain generalization methods.\n', 'strengths': 'The experimental results show good performance of FSN in certain scenarios and hence its potential for practical applications in fault diagnosis and domain generalization.\n', 'weaknesses': '\nThe writing of the paper should be substantially improved. It reads like bad machine translation and has a lot of grammatical and terminological errors.\nThe theoretical foundation of the FSN model could be explained in more detail. The model architecture shown in Fig. 3 requires further clarification and motivation.\nExperiments are only conducted on two datasets, with limited baseline methods for comparison. It is unclear how the proposed method performs on other datasets that also have ""linear"" domain labels.\nThe accuracy values do not have confidence intervals.\n\n', 'questions': 'See above.\n'}, {'summary': 'The paper introduces a novel approach called Load-Domain (LD) domain generalization for fault detection in situations where the training and testing sets have different fault pattern spaces and domain spaces. The authors propose a feature shift model called FSN (Feature Shift Network) specifically designed for LD domain generalization. The model is trained on adjacent source domains to learn feature shifts and then applies these shifts to target domain features, enabling generalization beyond the training set. The approach is validated through extensive experiments on the CWRU bearing dataset and the Rotation MNIST dataset, demonstrating superior performance compared to existing models in LD domain generalization scenarios.\n', 'strengths': '\nThe topic of Domain Generalization is highly relevant and of significant interest to the research community. Furthermore, the paper addresses the important aspect of leveraging domain information during the training process, which has gained increased attention in recent times.\nThe paper is well-written and easily comprehensible, effectively conveying its ideas and findings to the readers.\n\n', 'weaknesses': '\nThe LD domain generalization problem setting addressed in the paper is acknowledged as a highly specialized case, which limits its broader contribution to the field.\nThe experimental results presented in the paper lack persuasiveness. Firstly, the dataset used is small and may not accurately represent real-world scenarios. Additionally, the chosen baselines are outdated, primarily predating 2018, despite the emergence of numerous domain generalization methods since then. It is recommended to refer to recent surveys for a comprehensive overview of the latest approaches, e.g., [1].\nWhile the main idea of the paper is generally understandable, there are instances where sentences may create misunderstandings, and insufficient definitions of the problem and task settings are found throughout the paper. Notably, the captions for Figure 1 may inaccurately describe Figure 1(b), potentially causing confusion among readers.\n\n[1] Domain Generalization: A Survey\n', 'questions': 'Please review the weakness section, and kindly correct any misunderstandings that may exist in my assessment.\n'}, {'summary': 'In this paper, the authors introduce a new Load-Domain (LD) domain generalization setting, where the domain label corresponds to actual load magnitude. To serve the scenario, the authors propose a feature shift model (FSN) to learn feature mapping between adjacent domains according to the physical meaning in domain labels. Experiments are carried out on CWRU bearing dataset and rotated MINST datasets to showcase the performance.\n', 'strengths': '\nThe idea of employing the physical meaning of domain labels to achieve generalization on consecutive domains makes sense to me. \nThe new setting of LD domain generalization also seems suitable for the benchmark of CWRU dataset, where the physical meaning of domain labels can be clearly defined.\n\n', 'weaknesses': '\nThe paper’s writing and formatting are not good enough, making it sometimes hard to read and understand. There exist many formatting errors (e.g., the use of spaces in Sections 1 and 2, the math symbol consistency in Section 4.1: P(1) and P^{(K)}). The caption of Figure 1 is duplicated. The abbreviation in Paragraph 3, Section 2 might be RAP. In the second line of paragraph in section “Distribution Law Conjecture”, F_p should be the the mapping relation between features, not labels.\nBesides the ones from 1., the Experiment part (e.g., paragraph 4 in “Classical Model Contrast” part) is hard to understand. Bad formatting and discontinuous sentences make it unreadable to me.\nKey references are absent. In the first paragraph of Section 4.2, methods aligning the three types of distributions should be cited to justify the categorization. The compared methods in “Comparison with Classical Models” should also be referred to, and the Li et al. (2018) reference in this paragraph is wrongly cited, this paper should be “Deep Domain Generalization via Conditional Invariant Adversarial Networks”.\nAs to the experimental results, the metric of Table 1 is not clearly stated. Also, the experimental details like backbone choice, learning rate, optimization schedules are not provided.\nThe setting is still too limited. The current method and experiments only focus on generalizing from highly relevant and sequential source domains to a target domain close to the last seen source domain. The performance of the proposed method should be further evaluated on broader settings where the relationship of source and target domains is not fixed. Also, the setting seems much relevant to that of Continuous Domain Generalization, which should be discussed.\n\n', 'questions': 'Apart from those in weakness, the authors are encouraged to experiment on larger domain generalization benchmarks. Moreover, the compared methods are not recent enough, therefore more experiments should be added to provide a more comprehensive comparison.\n'}, {'summary': 'The paper proposes a feature shift network (FSN) for a new domain generalization task called load-domain (LD) generalization based on analyzing the CWRU-bearing dataset. The key idea is to leverage domain labels to shift target features into adjacent source domains. The method is evaluated on the CWRU and rotated MNIST datasets by comparing them to existing domain generalization techniques.\n', 'strengths': 'The application of domain generalization on the problem of fault detection is novel.\n', 'weaknesses': 'The paper lacks novelty as feature shift is explored in prior work. The theoretical analysis relies on unproven conjectures and lacks rigor. More comprehensive empirical evaluation on realistic datasets and comparisons to recent benchmarks are needed to demonstrate effectiveness.\n', 'questions': 'The novelty of the proposed feature shift network (FSN) is questionable given prior work on feature shift for domain generalization. The current paper does not sufficiently differentiate FSN from these existing methods. \nThe paper also lacks theoretical analysis regarding the generalization abilities of FSN.\n Empirically, evaluation is limited to two small datasets, which cannot sufficiently demonstrate effectiveness and robustness for the load-domain generalization task. More extensive testing on diverse realistic datasets are needed.\n'}, {'summary': 'n/a\n', 'strengths': ""The paper addresses a challenge in deep learning-based fault detection, where real-world faults may not always appear in the training set. This limitation makes it difficult for conventional models to generalize well to unseen fault patterns. To address this, the authors introduce a domain generalization method, Load-Domain (LD) domain generalization, specifically designed based on the CWRU bearing dataset. In this method, the domains are divided based on different operating conditions that have specific loads, which correspond to the actual load magnitude. This inclusion of physical information helps enhance the model's accuracy for unknown domains. The authors propose the Feature Shift Network (FSN), which is trained to shift features between adjacent source domains and the target domain for better generalization. The effectiveness of FSN is shown through experiments on both the CWRU bearing dataset and the MNIST dataset, where FSN outperforms existing methods.\n"", 'weaknesses': ""\nThe authors tackle a crucial issue in fault detection where conventional models may not perform well on unseen fault patterns.\nThis novel domain generalization approach, based on real physical properties (load magnitude), can potentially be more representative and robust than abstract or purely data-driven domain divisions.\nThe model's applicability on both the CWRU bearing dataset and the MNIST dataset suggests it is versatile and not limited to one type of data.\nThe authors compare their model with classical fault diagnosis methods, showing its superiority in specific scenarios.\nThe paper appears to have a well-structured format, with sections dedicated to reviewing the current state of research, introducing their novel domain generalization method, and discussing experimental results.\n\n"", 'questions': '\nThe assumption that domain label corresponds to actual load magnitude might not hold for all real-world scenarios. It may be beneficial to test scenarios where this is not the case.\nIntroducing domain-specific information like load magnitude could risk overfitting to specific domain characteristics. The generalization capability of the model in truly unseen domains is a concern.\n\n'}]"
"Ask Again, Then Fail: Large Language Models’ Vacillations in Judgement","['Large Language Models', ' Uncertainty', ' Evaluation', ' In-Context Learning', ' Alignment', ' Multi-round dialogue', ' Robustness']",9468,"[{'mark': [3, 4, 3], 'rate': 6, 'confidence': 4}, {'mark': [3, 3, 2], 'rate': 6, 'confidence': 4}]","With the emergence of generative conversational large language models (LLMs) like ChatGPT, serving as virtual assistants in various fields, the stability and reliability of their responses have become crucial. However, during usage, it has been observed that these models tend to waver in their judgements when confronted with follow-up questions from users expressing skepticism or disagreement. In this work, we draw inspiration from questioning strategies in education and propose a \textsc{Follow-up Questioning Mechanism} along with two evaluation metrics to assess the judgement consistency of LLMs before and after exposure to disturbances. We evaluate the judgement consistency of ChatGPT, PaLM2-Bison, and Vicuna-13B under this mechanism across eight reasoning benchmarks. Empirical results show that even when the initial answers are correct, judgement consistency sharply decreases when LLMs face disturbances such as questioning, negation, or misleading. Additionally, we study these models' judgement consistency under various settings (sampling temperature and prompts) to validate this issue further, observing the impact of prompt tone and conducting an in-depth error analysis for deeper behavioral insights. Furthermore, we also explore several prompting methods to mitigate this issue and demonstrate their effectiveness.
","[{'summary': ""The research addresses a critical concern in the use of generative conversational large language models (LLMs) like ChatGPT, focusing on their judgement consistency when faced with follow-up questions expressing skepticism or disagreement. Drawing inspiration from educational questioning strategies, the study proposes a FOLLOW-UP QUESTIONING MECHANISM and introduces evaluation metrics to assess LLMs' consistency before and after disturbances. The study evaluates ChatGPT, PaLM2-Bison, and Vicuna-13B across reasoning benchmarks, revealing a decline in judgement consistency even when initial answers are correct. The research explores the impact of disturbances, sampling temperature, and prompts, conducting an in-depth error analysis. Moreover, it introduces and evaluates various prompting methods to mitigate this issue, demonstrating their effectiveness.\n"", 'strengths': ""\nComprehensive Evaluation: The research evaluates multiple LLMs (ChatGPT, PaLM2-Bison, and Vicuna-13B) across eight reasoning benchmarks, ensuring a comprehensive analysis of their performance under different conditions.\nThorough Analysis: The study conducts a detailed analysis of disturbances, sampling temperature, prompts, and prompt tone, offering valuable insights into the factors affecting judgement consistency.\nEffective Solutions: The research explores various prompting methods and demonstrates their effectiveness in mitigating the issue, suggesting practical solutions for enhancing LLMs' reliability.\n\n"", 'weaknesses': ""\nLimited Scope of LLMs: The study evaluates a specific set of LLMs (ChatGPT, PaLM2-Bison, and Vicuna-13B), potentially limiting the generalizability of the findings to other models in the rapidly evolving landscape of conversational AI.\nScope of Disturbances: While disturbances like questioning, negation, and misleading are considered, the study might benefit from exploring a wider range of disturbances to provide a more comprehensive understanding of LLMs' judgement consistency challenges.\nLack of Real-World Application: The research focuses on theoretical evaluation and proposed mechanisms; it would strengthen its impact by discussing practical implications and real-world applications of the proposed solutions.\n\n"", 'questions': '\nConsidering the rapid advancements in AI technologies, how might the results differ when applied to newer or upcoming LLMs? Is there room for future research to address this limitation?\nCan you provide insights into how the proposed mechanisms and solutions could be practically applied in real-world scenarios, especially in fields where LLMs are extensively used, such as customer support or healthcare?\n\n'}, {'summary': 'This paper investigates the problem of answer consistency in large language models (LLMs), especially when prompted with questioning, disagreement, or misleading input. The authors designed a follow-up questioning mechanism, inspired by questioning strategies in education, to experiment with LLMs. After an initial correct response, the authors attempted prompts of questioning, disagreement, or misleading input in two different ways, one of the three and all of the three in a sequential manner. The authors conducted experiments on ChatGPT, PaLM2-Bison and Vicuna-13B using four kinds of objective reasoning questions: arithmetic reasoning, commonsense reasoning, symbolic reasoning, and knowledge reasoning. They found that a significant decrease in judgement consistency occurred after the models were prompted with questioning, disagreement, or misleading input, both in isolation and in sequence. The authors also tried some mitigation methods, but there is still room for improvement\n', 'strengths': '\nThe paper is clearly written and easy to follow. \nIt addresses the critical issue of trustworthiness in large language models. \nThe well-designed experiments and mitigation approaches clearly demonstrate the problem of LLMs and draw attention to its importance.\n\n', 'weaknesses': '\nI do not see a major problem with the paper. While some people may prefer a paper that proposes a new model, this investigative paper could still be a valuable contribution to the field.\n\n', 'questions': ""\nI didn't understand the second sentence in footnote 1.\n\nModification Rate (M. Rate) was not clear to me.\n\n\n""}]"
Do Current Large Language Models Master Adequate Clinical Knowledge?,"['Large Language Model', ' Medical Large Language Model', ' Clinical Knowledge', ' Knowledge Graph']",9466,"[{'mark': [2, 3, 2], 'rate': 5, 'confidence': 4}, {'mark': [3, 2, 2], 'rate': 5, 'confidence': 4}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 2}]","Large Language Models (LLMs) show promising potential in solving clinical problems. Current LLMs, including so-called medical LLMs, are reported to achieve excellent performance on certain medical evaluation benchmarks, such as medical question answering, medical exams, etc. However, such evaluations cannot assess whether LLMs have mastered sufficient, compressive, and necessary medical knowledge for solving real clinical problems, such as clinical diagnostic assistance. In this paper, we propose a framework to assess the mastery of LLMs in clinical knowledge. Firstly, we construct a large medical disease-based knowledge base, MedDisK, covering 10,632 common diseases across 18 clinical knowledge aspects, which are crucial for diagnosing and treating diseases. Built on that, we propose a MedDisK-based evaluation method MedDisKEval: We prompt LLMs to retrieve information related to these clinical knowledge aspects. Then, we evaluate an LLM's mastery of medical knowledge by measuring the similarity between the LLM-generated information and the content within our knowledge base. Our experimental findings reveal that over 50% of the clinical information generated by our evaluated LLMs is significantly inconsistent with the corresponding knowledge stored in our knowledge base. We further perform a significance analysis to compare the performance of medical LLMs with their backbone models, discovering that 5 out of 6 medical LLMs perform less effectively than their backbone models in over half of the clinical knowledge aspects. These observations demonstrate that existing LLMs have not mastered adequate knowledge for clinical practice. Our findings offer novel and constructive insights for the advancement of medical LLMs.
","[{'summary': ""The paper introduces a large-scale medical disease-based knowledge base MedDisK, covering 10,632 common diseases and 18 clinical knowledge to evaluate LLMs. The purpose of the dataset is to  (a) include common diseases (b) involve disease base knowledge and (c) ensure that the sourcing of the dataset is such that it remains publicly inaccessible to prevent leaks during testing.\t\nFirst filter common diseases (determined by clinical experts based on ICD10 databases and frequency in EHR)  resulting in 10,632 common diseases. Then  employ clinical experts to define 18 disease-based clinical knowledge aspects that are crucial to medical decision-making (diagnoses, examinations, treatments) for each of the diseases. They use this database to probe LLMs and evaluate the mastery of clinical knowledge. They show that their scoring measures are in high agreement with clinical experts' subjective evaluation.  \nUsing the evaluation metrics they show that existing LLMs have not mastered adequate knowledge for clinical practice (showing that over 50%  of the generated information is not consistent with their KB) and are not ready to be foundation models for clinical domain.\n"", 'strengths': ""The paper does a good job in communicating the ideas. I agree with the author's motivation that for the LLMs to be accepted as foundation models they need to have mastered adequate clinical knowledge. This is an important question and needs comprehensive evaluation.\n"", 'weaknesses': 'The paper could provide a more thorough justification for the introduction of the new medical dataset, especially in the context of existing evaluation datasets. The paper mentions that the existing evaluation datasets cover only some common diseases and lack extensive coverage of knowledge across various aspects of diseases. This reviewer feels that this needs to be substantiated with more thorough comparison. \nWhile it is surprising that most of the LLMs perform poorly (with over 50%) predicted to be completely wrong. The evaluation procedure used to arrive at this conclusion requires further elaboration.\nOverall I am not fully convinced that this dataset MedDisK  and the outlined evaluation procedure is robust for determining LLMs clinical knowledge yet. \nThis reviewer has listed all the concerning questions in detail below.\n', 'questions': ""What is the source of the EHR resource used in the preliminary making of the dataset?\nThe authors state “The existing medical evaluation benchmarks are predominantly based on question-answering (QA) tasks. These benchmarks collect questions from diverse sources, including medical examinations, electronic health records, online resources, and expert crafting……cover only some common diseases and lack extensive coverage of knowledge across various aspects of diseases. ”  Can you compare each of these resources the paper is referring to in this sentence with MedDisK in terms of coverage of common diseases, disease base knowledge and public availability?  How does this compare with other existing medical relational databases - MIMIC, i2b2, iBKH KG etc?\nI understand that the paper does interval sampling (10 examples from each interval) and engages clinical experts to provide a categorical standard - wrong, correct or partially correct.  And this resulted in the following standard (0-0.3 is wrong) and (0.3 to 0.8 is partially correct) and (0.8 to 1.0 is correct). How representative are these categories? Did the experts find that all the samples in 0.8 to 1.0 are correct and correspondingly all in 0-0.3 are wrong? Can you provide more representative examples or more thorough classification of the “Completely Wrong” category?\t\nSince LLMs response is post-processed using the NER model I think the NER model's performance is extremely crucial to evaluation. How well does it perform in identifying medical entities? From the analysis conducted in Table 8, it appears that all the LLMs are underperforming in identifying symptoms, affected sites, etc., while they generally perform well in recognizing population ages involving numeric entities. \nWould it be considered a correct hit if the model predicts 'GI tract' instead of 'digestive system' in the examples from Table 3? What kind of standardization was performed in evaluating LLMs response with the experts output?\nWhat according to the authors are the limitations of the dataset and the evaluation procedure outlined here?\n""}, {'summary': 'To evaluate whether LLMs have mastered sufficient clinical knowledge, the authors first propose a large-scale medical disease-based knowledge base named MedDisK. They then develop MedDisKEval, a method that prompts LLMs to retrieve information on clinical knowledge aspects and measures the similarity between LLM-generated information and MedDisK. Results show that most of the current LLMs do not have sufficient clinical knowledge.\n', 'strengths': '\nThe motivation is clear, and it is interesting to know whether current LLMs have mastered sufficient domain knowledge to help in the medical domain.\nThe authors conduct extensive experiments with 12 LLMs, which include general LLMs and medical LLMs.\nThe authors provide sufficient examples of prompt instructions, knowledge aspects, and LLM responses, which make it easier for readers to grasp the basic idea of the paper.\n\n', 'weaknesses': '\nOne significant issue with this paper is that the authors may overstate the implications of their evaluation results. The experiments are exclusively conducted in Chinese. However, this critical detail is not adequately emphasized in the main paper, particularly in their conclusion that ""none of the evaluated LLMs have mastered sufficient knowledge to handle real clinical problems effectively."" Based on their evaluation, the valid conclusion should be that LLMs do not possess adequate clinical knowledge in the Chinese language, and this finding cannot be generalized to other languages.\n\nIn the second paragraph of the introduction, the authors claim that current QA-based medical evaluation datasets cannot evaluate whether LLMs have mastered sufficient medical knowledge because those datasets cover only some common diseases. It would be more robust if the authors could further justify this statement with some analysis (e.g. to quantitatively show the coverage of diseases in the existing benchmarks).\n\nFor the proposed knowledge base MedDisK, it would be better for authors to include more details of the construction process. For example, how is the agreement among the clinical experts, is there any strategy used to tackle disagreement, and will this process introduce any additional human bias?\n\nIn section 3.2.1, the authors ""employ a specialized NER model to identify and extract medical entities from the text"". However, the exact name and citation of the used NER model are missing, and it will be more convincing to include an analysis of the accuracy of the NER model as incorrectly recognized entities could impact the evaluation results of LLMs.\n\n\n', 'questions': '\nThe authors claim that current QA-based medical evaluation datasets cover only some common diseases. However, in section 3.1 where the authors introduce their proposed knowledge base, it is said that ""We first select a subset from the ICD10 database according to whether the diseases are common in clinical (determined by clinical experts) and are statistically frequent in EHR (Electronic Health Record), resulting in 10,632 common diseases."" I wonder why they also consider common diseases in their knowledge base?\n\nIn the section of ""Disease-Knowledge-based Automated Scoring"", are there any better metrics to evaluate the similarity? The token-level BLEU-1 and ROUGE-1 cannot consider semantic meaning, and the M3E model is described as a sentence-level metric, whereas the evaluation in this context focuses on the meaning of individual tokens.\n\nIn Table 3, one completely wrong example of LLM response is ""ok, I see"". Since the authors mention that they employ a specialized NER model to identify and extract medical entities from the text, I wonder why the NER model could extract such words from the responses.\n\nIn section 4.2.2, the authors assign scores of 0, 5, and 10 to ”Completely Wrong,” ”Partially Correct,” and ”Basically Correct,” respectively, to calculate a total score. It\'s important to clarify how they arrived at the values ""0, 5, 10"" for this scoring system.\n\n\n'}, {'summary': 'The paper evaluates the current performance of medical LLMs by creating a benchmark and testing existing said LLMs against it. This work creates MedDisK, a database designed to test the medical knowledge of LLMs on different ""clinical knowledge aspects"". These properties are not limited to those used just for diagnosis; example properties include patient population, treatment principles, departments (relevant medical departments), etc. This work also introduces MedDisKEval, a method that includes automated and clinical-expert-dependent steps to grade the performance of LLMs. Notably, the paper concludes that most current medical LLMs do not perform better than the base LLMs they are built upon.\n', 'strengths': '\nThe development of a medical knowledge benchmark involved consulting 20 clinical experts over 10 months is good. This paper focuses largely on Chinese data/expert consult, but the presentation itself features relevant English translation.\nCreating a clear evaluation method combining automated/expert consultation is also useful. \nThe conclusions of the evaluation point out specific flaws in existing medical LLMs; certain models evaluate different features poorly, for example. This provides a concrete criticism/evaluation of those methods that can be built upon.\n\n', 'weaknesses': '\nThe creation of a medical LLM benchmark itself does not make fundamental improvements over existing benchmarks developed in medical LLM research. As an example, the Singhal et al. 2023a paper also tested modern LLMs with human evaluation (MultiMedQA). Creating another benchmark by itself is not a conceptually novel improvement, and this work did not sufficiently argue for its improvement above these existing models/evaluations.\nThis work does not go into as much detail about the representation of medical knowledge in LLMs, providing only a benchmark without technical insight of what the LLMs might be doing or how they encode medical information.\nUsing MedDisKEval seems expensive or possibly unreliable. Someone seeking to use this evaluation method may need to consult expert opinion themselves, just to calibrate the alignment scores. The motivation behind the linear combination of BLEU-1, ROUGE-1 and cosine sim is empirically driven and is not inherently convincing as a metric.\n\n', 'questions': '\nThe database MedDisK was constructed with ""clinical experts and machine assistance."" Further clarification is required; what was the exact process of constructing the database, and how was machine assistance used? \nThis work focused on a set of LLMs that is somewhat disjoint from existing popular medical LLMs. For example, MedPaLM?\n\n'}]"
SIMULTANEOUS GENERATION AND IMPROVEMENT: A UNIFIED RL PARADIGM FOR FJSP OPTIMIZATION,"['Reinforcement Learning', ' Flexible Job Shop Schedule Problem', ' FJSP']",9463,"[{'mark': [1, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [2, 2, 3], 'rate': 3, 'confidence': 3}, {'mark': [2, 1, 2], 'rate': 3, 'confidence': 3}, {'mark': [1, 1, 2], 'rate': 3, 'confidence': 4}]","We present an end-to-end reinforcement learning framework designed to address the Flexible Job Shop Problem (FJSP). Our approach consists of two primary components: a generative model that produces problem solutions stepwise, and a secondary model that continually refines these (partial) solutions. Importantly, we train both models concurrently, enabling each to be cognizant of the other's policy and make informed decisions. Extensive experimentation demonstrates that our model delivers better performance in shorter time on several public datasets comparing to baseline algorithms. Furthermore, we highlight the superior generalizability of our approach, as it maintains strong performance on large-scale instances even when trained on small-scale instances. It is worth noting that this training paradigm can be readily adapted to other combinatorial optimization problems, such as the traveling salesman problemand beyond.
","[{'summary': 'The paper introduces a reinforcement learning framework tailored for the Flexible Job Shop Problem (FJSP). The methodology leverages graph neural networks, allowing the model to handle FJSP instances of varying scales. The main novelty consists of simultaneous generation and improvement: a generative model sequentially produces solutions while an improvement model refines them. Both models are trained concurrently via reinforcement learning. The approach is at least an order of magnitude faster than metaheuristics and outperforms dispatching rules and some previous RL approaches in terms of solution quality.\n', 'strengths': 'The tackled problem is important in several practical scheduling applications. Unlike previous approaches that either only generate solutions in one shot or only learn to improve, the proposed approach trains two models to generate and improve at the same time, which could potentially provide the “best of both worlds”, i.e., speed of one-shot generation and solution quality of improvement methods. The proposed two-stage approach and training is novel for scheduling problems to the best of my knowledge.\n', 'weaknesses': 'My biggest concern is that the proposed approach seems to be only applicable to a specific scheduling problem (FJSP) with no variation in terms of constraints. In the abstract, the authors state that:\n\nIt is worth noting that this training paradigm can be readily adapted to other combinatorial optimization problems, such as the traveling salesman problem and beyond.\n\nhowever, there is 1) no empirical evidence to justify the claim and 2) no explanation of how this can actually be done. For instance, how can the improvement step be applied to the traveling salesman problem (TSP), especially considering the reward function? In several combinatorial optimization problems, it is hard to define a step-wise reward function, such as in routing problems such as the TSP. Moreover, the specific design of Section 3 seems to be over-fitted to the FJSP, with new problems requiring a substantial restructuring of the model.\nAnother important point is that the proposed generation-improvement method is not well justified in terms of performance. There is no ablation study on just using the generator model without any improvement:\n\nFrom the design of our framework, it can be seen that the generative model and the improved model can run independently, which means that we can only use the generative model to generate a complete solution or use the improved model individually to improve any feasible initial solution generated by other methods (such as random generation or PDRs).\n\nbut there is no result about this; in Table 3 only the improvement method alone is shown with other models. How would the generate only perform? Moreover, a natural question would arise, namely why authors decided to go for a potentially more burdensome generate+improve method (in which the generator may potentially be worse due to over-reliance on the improvement model), and not just a generator. In these regards, it would be interesting to see how the same model with the generation part only would do.\nThe experimental section seems to be lacking some baselines - for instance, Table 1 only compares against OR-Tools and dispatching rules, but not against RGA and 2SGA and the 2 DRL baselines. Also, OR-Tools is missing the solution time, so it is difficult to assess how the proposed approach compares in solution time (given that the quality is already worse than the OR-Tools metaheuristics). Finally, no standard deviation has been reported nor multiple runs.\nIn terms of the quality of the paper, there is room for improvement. Aside from several typos, the writing feels sloppy, and there are missing references ((ref)  in the paper, mk[?] in Table 2 and more), so I would suggest some revision. More importantly, in Algorithm 1:\n\nStore Transition τt+1g:<St;\xa0St+1>into\xa0EPI\n\nI believe this should be, in fact, EPI , given that EPG is not being used here.\nFinally, no code has been provided to reproduce the results.\n', 'questions': '\nWhy did you decide to use DuelingDQN, and not actor-critic algorithms such as PPO [29] or policy gradient methods as done in MatNet [17]*?\nAs in the “weaknesses” section, how would the model perform if only the generator was trained? And what if we trained with generator+improve but only used the generator for the solution?\nWhat is the number of improvement iterations nt, and how was it selected?\nHow would the proposed method fare in larger-scale instances? [29] studies scale up to 100×60.\n\n\n*Note: MatNet [17] is cited in the manuscript but not referenced throughout the text. It may be useful to at least briefly introduce the differences with the proposed method in the related works.\n'}, {'summary': 'This paper proposes an end-to-end RL framework to solve the Flexible Job-Shop Problem (FJSP). The framework consists of two major components: a generation model that produces an assignment of operations that updates the partial solution, and an improving model that refines the current partial solution. By repeating the generation and improving steps until the complete solution is found, the proposed framework finds a solution for FJSP.\nThe authors evaluate the proposed framework with various-sized FJSP instances, and it is shown to outperform compounded Priority Dispatching Rules (PDR) but underperform Meta-heuristics (e.g., OR-tools).\n', 'strengths': '\nThe proposed framework suggests a novel perspective for solving FJSP. Unlike the majority of iterative improving approaches that often perform improvement steps from a complete solution, the proposed framework employs ""improving"" actions during solution construction.\n\n', 'weaknesses': '\nThe current manuscript still has room for improvement, including a more detailed explanation of the training.\nThe performance evaluation of the proposed framework seems quite limited, especially as the baselines are overly simplified in Table 1.\n\n', 'questions': '\nIt seems the number of improvement iterations nt would play a crucial role within the proposed framework. Could the authors provide further details on how to decide nt? In the current manuscript, it is simply mentioned as a hand-crafted function depending on the iteration index t.\nWhat is GIM in Table 3? From the context, I assume it is the proposed method, but the acronym is never introduced.\nWhat is ""Generate+improve"" in Table 3? Is it different from GIM?\n\n'}, {'summary': 'This paper proposes an RL based scheduling methods for Flexible Job Shop Problem. The approach empolys two graph neural network models, a generative model and an improvement model, which collaboratively solve the problem. At each timestep, the generative model progressively constructs a partial solution by adding a new component into the existing partial solution, and the improvement model refines this partial solution for better performance. Both models are designed to leverage inductive biases from the problem and its current partial solution, e.g., neighbor nodes from different types of edge. The models are trained end-to-end using the reward signal for each model, in an alternating manner to stabilize the learning of two models.\nThe proposed algorithm is evaluated with two experiments, one for synthetic datasets and the other for public benchmarks, and it showed superiority over several heuristics and DRL-based methods in terms of solution quality. Also, though the method failed to outperform the meta-heuristic algorithms, it showed comparable result while spending much less time than the meta-heuristics.\n', 'strengths': '\nThis work proposed a new RL-based framework for solving FJSP, which combines the construction and the improvement processes so that they can be trained in end-to-end manner.\nThe method utilizes different graph representation that corresponds to a single partial solution, providing each model with relevant information. This approach is both interesting and convincing. \nAblation study for the two distinct models provides a good empirical evidence for the proposed architecture.\n\n', 'weaknesses': '[Methods and Experiments]\n\nThis paper doesn\'t provide a clear rationale or justification for the use of various embeddings. Also, there\'s no ablation study for these design choices.\nThe method is evaluated only two public benchmarks, whereas the DRL baseline [1] has been tested on a more extensive set of benchmarks. This raises concerns about the comprehensiveness of the evaluation and potentially limits the generalizability of the proposed method\'s performance.\nThe reported performance of DRL baseline [1] is based on the greedy selection, while the method of this paper leverages sampling for improvement steps. For fairer comparison, the results from both greedy and sampling decoding should be included. Note that sampling performance reported in [1] for v_la task is better than the proposed method, while consuming more computation time.\n\n[Writings]This paper has significant defects with clarity. \nFirst of all, there are too many typos, wrong spacing and inconsistent notaions. Below are some of them:  \n\npage 1: \'PRD\' → \'PDR\'\npage 2: There are many wrong spacing in Sec. 2, e.g, \'O_i,which\', \'operations,O_{ij}\', or ""...end of production.These two ...""\npage 3: There is a wrong figure reference, \'(in figure)\' \npage 4: \'avenger\' → \'average\'\npage 4: GAT has no reference\npage 5: \'avitation\' → \'activation\'\npage 5: \'M_{ij}\' suddenly pops up, which supposedly typo of {A_I}_{ij}, and suddenly A_J is used, which is definitely a typo.\npage 7: In the Algorithm 1, \'EP_I\' → \'EP_G\' for the transition of generative model.\npage 7: There are several \'(ref)\'s in Sec 5.1, which should have been replaced by appropriate reference.\npage 8: In the text they say they use Gurobi Solver, but they report OR-Tools in the table.\nThroughout the paper, the authors use abbreviations without declare it, e.g., DRL in page 3, GAT in page 4, and GIM in page 7 (Algorithm 1)\n\nMoreover, the models are not clearly described, which makes it hard to fully understand the algorithm.For example, in GAT Module section in page 5, it is unclear whether W is shared among different u\'s or not.Also, the reward for each model is not stated mathematically, which introduces an ambiguity.\n[1] Song, Wen, et al. ""Flexible job-shop scheduling via graph neural network and deep reinforcement learning."" IEEE Transactions on Industrial Informatics 19.2 (2022)\n', 'questions': '\nHow long it takes for training?\nWhy the 40 x 10 result is missing for OR-Tools?\nHow can this work be extended to other scheduling or CO problems?\n\n'}, {'summary': 'The author proposed a deep reinforcement learning model to address the FJSP problem. This approach involves the simultaneous application of construction heuristics and improvement heuristics, enabling it to achieve better performance in shorter time on several public datasets.\n', 'strengths': '\nBased on the claim of paper, it seems good to use construction heuristic to construct a better partial solution and use improvement heuristic to improve the partial solution.\n\n', 'weaknesses': '\nActions (in Section 3.1) are critical, but not defined clearly. I have no problems with actions for construction heuristics, but actions for improvement heuristics are not well defined. In Section 3.2 “Insertion Position Embedding” (P5), the definition of insertion position is undefined clearly, and why the number of choices is (n+m) for each operation. Besides, it is also unclear about why the total number of insertion positions is equal to n×(n+m). For these unclear descriptions, there is no clue to understand the proposed method. Note that in Section 3.2 “Policy Model” (P6), there is no way to understand the description “Obviously, there are at most m different insertion schemes for each improvement decision.”\n\nFigure 2 is confusing and unconvincing. For example, why is 31 moved to the position after 11, not before 11? If it can also be moved to that before 11, I don’t see the strategy.\n\nThe representation of operations is inconsistent and thus makes it hard to understand how the Insert Position Embedding works (There are Oij,Oj,Oj(i),Oi in the article).\n\nLack of test results for public benchmark dataset. With comparison to [29], you should also compare with la(edata) and la(rdata). And you may test on the dataset which is referenced by [29] to improve the reliability of your method.\n\n\nPresentation comments: \n\nLack of spaces in many places. E.g., “Both the generative model and the improvement model will use formula(4) to select the action to be executed in the current state st at step t on their respective feasible action sets.The advantage value function is fitted by a parametric MLP” \n\nIn section 5.1, “ In addition, we also used (ref1),(ref1),”, and “mk [? ]” in Table2. Please carefully check the content.\n\nIn Algorithm1, “E%K” => “e%K”, the second “EPI” => “EPG”, etc. There should be more that you need to find out for fixing. \n\nThere is no data in some places in the tables, such as 40x10 for OR-Tools in Table1 and mk[?] for UB* in Table2.\n\n\n', 'questions': '\nI am still wondering about your method for the Machine Process Queue Embedding:\nIs Mij=1 if Oj is processed on Machine i, or Oj “can be” processed on Machine i? What is the concept of model designing (or why it is designed in this way)?\n\nIt’s not clear that “Job Sequence Embedding”, if Oij (j-th operation of Job i) is processed then AJ(Ji,Oij) = 1?\n\n\n'}]"
